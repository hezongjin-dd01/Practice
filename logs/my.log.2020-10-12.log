09:16:57.215 INFO  [main] org.apache.spark.SparkContext - Running Spark version 2.2.3
09:16:58.666 INFO  [main] org.apache.spark.SparkContext - Submitted application: demo
09:16:58.697 INFO  [main] org.apache.spark.SecurityManager - Changing view acls to: user
09:16:58.697 INFO  [main] org.apache.spark.SecurityManager - Changing modify acls to: user
09:16:58.697 INFO  [main] org.apache.spark.SecurityManager - Changing view acls groups to: 
09:16:58.697 INFO  [main] org.apache.spark.SecurityManager - Changing modify acls groups to: 
09:16:58.697 INFO  [main] org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(user); groups with view permissions: Set(); users  with modify permissions: Set(user); groups with modify permissions: Set()
09:16:59.181 INFO  [main] org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 51178.
09:16:59.212 INFO  [main] org.apache.spark.SparkEnv - Registering MapOutputTracker
09:16:59.228 INFO  [main] org.apache.spark.SparkEnv - Registering BlockManagerMaster
09:16:59.228 INFO  [main] org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
09:16:59.228 INFO  [main] org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
09:16:59.244 INFO  [main] org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\user\AppData\Local\Temp\blockmgr-c5a4da37-0f00-49df-a04c-3718932b35f2
09:16:59.259 INFO  [main] org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 1954.5 MB
09:16:59.306 INFO  [main] org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
09:16:59.400 INFO  [main] org.spark_project.jetty.util.log - Logging initialized @3824ms
09:16:59.462 INFO  [main] org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
09:16:59.462 INFO  [main] org.spark_project.jetty.server.Server - Started @3899ms
09:16:59.494 INFO  [main] org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@71f67a79{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
09:16:59.494 INFO  [main] org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
09:16:59.509 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5400db36{/jobs,null,AVAILABLE,@Spark}
09:16:59.509 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@13006998{/jobs/json,null,AVAILABLE,@Spark}
09:16:59.509 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@352c308{/jobs/job,null,AVAILABLE,@Spark}
09:16:59.509 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dda6f9{/jobs/job/json,null,AVAILABLE,@Spark}
09:16:59.509 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54afd745{/stages,null,AVAILABLE,@Spark}
09:16:59.509 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@fff25f1{/stages/json,null,AVAILABLE,@Spark}
09:16:59.509 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@263f04ca{/stages/stage,null,AVAILABLE,@Spark}
09:16:59.509 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@f31c0c6{/stages/stage/json,null,AVAILABLE,@Spark}
09:16:59.509 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4a9419d7{/stages/pool,null,AVAILABLE,@Spark}
09:16:59.509 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2e8ab815{/stages/pool/json,null,AVAILABLE,@Spark}
09:16:59.509 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d1f74b8{/storage,null,AVAILABLE,@Spark}
09:16:59.509 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a0807b7{/storage/json,null,AVAILABLE,@Spark}
09:16:59.509 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5769e7ae{/storage/rdd,null,AVAILABLE,@Spark}
09:16:59.509 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@26b894bd{/storage/rdd/json,null,AVAILABLE,@Spark}
09:16:59.509 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@30b34287{/environment,null,AVAILABLE,@Spark}
09:16:59.509 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3676ac27{/environment/json,null,AVAILABLE,@Spark}
09:16:59.509 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@48f5bde6{/executors,null,AVAILABLE,@Spark}
09:16:59.509 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5149f008{/executors/json,null,AVAILABLE,@Spark}
09:16:59.525 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158d255c{/executors/threadDump,null,AVAILABLE,@Spark}
09:16:59.525 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@327120c8{/executors/threadDump/json,null,AVAILABLE,@Spark}
09:16:59.525 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2b5cb9b2{/static,null,AVAILABLE,@Spark}
09:16:59.525 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@120f38e6{/,null,AVAILABLE,@Spark}
09:16:59.525 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@702ed190{/api,null,AVAILABLE,@Spark}
09:16:59.525 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5a4bef8{/jobs/job/kill,null,AVAILABLE,@Spark}
09:16:59.525 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2449cff7{/stages/stage/kill,null,AVAILABLE,@Spark}
09:16:59.540 INFO  [main] org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://172.16.2.246:4040
09:16:59.618 INFO  [main] org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
09:16:59.634 INFO  [main] org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51199.
09:16:59.650 INFO  [main] org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.16.2.246:51199
09:16:59.650 INFO  [main] org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
09:16:59.681 INFO  [main] org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 172.16.2.246, 51199, None)
09:16:59.681 INFO  [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 172.16.2.246:51199 with 1954.5 MB RAM, BlockManagerId(driver, 172.16.2.246, 51199, None)
09:16:59.681 INFO  [main] org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 172.16.2.246, 51199, None)
09:16:59.681 INFO  [main] org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 172.16.2.246, 51199, None)
09:16:59.822 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@36bc415e{/metrics/json,null,AVAILABLE,@Spark}
09:16:59.900 INFO  [main] org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/E:/IdeaProjects/practice/spark-warehouse/').
09:16:59.900 INFO  [main] org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/E:/IdeaProjects/practice/spark-warehouse/'.
09:16:59.916 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4bdc8b5d{/SQL,null,AVAILABLE,@Spark}
09:16:59.916 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5f14a673{/SQL/json,null,AVAILABLE,@Spark}
09:16:59.916 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5467eea4{/SQL/execution,null,AVAILABLE,@Spark}
09:16:59.916 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a799159{/SQL/execution/json,null,AVAILABLE,@Spark}
09:16:59.916 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@76b224cd{/static/sql,null,AVAILABLE,@Spark}
09:17:00.650 INFO  [main] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
09:17:00.702 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
09:17:01.948 INFO  [Thread-1] org.apache.spark.SparkContext - Invoking stop() from shutdown hook
09:17:01.964 INFO  [Thread-1] org.spark_project.jetty.server.AbstractConnector - Stopped Spark@71f67a79{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
09:17:01.964 INFO  [Thread-1] org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://172.16.2.246:4040
09:17:01.964 INFO  [dispatcher-event-loop-7] org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
09:17:01.980 INFO  [Thread-1] org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
09:17:01.980 INFO  [Thread-1] org.apache.spark.storage.BlockManager - BlockManager stopped
09:17:01.980 INFO  [Thread-1] org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
09:17:01.980 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
09:17:01.980 INFO  [Thread-1] org.apache.spark.SparkContext - Successfully stopped SparkContext
09:17:01.980 INFO  [Thread-1] org.apache.spark.util.ShutdownHookManager - Shutdown hook called
09:17:01.980 INFO  [Thread-1] org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\user\AppData\Local\Temp\spark-0f0ff0f8-eae2-4790-b591-d19c37408886
09:17:33.249 INFO  [main] org.apache.spark.SparkContext - Running Spark version 2.2.3
09:17:33.767 INFO  [main] org.apache.spark.SparkContext - Submitted application: demo
09:17:33.796 INFO  [main] org.apache.spark.SecurityManager - Changing view acls to: user
09:17:33.797 INFO  [main] org.apache.spark.SecurityManager - Changing modify acls to: user
09:17:33.798 INFO  [main] org.apache.spark.SecurityManager - Changing view acls groups to: 
09:17:33.798 INFO  [main] org.apache.spark.SecurityManager - Changing modify acls groups to: 
09:17:33.799 INFO  [main] org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(user); groups with view permissions: Set(); users  with modify permissions: Set(user); groups with modify permissions: Set()
09:17:34.300 INFO  [main] org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 51255.
09:17:34.313 INFO  [main] org.apache.spark.SparkEnv - Registering MapOutputTracker
09:17:34.327 INFO  [main] org.apache.spark.SparkEnv - Registering BlockManagerMaster
09:17:34.330 INFO  [main] org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
09:17:34.330 INFO  [main] org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
09:17:34.339 INFO  [main] org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\user\AppData\Local\Temp\blockmgr-b5959bd5-3423-4227-bb92-628889249136
09:17:34.360 INFO  [main] org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 1954.5 MB
09:17:34.396 INFO  [main] org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
09:17:34.451 INFO  [main] org.spark_project.jetty.util.log - Logging initialized @2546ms
09:17:34.495 INFO  [main] org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
09:17:34.508 INFO  [main] org.spark_project.jetty.server.Server - Started @2604ms
09:17:34.527 INFO  [main] org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@4263b080{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
09:17:34.528 INFO  [main] org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
09:17:34.545 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@411341bd{/jobs,null,AVAILABLE,@Spark}
09:17:34.546 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@41beb473{/jobs/json,null,AVAILABLE,@Spark}
09:17:34.546 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@13006998{/jobs/job,null,AVAILABLE,@Spark}
09:17:34.547 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7d373bcf{/jobs/job/json,null,AVAILABLE,@Spark}
09:17:34.547 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dda6f9{/stages,null,AVAILABLE,@Spark}
09:17:34.547 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54afd745{/stages/json,null,AVAILABLE,@Spark}
09:17:34.547 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@fff25f1{/stages/stage,null,AVAILABLE,@Spark}
09:17:34.548 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5a021cb9{/stages/stage/json,null,AVAILABLE,@Spark}
09:17:34.549 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@f31c0c6{/stages/pool,null,AVAILABLE,@Spark}
09:17:34.549 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4a9419d7{/stages/pool/json,null,AVAILABLE,@Spark}
09:17:34.550 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2e8ab815{/storage,null,AVAILABLE,@Spark}
09:17:34.551 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d1f74b8{/storage/json,null,AVAILABLE,@Spark}
09:17:34.552 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a0807b7{/storage/rdd,null,AVAILABLE,@Spark}
09:17:34.553 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5769e7ae{/storage/rdd/json,null,AVAILABLE,@Spark}
09:17:34.554 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@26b894bd{/environment,null,AVAILABLE,@Spark}
09:17:34.554 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@30b34287{/environment/json,null,AVAILABLE,@Spark}
09:17:34.554 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3676ac27{/executors,null,AVAILABLE,@Spark}
09:17:34.555 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@48f5bde6{/executors/json,null,AVAILABLE,@Spark}
09:17:34.555 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5149f008{/executors/threadDump,null,AVAILABLE,@Spark}
09:17:34.556 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158d255c{/executors/threadDump/json,null,AVAILABLE,@Spark}
09:17:34.560 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@327120c8{/static,null,AVAILABLE,@Spark}
09:17:34.561 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2555fff0{/,null,AVAILABLE,@Spark}
09:17:34.562 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@120f38e6{/api,null,AVAILABLE,@Spark}
09:17:34.562 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@70e29e14{/jobs/job/kill,null,AVAILABLE,@Spark}
09:17:34.563 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5a4bef8{/stages/stage/kill,null,AVAILABLE,@Spark}
09:17:34.565 INFO  [main] org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://172.16.2.246:4040
09:17:34.639 INFO  [main] org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
09:17:34.655 INFO  [main] org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51276.
09:17:34.655 INFO  [main] org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.16.2.246:51276
09:17:34.660 INFO  [main] org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
09:17:34.681 INFO  [main] org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 172.16.2.246, 51276, None)
09:17:34.683 INFO  [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 172.16.2.246:51276 with 1954.5 MB RAM, BlockManagerId(driver, 172.16.2.246, 51276, None)
09:17:34.685 INFO  [main] org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 172.16.2.246, 51276, None)
09:17:34.686 INFO  [main] org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 172.16.2.246, 51276, None)
09:17:34.816 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6d367020{/metrics/json,null,AVAILABLE,@Spark}
09:17:34.874 INFO  [main] org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/E:/IdeaProjects/practice/spark-warehouse/').
09:17:34.874 INFO  [main] org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/E:/IdeaProjects/practice/spark-warehouse/'.
09:17:34.879 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4c9e38{/SQL,null,AVAILABLE,@Spark}
09:17:34.879 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4bdc8b5d{/SQL/json,null,AVAILABLE,@Spark}
09:17:34.880 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@c4c0b41{/SQL/execution,null,AVAILABLE,@Spark}
09:17:34.880 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5467eea4{/SQL/execution/json,null,AVAILABLE,@Spark}
09:17:34.881 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@53093491{/static/sql,null,AVAILABLE,@Spark}
09:17:35.516 INFO  [main] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
09:17:35.543 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
09:17:36.662 INFO  [Thread-1] org.apache.spark.SparkContext - Invoking stop() from shutdown hook
09:17:36.666 INFO  [Thread-1] org.spark_project.jetty.server.AbstractConnector - Stopped Spark@4263b080{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
09:17:36.668 INFO  [Thread-1] org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://172.16.2.246:4040
09:17:36.674 INFO  [dispatcher-event-loop-7] org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
09:17:36.679 INFO  [Thread-1] org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
09:17:36.679 INFO  [Thread-1] org.apache.spark.storage.BlockManager - BlockManager stopped
09:17:36.683 INFO  [Thread-1] org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
09:17:36.685 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
09:17:36.686 INFO  [Thread-1] org.apache.spark.SparkContext - Successfully stopped SparkContext
09:17:36.687 INFO  [Thread-1] org.apache.spark.util.ShutdownHookManager - Shutdown hook called
09:17:36.688 INFO  [Thread-1] org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\user\AppData\Local\Temp\spark-9bad686c-c7e5-48a1-9fbc-6d4b2d9feb92
09:20:45.495 INFO  [main] org.apache.spark.SparkContext - Running Spark version 2.2.3
09:20:45.839 INFO  [main] org.apache.spark.SparkContext - Submitted application: demo
09:20:45.855 INFO  [main] org.apache.spark.SecurityManager - Changing view acls to: user
09:20:45.855 INFO  [main] org.apache.spark.SecurityManager - Changing modify acls to: user
09:20:45.855 INFO  [main] org.apache.spark.SecurityManager - Changing view acls groups to: 
09:20:45.855 INFO  [main] org.apache.spark.SecurityManager - Changing modify acls groups to: 
09:20:45.870 INFO  [main] org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(user); groups with view permissions: Set(); users  with modify permissions: Set(user); groups with modify permissions: Set()
09:20:46.323 INFO  [main] org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 51444.
09:20:46.339 INFO  [main] org.apache.spark.SparkEnv - Registering MapOutputTracker
09:20:46.355 INFO  [main] org.apache.spark.SparkEnv - Registering BlockManagerMaster
09:20:46.355 INFO  [main] org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
09:20:46.355 INFO  [main] org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
09:20:46.355 INFO  [main] org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\user\AppData\Local\Temp\blockmgr-9c03e2e5-a0c7-4c49-8531-9a20a1fbbfd6
09:20:46.370 INFO  [main] org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 1954.5 MB
09:20:46.401 INFO  [main] org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
09:20:46.464 INFO  [main] org.spark_project.jetty.util.log - Logging initialized @2214ms
09:20:46.495 INFO  [main] org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
09:20:46.511 INFO  [main] org.spark_project.jetty.server.Server - Started @2265ms
09:20:46.526 INFO  [main] org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@71f67a79{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
09:20:46.526 INFO  [main] org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
09:20:46.542 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5400db36{/jobs,null,AVAILABLE,@Spark}
09:20:46.542 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@13006998{/jobs/json,null,AVAILABLE,@Spark}
09:20:46.542 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@352c308{/jobs/job,null,AVAILABLE,@Spark}
09:20:46.542 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5dda6f9{/jobs/job/json,null,AVAILABLE,@Spark}
09:20:46.542 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@54afd745{/stages,null,AVAILABLE,@Spark}
09:20:46.542 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@fff25f1{/stages/json,null,AVAILABLE,@Spark}
09:20:46.542 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@263f04ca{/stages/stage,null,AVAILABLE,@Spark}
09:20:46.542 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@f31c0c6{/stages/stage/json,null,AVAILABLE,@Spark}
09:20:46.542 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4a9419d7{/stages/pool,null,AVAILABLE,@Spark}
09:20:46.542 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2e8ab815{/stages/pool/json,null,AVAILABLE,@Spark}
09:20:46.542 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d1f74b8{/storage,null,AVAILABLE,@Spark}
09:20:46.542 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a0807b7{/storage/json,null,AVAILABLE,@Spark}
09:20:46.542 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5769e7ae{/storage/rdd,null,AVAILABLE,@Spark}
09:20:46.542 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@26b894bd{/storage/rdd/json,null,AVAILABLE,@Spark}
09:20:46.542 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@30b34287{/environment,null,AVAILABLE,@Spark}
09:20:46.542 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3676ac27{/environment/json,null,AVAILABLE,@Spark}
09:20:46.542 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@48f5bde6{/executors,null,AVAILABLE,@Spark}
09:20:46.558 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5149f008{/executors/json,null,AVAILABLE,@Spark}
09:20:46.558 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@158d255c{/executors/threadDump,null,AVAILABLE,@Spark}
09:20:46.558 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@327120c8{/executors/threadDump/json,null,AVAILABLE,@Spark}
09:20:46.558 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2b5cb9b2{/static,null,AVAILABLE,@Spark}
09:20:46.558 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@120f38e6{/,null,AVAILABLE,@Spark}
09:20:46.558 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@702ed190{/api,null,AVAILABLE,@Spark}
09:20:46.558 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5a4bef8{/jobs/job/kill,null,AVAILABLE,@Spark}
09:20:46.558 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2449cff7{/stages/stage/kill,null,AVAILABLE,@Spark}
09:20:46.558 INFO  [main] org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://172.16.2.246:4040
09:20:46.620 INFO  [main] org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
09:20:46.636 INFO  [main] org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51465.
09:20:46.636 INFO  [main] org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.16.2.246:51465
09:20:46.636 INFO  [main] org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
09:20:46.667 INFO  [main] org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 172.16.2.246, 51465, None)
09:20:46.667 INFO  [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 172.16.2.246:51465 with 1954.5 MB RAM, BlockManagerId(driver, 172.16.2.246, 51465, None)
09:20:46.667 INFO  [main] org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 172.16.2.246, 51465, None)
09:20:46.667 INFO  [main] org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 172.16.2.246, 51465, None)
09:20:46.776 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@36bc415e{/metrics/json,null,AVAILABLE,@Spark}
09:20:46.839 INFO  [main] org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/E:/IdeaProjects/practice/spark-warehouse/').
09:20:46.839 INFO  [main] org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/E:/IdeaProjects/practice/spark-warehouse/'.
09:20:46.839 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4bdc8b5d{/SQL,null,AVAILABLE,@Spark}
09:20:46.839 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5f14a673{/SQL/json,null,AVAILABLE,@Spark}
09:20:46.839 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5467eea4{/SQL/execution,null,AVAILABLE,@Spark}
09:20:46.839 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7a799159{/SQL/execution/json,null,AVAILABLE,@Spark}
09:20:46.839 INFO  [main] org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@76b224cd{/static/sql,null,AVAILABLE,@Spark}
09:20:47.432 INFO  [main] org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef - Registered StateStoreCoordinator endpoint
09:20:47.464 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
09:20:48.651 INFO  [main] org.apache.spark.sql.execution.streaming.StreamExecution - Starting [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]. Use C:\Users\user\AppData\Local\Temp\temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430 to store the query checkpoint.
09:20:48.710 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.sql.execution.streaming.StreamExecution - Starting new streaming query.
09:20:49.901 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.sql.execution.streaming.StreamExecution - Committed offsets for batch 0. Metadata OffsetSeqMetadata(0,1602465648714,Map(spark.sql.shuffle.partitions -> 200))
09:20:50.216 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 169.4663 ms
09:20:50.576 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 7.0974 ms
09:20:50.823 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 30.5098 ms
09:20:50.870 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 43.8892 ms
09:20:50.917 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 30.8537 ms
09:20:50.933 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 5.0331 ms
09:20:51.136 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 250.7 KB, free 1954.3 MB)
09:20:51.198 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 21.2 KB, free 1954.2 MB)
09:20:51.198 INFO  [dispatcher-event-loop-6] org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on 172.16.2.246:51465 (size: 21.2 KB, free: 1954.5 MB)
09:20:51.198 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.SparkContext - Created broadcast 0 from start at demo.scala:28
09:20:51.245 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 250.7 KB, free 1954.0 MB)
09:20:51.261 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 21.2 KB, free 1954.0 MB)
09:20:51.261 INFO  [dispatcher-event-loop-7] org.apache.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on 172.16.2.246:51465 (size: 21.2 KB, free: 1954.5 MB)
09:20:51.261 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.SparkContext - Created broadcast 1 from start at demo.scala:28
09:20:51.292 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.SparkContext - Starting job: start at demo.scala:28
09:20:51.308 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Registering RDD 5 (start at demo.scala:28)
09:20:51.308 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Got job 0 (start at demo.scala:28) with 200 output partitions
09:20:51.308 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (start at demo.scala:28)
09:20:51.308 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 0)
09:20:51.308 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 0)
09:20:51.308 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at start at demo.scala:28), which has no missing parents
09:20:51.339 INFO  [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 23.8 KB, free 1953.9 MB)
09:20:51.339 INFO  [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.7 KB, free 1953.9 MB)
09:20:51.339 INFO  [dispatcher-event-loop-0] org.apache.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on 172.16.2.246:51465 (size: 10.7 KB, free: 1954.4 MB)
09:20:51.339 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext - Created broadcast 2 from broadcast at DAGScheduler.scala:1004
09:20:51.370 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[5] at start at demo.scala:28) (first 15 tasks are for partitions Vector(0))
09:20:51.370 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks
09:20:51.370 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner - Cleaned accumulator 0
09:20:51.401 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5000 bytes)
09:20:51.417 INFO  [Executor task launch worker for task 0] org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
09:20:51.479 INFO  [Executor task launch worker for task 0] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 6.1826 ms
09:20:51.479 INFO  [Executor task launch worker for task 0] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 4.6555 ms
09:20:51.495 INFO  [Executor task launch worker for task 0] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 4.966 ms
09:20:51.511 INFO  [Executor task launch worker for task 0] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 5.4393 ms
09:20:51.511 INFO  [Executor task launch worker for task 0] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 8.0026 ms
09:20:51.604 INFO  [Executor task launch worker for task 0] org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1932 bytes result sent to driver
09:20:51.604 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 218 ms on localhost (executor driver) (1/1)
09:20:51.620 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
09:20:51.620 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 0 (start at demo.scala:28) finished in 0.234 s
09:20:51.620 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
09:20:51.620 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - running: Set()
09:20:51.620 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 1)
09:20:51.620 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - failed: Set()
09:20:51.620 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[12] at start at demo.scala:28), which has no missing parents
09:20:51.682 INFO  [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 45.4 KB, free 1953.9 MB)
09:20:51.682 INFO  [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 16.7 KB, free 1953.9 MB)
09:20:51.682 INFO  [dispatcher-event-loop-4] org.apache.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on 172.16.2.246:51465 (size: 16.7 KB, free: 1954.4 MB)
09:20:51.682 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext - Created broadcast 3 from broadcast at DAGScheduler.scala:1004
09:20:51.682 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Submitting 200 missing tasks from ResultStage 1 (MapPartitionsRDD[12] at start at demo.scala:28) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
09:20:51.682 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 200 tasks
09:20:51.682 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 4726 bytes)
09:20:51.682 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 4726 bytes)
09:20:51.682 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 1.0 (TID 3, localhost, executor driver, partition 2, PROCESS_LOCAL, 4726 bytes)
09:20:51.682 INFO  [Executor task launch worker for task 1] org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
09:20:51.682 INFO  [Executor task launch worker for task 3] org.apache.spark.executor.Executor - Running task 2.0 in stage 1.0 (TID 3)
09:20:51.682 INFO  [Executor task launch worker for task 2] org.apache.spark.executor.Executor - Running task 1.0 in stage 1.0 (TID 2)
09:20:51.712 INFO  [Executor task launch worker for task 3] org.apache.spark.sql.execution.streaming.state.StateStore - State Store maintenance task started
09:20:51.722 INFO  [Executor task launch worker for task 2] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=1), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/1] for update
09:20:51.722 INFO  [Executor task launch worker for task 1] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=0), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/0] for update
09:20:51.722 INFO  [Executor task launch worker for task 3] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=2), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/2] for update
09:20:51.722 INFO  [Executor task launch worker for task 2] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=1), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/1] for update
09:20:51.723 INFO  [Executor task launch worker for task 3] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=2), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/2] for update
09:20:51.723 INFO  [Executor task launch worker for task 1] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=0), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/0] for update
09:20:51.730 INFO  [Executor task launch worker for task 1] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:51.730 INFO  [Executor task launch worker for task 2] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:51.730 INFO  [Executor task launch worker for task 3] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:51.730 INFO  [Executor task launch worker for task 3] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:51.730 INFO  [Executor task launch worker for task 2] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:51.730 INFO  [Executor task launch worker for task 1] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:51.855 INFO  [Executor task launch worker for task 3] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=2),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/2] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/2/1.delta
09:20:51.855 INFO  [Executor task launch worker for task 1] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=0),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/0] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/0/1.delta
09:20:51.855 INFO  [Executor task launch worker for task 2] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=1),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/1] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/1/1.delta
09:20:51.855 INFO  [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerInfo - Removed broadcast_2_piece0 on 172.16.2.246:51465 in memory (size: 10.7 KB, free: 1954.4 MB)
09:20:51.870 INFO  [Executor task launch worker for task 1] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=0),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/0]
09:20:51.870 INFO  [Executor task launch worker for task 2] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=1),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/1]
09:20:51.870 INFO  [Executor task launch worker for task 3] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=2),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/2]
09:20:51.870 INFO  [Executor task launch worker for task 1] org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 3494 bytes result sent to driver
09:20:51.870 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 1.0 (TID 4, localhost, executor driver, partition 3, PROCESS_LOCAL, 4726 bytes)
09:20:51.870 INFO  [Executor task launch worker for task 2] org.apache.spark.executor.Executor - Finished task 1.0 in stage 1.0 (TID 2). 3494 bytes result sent to driver
09:20:51.870 INFO  [Executor task launch worker for task 4] org.apache.spark.executor.Executor - Running task 3.0 in stage 1.0 (TID 4)
09:20:51.870 INFO  [Executor task launch worker for task 3] org.apache.spark.executor.Executor - Finished task 2.0 in stage 1.0 (TID 3). 3494 bytes result sent to driver
09:20:51.870 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 1.0 (TID 5, localhost, executor driver, partition 4, PROCESS_LOCAL, 4726 bytes)
09:20:51.870 INFO  [Executor task launch worker for task 5] org.apache.spark.executor.Executor - Running task 4.0 in stage 1.0 (TID 5)
09:20:51.870 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 1.0 (TID 6, localhost, executor driver, partition 5, PROCESS_LOCAL, 4726 bytes)
09:20:51.870 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 1) in 188 ms on localhost (executor driver) (1/200)
09:20:51.870 INFO  [Executor task launch worker for task 6] org.apache.spark.executor.Executor - Running task 5.0 in stage 1.0 (TID 6)
09:20:51.886 INFO  [Executor task launch worker for task 6] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=5), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/5] for update
09:20:51.886 INFO  [Executor task launch worker for task 6] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=5), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/5] for update
09:20:51.886 INFO  [Executor task launch worker for task 6] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:51.886 INFO  [Executor task launch worker for task 6] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:51.886 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 1.0 (TID 2) in 204 ms on localhost (executor driver) (2/200)
09:20:51.886 INFO  [Executor task launch worker for task 5] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=4), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/4] for update
09:20:51.886 INFO  [Executor task launch worker for task 4] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=3), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/3] for update
09:20:51.886 INFO  [Executor task launch worker for task 4] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=3), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/3] for update
09:20:51.886 INFO  [Executor task launch worker for task 5] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=4), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/4] for update
09:20:51.886 INFO  [Executor task launch worker for task 4] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:51.886 INFO  [Executor task launch worker for task 4] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:51.886 INFO  [Executor task launch worker for task 5] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:51.886 INFO  [Executor task launch worker for task 5] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:51.901 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 1.0 (TID 3) in 219 ms on localhost (executor driver) (3/200)
09:20:51.901 INFO  [Executor task launch worker for task 6] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=5),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/5] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/5/1.delta
09:20:51.901 INFO  [Executor task launch worker for task 5] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=4),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/4] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/4/1.delta
09:20:51.901 INFO  [Executor task launch worker for task 6] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=5),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/5]
09:20:51.901 INFO  [Executor task launch worker for task 6] org.apache.spark.executor.Executor - Finished task 5.0 in stage 1.0 (TID 6). 3451 bytes result sent to driver
09:20:51.901 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 6.0 in stage 1.0 (TID 7, localhost, executor driver, partition 6, PROCESS_LOCAL, 4726 bytes)
09:20:51.901 INFO  [Executor task launch worker for task 4] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=3),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/3] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/3/1.delta
09:20:51.901 INFO  [Executor task launch worker for task 7] org.apache.spark.executor.Executor - Running task 6.0 in stage 1.0 (TID 7)
09:20:51.901 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 1.0 (TID 6) in 31 ms on localhost (executor driver) (4/200)
09:20:51.917 INFO  [Executor task launch worker for task 7] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=6), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/6] for update
09:20:51.917 INFO  [Executor task launch worker for task 7] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=6), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/6] for update
09:20:51.917 INFO  [Executor task launch worker for task 7] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:51.917 INFO  [Executor task launch worker for task 7] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:51.917 INFO  [Executor task launch worker for task 5] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=4),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/4]
09:20:51.917 INFO  [Executor task launch worker for task 5] org.apache.spark.executor.Executor - Finished task 4.0 in stage 1.0 (TID 5). 3451 bytes result sent to driver
09:20:51.917 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 7.0 in stage 1.0 (TID 8, localhost, executor driver, partition 7, PROCESS_LOCAL, 4726 bytes)
09:20:51.917 INFO  [Executor task launch worker for task 8] org.apache.spark.executor.Executor - Running task 7.0 in stage 1.0 (TID 8)
09:20:51.917 INFO  [Executor task launch worker for task 4] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=3),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/3]
09:20:51.917 INFO  [Executor task launch worker for task 4] org.apache.spark.executor.Executor - Finished task 3.0 in stage 1.0 (TID 4). 3365 bytes result sent to driver
09:20:51.917 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 1.0 (TID 5) in 47 ms on localhost (executor driver) (5/200)
09:20:51.933 INFO  [Executor task launch worker for task 7] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=6),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/6] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/6/1.delta
09:20:51.933 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 8.0 in stage 1.0 (TID 9, localhost, executor driver, partition 8, PROCESS_LOCAL, 4726 bytes)
09:20:51.933 INFO  [Executor task launch worker for task 9] org.apache.spark.executor.Executor - Running task 8.0 in stage 1.0 (TID 9)
09:20:51.933 INFO  [Executor task launch worker for task 8] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=7), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/7] for update
09:20:51.933 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 1.0 (TID 4) in 63 ms on localhost (executor driver) (6/200)
09:20:51.933 INFO  [Executor task launch worker for task 8] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=7), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/7] for update
09:20:51.933 INFO  [Executor task launch worker for task 8] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:51.933 INFO  [Executor task launch worker for task 8] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:51.933 INFO  [Executor task launch worker for task 7] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=6),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/6]
09:20:51.933 INFO  [Executor task launch worker for task 7] org.apache.spark.executor.Executor - Finished task 6.0 in stage 1.0 (TID 7). 3451 bytes result sent to driver
09:20:51.933 INFO  [Executor task launch worker for task 9] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=8), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/8] for update
09:20:51.933 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 9.0 in stage 1.0 (TID 10, localhost, executor driver, partition 9, PROCESS_LOCAL, 4726 bytes)
09:20:51.933 INFO  [Executor task launch worker for task 9] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=8), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/8] for update
09:20:51.948 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 6.0 in stage 1.0 (TID 7) in 47 ms on localhost (executor driver) (7/200)
09:20:51.948 INFO  [Executor task launch worker for task 10] org.apache.spark.executor.Executor - Running task 9.0 in stage 1.0 (TID 10)
09:20:51.948 INFO  [Executor task launch worker for task 9] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:51.948 INFO  [Executor task launch worker for task 9] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:51.948 INFO  [Executor task launch worker for task 10] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=9), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/9] for update
09:20:51.948 INFO  [Executor task launch worker for task 10] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=9), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/9] for update
09:20:51.948 INFO  [Executor task launch worker for task 10] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:51.948 INFO  [Executor task launch worker for task 10] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:51.948 INFO  [Executor task launch worker for task 8] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=7),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/7] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/7/1.delta
09:20:51.964 INFO  [Executor task launch worker for task 10] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=9),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/9] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/9/1.delta
09:20:51.964 INFO  [Executor task launch worker for task 8] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=7),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/7]
09:20:51.964 INFO  [Executor task launch worker for task 10] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=9),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/9]
09:20:51.964 INFO  [Executor task launch worker for task 10] org.apache.spark.executor.Executor - Finished task 9.0 in stage 1.0 (TID 10). 3365 bytes result sent to driver
09:20:51.964 INFO  [Executor task launch worker for task 8] org.apache.spark.executor.Executor - Finished task 7.0 in stage 1.0 (TID 8). 3451 bytes result sent to driver
09:20:51.964 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 10.0 in stage 1.0 (TID 11, localhost, executor driver, partition 10, PROCESS_LOCAL, 4726 bytes)
09:20:51.964 INFO  [Executor task launch worker for task 9] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=8),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/8] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/8/1.delta
09:20:51.964 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 11.0 in stage 1.0 (TID 12, localhost, executor driver, partition 11, PROCESS_LOCAL, 4726 bytes)
09:20:51.964 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 9.0 in stage 1.0 (TID 10) in 31 ms on localhost (executor driver) (8/200)
09:20:51.964 INFO  [Executor task launch worker for task 12] org.apache.spark.executor.Executor - Running task 11.0 in stage 1.0 (TID 12)
09:20:51.964 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 7.0 in stage 1.0 (TID 8) in 47 ms on localhost (executor driver) (9/200)
09:20:51.964 INFO  [Executor task launch worker for task 11] org.apache.spark.executor.Executor - Running task 10.0 in stage 1.0 (TID 11)
09:20:51.980 INFO  [Executor task launch worker for task 12] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=11), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/11] for update
09:20:51.980 INFO  [Executor task launch worker for task 12] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=11), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/11] for update
09:20:51.980 INFO  [Executor task launch worker for task 11] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=10), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/10] for update
09:20:51.980 INFO  [Executor task launch worker for task 11] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=10), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/10] for update
09:20:51.980 INFO  [Executor task launch worker for task 12] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:51.980 INFO  [Executor task launch worker for task 12] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:51.980 INFO  [Executor task launch worker for task 11] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:51.980 INFO  [Executor task launch worker for task 11] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:51.980 INFO  [Executor task launch worker for task 9] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=8),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/8]
09:20:51.980 INFO  [Executor task launch worker for task 9] org.apache.spark.executor.Executor - Finished task 8.0 in stage 1.0 (TID 9). 3365 bytes result sent to driver
09:20:51.980 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 12.0 in stage 1.0 (TID 13, localhost, executor driver, partition 12, PROCESS_LOCAL, 4726 bytes)
09:20:51.980 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 8.0 in stage 1.0 (TID 9) in 47 ms on localhost (executor driver) (10/200)
09:20:51.980 INFO  [Executor task launch worker for task 13] org.apache.spark.executor.Executor - Running task 12.0 in stage 1.0 (TID 13)
09:20:51.980 INFO  [Executor task launch worker for task 12] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=11),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/11] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/11/1.delta
09:20:51.995 INFO  [Executor task launch worker for task 11] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=10),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/10] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/10/1.delta
09:20:51.995 INFO  [Executor task launch worker for task 13] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=12), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/12] for update
09:20:51.995 INFO  [Executor task launch worker for task 13] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=12), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/12] for update
09:20:51.995 INFO  [Executor task launch worker for task 13] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:51.995 INFO  [Executor task launch worker for task 13] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:51.995 INFO  [Executor task launch worker for task 12] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=11),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/11]
09:20:51.995 INFO  [Executor task launch worker for task 12] org.apache.spark.executor.Executor - Finished task 11.0 in stage 1.0 (TID 12). 3451 bytes result sent to driver
09:20:51.995 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 13.0 in stage 1.0 (TID 14, localhost, executor driver, partition 13, PROCESS_LOCAL, 4726 bytes)
09:20:51.995 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 11.0 in stage 1.0 (TID 12) in 31 ms on localhost (executor driver) (11/200)
09:20:51.995 INFO  [Executor task launch worker for task 14] org.apache.spark.executor.Executor - Running task 13.0 in stage 1.0 (TID 14)
09:20:52.011 INFO  [Executor task launch worker for task 14] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=13), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/13] for update
09:20:52.011 INFO  [Executor task launch worker for task 14] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=13), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/13] for update
09:20:52.011 INFO  [Executor task launch worker for task 14] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.011 INFO  [Executor task launch worker for task 14] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.011 INFO  [Executor task launch worker for task 11] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=10),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/10]
09:20:52.011 INFO  [Executor task launch worker for task 11] org.apache.spark.executor.Executor - Finished task 10.0 in stage 1.0 (TID 11). 3451 bytes result sent to driver
09:20:52.011 INFO  [Executor task launch worker for task 13] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=12),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/12] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/12/1.delta
09:20:52.011 INFO  [Executor task launch worker for task 14] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=13),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/13] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/13/1.delta
09:20:52.011 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 14.0 in stage 1.0 (TID 15, localhost, executor driver, partition 14, PROCESS_LOCAL, 4726 bytes)
09:20:52.026 INFO  [Executor task launch worker for task 15] org.apache.spark.executor.Executor - Running task 14.0 in stage 1.0 (TID 15)
09:20:52.026 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 10.0 in stage 1.0 (TID 11) in 62 ms on localhost (executor driver) (12/200)
09:20:52.026 INFO  [Executor task launch worker for task 15] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=14), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/14] for update
09:20:52.026 INFO  [Executor task launch worker for task 15] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=14), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/14] for update
09:20:52.026 INFO  [Executor task launch worker for task 15] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.026 INFO  [Executor task launch worker for task 15] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.026 INFO  [Executor task launch worker for task 13] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=12),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/12]
09:20:52.042 INFO  [Executor task launch worker for task 13] org.apache.spark.executor.Executor - Finished task 12.0 in stage 1.0 (TID 13). 3451 bytes result sent to driver
09:20:52.042 INFO  [Executor task launch worker for task 14] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=13),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/13]
09:20:52.042 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 15.0 in stage 1.0 (TID 16, localhost, executor driver, partition 15, PROCESS_LOCAL, 4726 bytes)
09:20:52.042 INFO  [Executor task launch worker for task 16] org.apache.spark.executor.Executor - Running task 15.0 in stage 1.0 (TID 16)
09:20:52.042 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 12.0 in stage 1.0 (TID 13) in 62 ms on localhost (executor driver) (13/200)
09:20:52.042 INFO  [Executor task launch worker for task 14] org.apache.spark.executor.Executor - Finished task 13.0 in stage 1.0 (TID 14). 3365 bytes result sent to driver
09:20:52.042 INFO  [Executor task launch worker for task 16] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=15), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/15] for update
09:20:52.042 INFO  [Executor task launch worker for task 16] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=15), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/15] for update
09:20:52.042 INFO  [Executor task launch worker for task 16] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.042 INFO  [Executor task launch worker for task 16] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.042 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 16.0 in stage 1.0 (TID 17, localhost, executor driver, partition 16, PROCESS_LOCAL, 4726 bytes)
09:20:52.042 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 13.0 in stage 1.0 (TID 14) in 47 ms on localhost (executor driver) (14/200)
09:20:52.058 INFO  [Executor task launch worker for task 15] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=14),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/14] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/14/1.delta
09:20:52.058 INFO  [Executor task launch worker for task 16] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=15),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/15] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/15/1.delta
09:20:52.058 INFO  [Executor task launch worker for task 17] org.apache.spark.executor.Executor - Running task 16.0 in stage 1.0 (TID 17)
09:20:52.058 INFO  [Executor task launch worker for task 17] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=16), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/16] for update
09:20:52.058 INFO  [Executor task launch worker for task 17] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=16), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/16] for update
09:20:52.058 INFO  [Executor task launch worker for task 17] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.058 INFO  [Executor task launch worker for task 17] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.136 INFO  [Executor task launch worker for task 15] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=14),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/14]
09:20:52.136 INFO  [Executor task launch worker for task 15] org.apache.spark.executor.Executor - Finished task 14.0 in stage 1.0 (TID 15). 3322 bytes result sent to driver
09:20:52.136 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 17.0 in stage 1.0 (TID 18, localhost, executor driver, partition 17, PROCESS_LOCAL, 4726 bytes)
09:20:52.136 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 14.0 in stage 1.0 (TID 15) in 125 ms on localhost (executor driver) (15/200)
09:20:52.136 INFO  [Executor task launch worker for task 16] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=15),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/15]
09:20:52.151 INFO  [Executor task launch worker for task 18] org.apache.spark.executor.Executor - Running task 17.0 in stage 1.0 (TID 18)
09:20:52.151 INFO  [Executor task launch worker for task 16] org.apache.spark.executor.Executor - Finished task 15.0 in stage 1.0 (TID 16). 3365 bytes result sent to driver
09:20:52.151 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 18.0 in stage 1.0 (TID 19, localhost, executor driver, partition 18, PROCESS_LOCAL, 4726 bytes)
09:20:52.151 INFO  [Executor task launch worker for task 19] org.apache.spark.executor.Executor - Running task 18.0 in stage 1.0 (TID 19)
09:20:52.151 INFO  [Executor task launch worker for task 18] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=17), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/17] for update
09:20:52.151 INFO  [Executor task launch worker for task 18] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=17), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/17] for update
09:20:52.151 INFO  [Executor task launch worker for task 18] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.151 INFO  [Executor task launch worker for task 18] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.151 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 15.0 in stage 1.0 (TID 16) in 109 ms on localhost (executor driver) (16/200)
09:20:52.167 INFO  [Executor task launch worker for task 19] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=18), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/18] for update
09:20:52.167 INFO  [Executor task launch worker for task 17] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=16),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/16] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/16/1.delta
09:20:52.167 INFO  [Executor task launch worker for task 19] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=18), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/18] for update
09:20:52.167 INFO  [Executor task launch worker for task 19] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.167 INFO  [Executor task launch worker for task 19] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.167 INFO  [Executor task launch worker for task 18] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=17),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/17] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/17/1.delta
09:20:52.183 INFO  [Executor task launch worker for task 18] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=17),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/17]
09:20:52.183 INFO  [Executor task launch worker for task 18] org.apache.spark.executor.Executor - Finished task 17.0 in stage 1.0 (TID 18). 3365 bytes result sent to driver
09:20:52.183 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 19.0 in stage 1.0 (TID 20, localhost, executor driver, partition 19, PROCESS_LOCAL, 4726 bytes)
09:20:52.183 INFO  [Executor task launch worker for task 17] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=16),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/16]
09:20:52.183 INFO  [Executor task launch worker for task 17] org.apache.spark.executor.Executor - Finished task 16.0 in stage 1.0 (TID 17). 3365 bytes result sent to driver
09:20:52.183 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 20.0 in stage 1.0 (TID 21, localhost, executor driver, partition 20, PROCESS_LOCAL, 4726 bytes)
09:20:52.198 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 16.0 in stage 1.0 (TID 17) in 156 ms on localhost (executor driver) (17/200)
09:20:52.198 INFO  [Executor task launch worker for task 20] org.apache.spark.executor.Executor - Running task 19.0 in stage 1.0 (TID 20)
09:20:52.198 INFO  [Executor task launch worker for task 21] org.apache.spark.executor.Executor - Running task 20.0 in stage 1.0 (TID 21)
09:20:52.198 INFO  [Executor task launch worker for task 20] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=19), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/19] for update
09:20:52.198 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 17.0 in stage 1.0 (TID 18) in 62 ms on localhost (executor driver) (18/200)
09:20:52.198 INFO  [Executor task launch worker for task 21] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=20), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/20] for update
09:20:52.198 INFO  [Executor task launch worker for task 20] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=19), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/19] for update
09:20:52.198 INFO  [Executor task launch worker for task 21] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=20), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/20] for update
09:20:52.198 INFO  [Executor task launch worker for task 20] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.198 INFO  [Executor task launch worker for task 21] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.198 INFO  [Executor task launch worker for task 20] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.198 INFO  [Executor task launch worker for task 21] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.214 INFO  [Executor task launch worker for task 19] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=18),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/18] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/18/1.delta
09:20:52.245 INFO  [Executor task launch worker for task 19] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=18),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/18]
09:20:52.245 INFO  [Executor task launch worker for task 21] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=20),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/20] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/20/1.delta
09:20:52.261 INFO  [Executor task launch worker for task 21] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=20),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/20]
09:20:52.261 INFO  [Executor task launch worker for task 21] org.apache.spark.executor.Executor - Finished task 20.0 in stage 1.0 (TID 21). 3365 bytes result sent to driver
09:20:52.261 INFO  [Executor task launch worker for task 20] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=19),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/19] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/19/1.delta
09:20:52.261 INFO  [Executor task launch worker for task 20] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=19),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/19]
09:20:52.261 INFO  [Executor task launch worker for task 20] org.apache.spark.executor.Executor - Finished task 19.0 in stage 1.0 (TID 20). 3365 bytes result sent to driver
09:20:52.261 INFO  [Executor task launch worker for task 19] org.apache.spark.executor.Executor - Finished task 18.0 in stage 1.0 (TID 19). 3365 bytes result sent to driver
09:20:52.261 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 21.0 in stage 1.0 (TID 22, localhost, executor driver, partition 21, PROCESS_LOCAL, 4726 bytes)
09:20:52.276 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 22.0 in stage 1.0 (TID 23, localhost, executor driver, partition 22, PROCESS_LOCAL, 4726 bytes)
09:20:52.276 INFO  [Executor task launch worker for task 23] org.apache.spark.executor.Executor - Running task 22.0 in stage 1.0 (TID 23)
09:20:52.276 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 23.0 in stage 1.0 (TID 24, localhost, executor driver, partition 23, PROCESS_LOCAL, 4726 bytes)
09:20:52.276 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 19.0 in stage 1.0 (TID 20) in 93 ms on localhost (executor driver) (19/200)
09:20:52.276 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 20.0 in stage 1.0 (TID 21) in 93 ms on localhost (executor driver) (20/200)
09:20:52.276 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 18.0 in stage 1.0 (TID 19) in 125 ms on localhost (executor driver) (21/200)
09:20:52.276 INFO  [Executor task launch worker for task 23] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=22), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/22] for update
09:20:52.276 INFO  [Executor task launch worker for task 23] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=22), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/22] for update
09:20:52.276 INFO  [Executor task launch worker for task 23] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.276 INFO  [Executor task launch worker for task 23] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.276 INFO  [Executor task launch worker for task 22] org.apache.spark.executor.Executor - Running task 21.0 in stage 1.0 (TID 22)
09:20:52.276 INFO  [Executor task launch worker for task 24] org.apache.spark.executor.Executor - Running task 23.0 in stage 1.0 (TID 24)
09:20:52.292 INFO  [Executor task launch worker for task 24] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=23), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/23] for update
09:20:52.308 INFO  [Executor task launch worker for task 22] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=21), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/21] for update
09:20:52.308 INFO  [Executor task launch worker for task 22] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=21), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/21] for update
09:20:52.308 INFO  [Executor task launch worker for task 22] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.308 INFO  [Executor task launch worker for task 22] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.308 INFO  [Executor task launch worker for task 23] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=22),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/22] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/22/1.delta
09:20:52.323 INFO  [Executor task launch worker for task 24] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=23), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/23] for update
09:20:52.323 INFO  [Executor task launch worker for task 24] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.323 INFO  [Executor task launch worker for task 24] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.356 INFO  [Executor task launch worker for task 22] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=21),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/21] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/21/1.delta
09:20:52.356 INFO  [Executor task launch worker for task 23] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=22),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/22]
09:20:52.356 INFO  [Executor task launch worker for task 24] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=23),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/23] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/23/1.delta
09:20:52.356 INFO  [Executor task launch worker for task 23] org.apache.spark.executor.Executor - Finished task 22.0 in stage 1.0 (TID 23). 3408 bytes result sent to driver
09:20:52.356 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 24.0 in stage 1.0 (TID 25, localhost, executor driver, partition 24, PROCESS_LOCAL, 4726 bytes)
09:20:52.356 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 22.0 in stage 1.0 (TID 23) in 80 ms on localhost (executor driver) (22/200)
09:20:52.356 INFO  [Executor task launch worker for task 25] org.apache.spark.executor.Executor - Running task 24.0 in stage 1.0 (TID 25)
09:20:52.371 INFO  [Executor task launch worker for task 24] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=23),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/23]
09:20:52.559 INFO  [Executor task launch worker for task 25] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=24), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/24] for update
09:20:52.371 INFO  [Executor task launch worker for task 22] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=21),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/21]
09:20:52.559 INFO  [Executor task launch worker for task 24] org.apache.spark.executor.Executor - Finished task 23.0 in stage 1.0 (TID 24). 3408 bytes result sent to driver
09:20:52.559 INFO  [Executor task launch worker for task 25] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=24), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/24] for update
09:20:52.559 INFO  [Executor task launch worker for task 25] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.559 INFO  [Executor task launch worker for task 25] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.559 INFO  [Executor task launch worker for task 22] org.apache.spark.executor.Executor - Finished task 21.0 in stage 1.0 (TID 22). 3408 bytes result sent to driver
09:20:52.559 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 25.0 in stage 1.0 (TID 26, localhost, executor driver, partition 25, PROCESS_LOCAL, 4726 bytes)
09:20:52.559 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 23.0 in stage 1.0 (TID 24) in 283 ms on localhost (executor driver) (23/200)
09:20:52.559 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 26.0 in stage 1.0 (TID 27, localhost, executor driver, partition 26, PROCESS_LOCAL, 4726 bytes)
09:20:52.559 INFO  [Executor task launch worker for task 26] org.apache.spark.executor.Executor - Running task 25.0 in stage 1.0 (TID 26)
09:20:52.574 INFO  [Executor task launch worker for task 25] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=24),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/24] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/24/1.delta
09:20:52.574 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 21.0 in stage 1.0 (TID 22) in 313 ms on localhost (executor driver) (24/200)
09:20:52.574 INFO  [Executor task launch worker for task 25] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=24),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/24]
09:20:52.574 INFO  [Executor task launch worker for task 27] org.apache.spark.executor.Executor - Running task 26.0 in stage 1.0 (TID 27)
09:20:52.574 INFO  [Executor task launch worker for task 25] org.apache.spark.executor.Executor - Finished task 24.0 in stage 1.0 (TID 25). 3365 bytes result sent to driver
09:20:52.574 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 27.0 in stage 1.0 (TID 28, localhost, executor driver, partition 27, PROCESS_LOCAL, 4726 bytes)
09:20:52.574 INFO  [Executor task launch worker for task 28] org.apache.spark.executor.Executor - Running task 27.0 in stage 1.0 (TID 28)
09:20:52.590 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 24.0 in stage 1.0 (TID 25) in 234 ms on localhost (executor driver) (25/200)
09:20:52.590 INFO  [Executor task launch worker for task 27] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=26), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/26] for update
09:20:52.590 INFO  [Executor task launch worker for task 26] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=25), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/25] for update
09:20:52.590 INFO  [Executor task launch worker for task 28] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=27), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/27] for update
09:20:52.590 INFO  [Executor task launch worker for task 26] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=25), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/25] for update
09:20:52.590 INFO  [Executor task launch worker for task 27] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=26), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/26] for update
09:20:52.590 INFO  [Executor task launch worker for task 28] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=27), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/27] for update
09:20:52.590 INFO  [Executor task launch worker for task 26] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.590 INFO  [Executor task launch worker for task 26] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.590 INFO  [Executor task launch worker for task 27] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.590 INFO  [Executor task launch worker for task 28] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.590 INFO  [Executor task launch worker for task 27] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.590 INFO  [Executor task launch worker for task 28] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.606 INFO  [Executor task launch worker for task 28] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=27),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/27] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/27/1.delta
09:20:52.606 INFO  [Executor task launch worker for task 27] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=26),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/26] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/26/1.delta
09:20:52.606 INFO  [Executor task launch worker for task 28] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=27),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/27]
09:20:52.606 INFO  [Executor task launch worker for task 28] org.apache.spark.executor.Executor - Finished task 27.0 in stage 1.0 (TID 28). 3451 bytes result sent to driver
09:20:52.606 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 28.0 in stage 1.0 (TID 29, localhost, executor driver, partition 28, PROCESS_LOCAL, 4726 bytes)
09:20:52.606 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 27.0 in stage 1.0 (TID 28) in 32 ms on localhost (executor driver) (26/200)
09:20:52.606 INFO  [Executor task launch worker for task 29] org.apache.spark.executor.Executor - Running task 28.0 in stage 1.0 (TID 29)
09:20:52.606 INFO  [Executor task launch worker for task 27] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=26),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/26]
09:20:52.606 INFO  [Executor task launch worker for task 27] org.apache.spark.executor.Executor - Finished task 26.0 in stage 1.0 (TID 27). 3408 bytes result sent to driver
09:20:52.606 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 29.0 in stage 1.0 (TID 30, localhost, executor driver, partition 29, PROCESS_LOCAL, 4726 bytes)
09:20:52.621 INFO  [Executor task launch worker for task 30] org.apache.spark.executor.Executor - Running task 29.0 in stage 1.0 (TID 30)
09:20:52.621 INFO  [Executor task launch worker for task 29] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=28), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/28] for update
09:20:52.621 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 26.0 in stage 1.0 (TID 27) in 62 ms on localhost (executor driver) (27/200)
09:20:52.621 INFO  [Executor task launch worker for task 29] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=28), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/28] for update
09:20:52.621 INFO  [Executor task launch worker for task 29] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.621 INFO  [Executor task launch worker for task 29] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.621 INFO  [Executor task launch worker for task 30] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=29), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/29] for update
09:20:52.621 INFO  [Executor task launch worker for task 30] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=29), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/29] for update
09:20:52.621 INFO  [Executor task launch worker for task 30] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.621 INFO  [Executor task launch worker for task 30] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.621 INFO  [Executor task launch worker for task 29] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=28),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/28] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/28/1.delta
09:20:52.621 INFO  [Executor task launch worker for task 26] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=25),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/25] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/25/1.delta
09:20:52.621 INFO  [Executor task launch worker for task 30] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=29),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/29] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/29/1.delta
09:20:52.637 INFO  [Executor task launch worker for task 29] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=28),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/28]
09:20:52.637 INFO  [Executor task launch worker for task 29] org.apache.spark.executor.Executor - Finished task 28.0 in stage 1.0 (TID 29). 3365 bytes result sent to driver
09:20:52.637 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 30.0 in stage 1.0 (TID 31, localhost, executor driver, partition 30, PROCESS_LOCAL, 4726 bytes)
09:20:52.637 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 28.0 in stage 1.0 (TID 29) in 31 ms on localhost (executor driver) (28/200)
09:20:52.637 INFO  [Executor task launch worker for task 30] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=29),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/29]
09:20:52.637 INFO  [Executor task launch worker for task 30] org.apache.spark.executor.Executor - Finished task 29.0 in stage 1.0 (TID 30). 3365 bytes result sent to driver
09:20:52.637 INFO  [Executor task launch worker for task 31] org.apache.spark.executor.Executor - Running task 30.0 in stage 1.0 (TID 31)
09:20:52.637 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 31.0 in stage 1.0 (TID 32, localhost, executor driver, partition 31, PROCESS_LOCAL, 4726 bytes)
09:20:52.637 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 29.0 in stage 1.0 (TID 30) in 31 ms on localhost (executor driver) (29/200)
09:20:52.637 INFO  [Executor task launch worker for task 32] org.apache.spark.executor.Executor - Running task 31.0 in stage 1.0 (TID 32)
09:20:52.637 INFO  [Executor task launch worker for task 31] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=30), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/30] for update
09:20:52.637 INFO  [Executor task launch worker for task 31] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=30), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/30] for update
09:20:52.637 INFO  [Executor task launch worker for task 31] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.637 INFO  [Executor task launch worker for task 31] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.652 INFO  [Executor task launch worker for task 26] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=25),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/25]
09:20:52.652 INFO  [Executor task launch worker for task 32] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=31), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/31] for update
09:20:52.652 INFO  [Executor task launch worker for task 32] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=31), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/31] for update
09:20:52.652 INFO  [Executor task launch worker for task 26] org.apache.spark.executor.Executor - Finished task 25.0 in stage 1.0 (TID 26). 3451 bytes result sent to driver
09:20:52.652 INFO  [Executor task launch worker for task 32] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.652 INFO  [Executor task launch worker for task 32] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.652 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 32.0 in stage 1.0 (TID 33, localhost, executor driver, partition 32, PROCESS_LOCAL, 4726 bytes)
09:20:52.652 INFO  [Executor task launch worker for task 33] org.apache.spark.executor.Executor - Running task 32.0 in stage 1.0 (TID 33)
09:20:52.652 INFO  [Executor task launch worker for task 31] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=30),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/30] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/30/1.delta
09:20:52.652 INFO  [Executor task launch worker for task 33] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=32), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/32] for update
09:20:52.652 INFO  [Executor task launch worker for task 33] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=32), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/32] for update
09:20:52.652 INFO  [Executor task launch worker for task 33] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.652 INFO  [Executor task launch worker for task 33] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.652 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 25.0 in stage 1.0 (TID 26) in 93 ms on localhost (executor driver) (30/200)
09:20:52.668 INFO  [Executor task launch worker for task 32] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=31),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/31] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/31/1.delta
09:20:52.668 INFO  [Executor task launch worker for task 31] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=30),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/30]
09:20:52.668 INFO  [Executor task launch worker for task 31] org.apache.spark.executor.Executor - Finished task 30.0 in stage 1.0 (TID 31). 3365 bytes result sent to driver
09:20:52.668 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 33.0 in stage 1.0 (TID 34, localhost, executor driver, partition 33, PROCESS_LOCAL, 4726 bytes)
09:20:52.668 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 30.0 in stage 1.0 (TID 31) in 31 ms on localhost (executor driver) (31/200)
09:20:52.668 INFO  [Executor task launch worker for task 34] org.apache.spark.executor.Executor - Running task 33.0 in stage 1.0 (TID 34)
09:20:52.684 INFO  [Executor task launch worker for task 34] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=33), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/33] for update
09:20:52.684 INFO  [Executor task launch worker for task 34] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=33), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/33] for update
09:20:52.684 INFO  [Executor task launch worker for task 34] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.684 INFO  [Executor task launch worker for task 34] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.684 INFO  [Executor task launch worker for task 33] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=32),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/32] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/32/1.delta
09:20:52.684 INFO  [Executor task launch worker for task 33] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=32),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/32]
09:20:52.684 INFO  [Executor task launch worker for task 33] org.apache.spark.executor.Executor - Finished task 32.0 in stage 1.0 (TID 33). 3365 bytes result sent to driver
09:20:52.684 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 34.0 in stage 1.0 (TID 35, localhost, executor driver, partition 34, PROCESS_LOCAL, 4726 bytes)
09:20:52.684 INFO  [Executor task launch worker for task 34] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=33),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/33] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/33/1.delta
09:20:52.684 INFO  [Executor task launch worker for task 35] org.apache.spark.executor.Executor - Running task 34.0 in stage 1.0 (TID 35)
09:20:52.684 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 32.0 in stage 1.0 (TID 33) in 32 ms on localhost (executor driver) (32/200)
09:20:52.699 INFO  [Executor task launch worker for task 32] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=31),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/31]
09:20:52.699 INFO  [Executor task launch worker for task 32] org.apache.spark.executor.Executor - Finished task 31.0 in stage 1.0 (TID 32). 3365 bytes result sent to driver
09:20:52.699 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 35.0 in stage 1.0 (TID 36, localhost, executor driver, partition 35, PROCESS_LOCAL, 4726 bytes)
09:20:52.699 INFO  [Executor task launch worker for task 36] org.apache.spark.executor.Executor - Running task 35.0 in stage 1.0 (TID 36)
09:20:52.699 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 31.0 in stage 1.0 (TID 32) in 62 ms on localhost (executor driver) (33/200)
09:20:52.699 INFO  [Executor task launch worker for task 34] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=33),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/33]
09:20:52.699 INFO  [Executor task launch worker for task 34] org.apache.spark.executor.Executor - Finished task 33.0 in stage 1.0 (TID 34). 3451 bytes result sent to driver
09:20:52.699 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 36.0 in stage 1.0 (TID 37, localhost, executor driver, partition 36, PROCESS_LOCAL, 4726 bytes)
09:20:52.699 INFO  [Executor task launch worker for task 37] org.apache.spark.executor.Executor - Running task 36.0 in stage 1.0 (TID 37)
09:20:52.699 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 33.0 in stage 1.0 (TID 34) in 31 ms on localhost (executor driver) (34/200)
09:20:52.699 INFO  [Executor task launch worker for task 36] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=35), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/35] for update
09:20:52.699 INFO  [Executor task launch worker for task 36] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=35), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/35] for update
09:20:52.699 INFO  [Executor task launch worker for task 36] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.699 INFO  [Executor task launch worker for task 36] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.699 INFO  [Executor task launch worker for task 37] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=36), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/36] for update
09:20:52.699 INFO  [Executor task launch worker for task 37] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=36), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/36] for update
09:20:52.699 INFO  [Executor task launch worker for task 37] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.699 INFO  [Executor task launch worker for task 35] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=34), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/34] for update
09:20:52.715 INFO  [Executor task launch worker for task 37] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 16 ms
09:20:52.715 INFO  [Executor task launch worker for task 36] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=35),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/35] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/35/1.delta
09:20:52.715 INFO  [Executor task launch worker for task 35] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=34), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/34] for update
09:20:52.715 INFO  [Executor task launch worker for task 35] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.715 INFO  [Executor task launch worker for task 35] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.715 INFO  [Executor task launch worker for task 36] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=35),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/35]
09:20:52.715 INFO  [Executor task launch worker for task 37] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=36),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/36] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/36/1.delta
09:20:52.729 INFO  [Executor task launch worker for task 36] org.apache.spark.executor.Executor - Finished task 35.0 in stage 1.0 (TID 36). 3365 bytes result sent to driver
09:20:52.730 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 37.0 in stage 1.0 (TID 38, localhost, executor driver, partition 37, PROCESS_LOCAL, 4726 bytes)
09:20:52.732 INFO  [Executor task launch worker for task 38] org.apache.spark.executor.Executor - Running task 37.0 in stage 1.0 (TID 38)
09:20:52.733 INFO  [Executor task launch worker for task 37] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=36),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/36]
09:20:52.733 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 35.0 in stage 1.0 (TID 36) in 34 ms on localhost (executor driver) (35/200)
09:20:52.733 INFO  [Executor task launch worker for task 37] org.apache.spark.executor.Executor - Finished task 36.0 in stage 1.0 (TID 37). 3322 bytes result sent to driver
09:20:52.734 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 38.0 in stage 1.0 (TID 39, localhost, executor driver, partition 38, PROCESS_LOCAL, 4726 bytes)
09:20:52.734 INFO  [Executor task launch worker for task 39] org.apache.spark.executor.Executor - Running task 38.0 in stage 1.0 (TID 39)
09:20:52.736 INFO  [Executor task launch worker for task 38] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=37), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/37] for update
09:20:52.736 INFO  [Executor task launch worker for task 38] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=37), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/37] for update
09:20:52.736 INFO  [Executor task launch worker for task 38] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.736 INFO  [Executor task launch worker for task 38] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.738 INFO  [Executor task launch worker for task 39] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=38), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/38] for update
09:20:52.738 INFO  [Executor task launch worker for task 39] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=38), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/38] for update
09:20:52.739 INFO  [Executor task launch worker for task 39] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.739 INFO  [Executor task launch worker for task 39] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.743 INFO  [Executor task launch worker for task 35] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=34),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/34] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/34/1.delta
09:20:52.743 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 36.0 in stage 1.0 (TID 37) in 44 ms on localhost (executor driver) (36/200)
09:20:52.749 INFO  [Executor task launch worker for task 38] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=37),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/37] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/37/1.delta
09:20:52.753 INFO  [Executor task launch worker for task 39] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=38),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/38] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/38/1.delta
09:20:52.754 INFO  [Executor task launch worker for task 38] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=37),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/37]
09:20:52.755 INFO  [Executor task launch worker for task 38] org.apache.spark.executor.Executor - Finished task 37.0 in stage 1.0 (TID 38). 3408 bytes result sent to driver
09:20:52.757 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 39.0 in stage 1.0 (TID 40, localhost, executor driver, partition 39, PROCESS_LOCAL, 4726 bytes)
09:20:52.757 INFO  [Executor task launch worker for task 40] org.apache.spark.executor.Executor - Running task 39.0 in stage 1.0 (TID 40)
09:20:52.757 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 37.0 in stage 1.0 (TID 38) in 27 ms on localhost (executor driver) (37/200)
09:20:52.759 INFO  [Executor task launch worker for task 35] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=34),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/34]
09:20:52.760 INFO  [Executor task launch worker for task 39] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=38),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/38]
09:20:52.760 INFO  [Executor task launch worker for task 39] org.apache.spark.executor.Executor - Finished task 38.0 in stage 1.0 (TID 39). 3451 bytes result sent to driver
09:20:52.761 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 40.0 in stage 1.0 (TID 41, localhost, executor driver, partition 40, PROCESS_LOCAL, 4726 bytes)
09:20:52.761 INFO  [Executor task launch worker for task 35] org.apache.spark.executor.Executor - Finished task 34.0 in stage 1.0 (TID 35). 3365 bytes result sent to driver
09:20:52.761 INFO  [Executor task launch worker for task 40] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=39), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/39] for update
09:20:52.762 INFO  [Executor task launch worker for task 40] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=39), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/39] for update
09:20:52.763 INFO  [Executor task launch worker for task 40] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.763 INFO  [Executor task launch worker for task 40] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.762 INFO  [Executor task launch worker for task 41] org.apache.spark.executor.Executor - Running task 40.0 in stage 1.0 (TID 41)
09:20:52.762 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 41.0 in stage 1.0 (TID 42, localhost, executor driver, partition 41, PROCESS_LOCAL, 4726 bytes)
09:20:52.763 INFO  [Executor task launch worker for task 42] org.apache.spark.executor.Executor - Running task 41.0 in stage 1.0 (TID 42)
09:20:52.765 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 34.0 in stage 1.0 (TID 35) in 81 ms on localhost (executor driver) (38/200)
09:20:52.766 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 38.0 in stage 1.0 (TID 39) in 32 ms on localhost (executor driver) (39/200)
09:20:52.766 INFO  [Executor task launch worker for task 41] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=40), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/40] for update
09:20:52.768 INFO  [Executor task launch worker for task 42] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=41), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/41] for update
09:20:52.768 INFO  [Executor task launch worker for task 41] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=40), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/40] for update
09:20:52.769 INFO  [Executor task launch worker for task 42] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=41), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/41] for update
09:20:52.769 INFO  [Executor task launch worker for task 41] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.769 INFO  [Executor task launch worker for task 41] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.769 INFO  [Executor task launch worker for task 42] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.769 INFO  [Executor task launch worker for task 42] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.774 INFO  [Executor task launch worker for task 40] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=39),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/39] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/39/1.delta
09:20:52.777 INFO  [Executor task launch worker for task 41] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=40),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/40] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/40/1.delta
09:20:52.780 INFO  [Executor task launch worker for task 40] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=39),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/39]
09:20:52.781 INFO  [Executor task launch worker for task 40] org.apache.spark.executor.Executor - Finished task 39.0 in stage 1.0 (TID 40). 3408 bytes result sent to driver
09:20:52.783 INFO  [Executor task launch worker for task 41] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=40),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/40]
09:20:52.783 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 42.0 in stage 1.0 (TID 43, localhost, executor driver, partition 42, PROCESS_LOCAL, 4726 bytes)
09:20:52.783 INFO  [Executor task launch worker for task 41] org.apache.spark.executor.Executor - Finished task 40.0 in stage 1.0 (TID 41). 3408 bytes result sent to driver
09:20:52.783 INFO  [Executor task launch worker for task 43] org.apache.spark.executor.Executor - Running task 42.0 in stage 1.0 (TID 43)
09:20:52.784 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 43.0 in stage 1.0 (TID 44, localhost, executor driver, partition 43, PROCESS_LOCAL, 4726 bytes)
09:20:52.784 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 39.0 in stage 1.0 (TID 40) in 27 ms on localhost (executor driver) (40/200)
09:20:52.784 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 40.0 in stage 1.0 (TID 41) in 23 ms on localhost (executor driver) (41/200)
09:20:52.784 INFO  [Executor task launch worker for task 44] org.apache.spark.executor.Executor - Running task 43.0 in stage 1.0 (TID 44)
09:20:52.797 INFO  [Executor task launch worker for task 44] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=43), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/43] for update
09:20:52.798 INFO  [Executor task launch worker for task 44] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=43), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/43] for update
09:20:52.798 INFO  [Executor task launch worker for task 44] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.798 INFO  [Executor task launch worker for task 44] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.800 INFO  [Executor task launch worker for task 43] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=42), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/42] for update
09:20:52.801 INFO  [Executor task launch worker for task 43] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=42), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/42] for update
09:20:52.801 INFO  [Executor task launch worker for task 43] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.801 INFO  [Executor task launch worker for task 43] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.806 INFO  [Executor task launch worker for task 44] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=43),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/43] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/43/1.delta
09:20:52.818 INFO  [Executor task launch worker for task 43] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=42),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/42] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/42/1.delta
09:20:52.827 INFO  [Executor task launch worker for task 44] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=43),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/43]
09:20:52.828 INFO  [Executor task launch worker for task 44] org.apache.spark.executor.Executor - Finished task 43.0 in stage 1.0 (TID 44). 3408 bytes result sent to driver
09:20:52.829 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 44.0 in stage 1.0 (TID 45, localhost, executor driver, partition 44, PROCESS_LOCAL, 4726 bytes)
09:20:52.829 INFO  [Executor task launch worker for task 43] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=42),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/42]
09:20:52.829 INFO  [Executor task launch worker for task 45] org.apache.spark.executor.Executor - Running task 44.0 in stage 1.0 (TID 45)
09:20:52.830 INFO  [Executor task launch worker for task 43] org.apache.spark.executor.Executor - Finished task 42.0 in stage 1.0 (TID 43). 3451 bytes result sent to driver
09:20:52.831 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 45.0 in stage 1.0 (TID 46, localhost, executor driver, partition 45, PROCESS_LOCAL, 4726 bytes)
09:20:52.832 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 43.0 in stage 1.0 (TID 44) in 48 ms on localhost (executor driver) (42/200)
09:20:52.832 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 42.0 in stage 1.0 (TID 43) in 49 ms on localhost (executor driver) (43/200)
09:20:52.833 INFO  [Executor task launch worker for task 45] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=44), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/44] for update
09:20:52.833 INFO  [Executor task launch worker for task 45] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=44), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/44] for update
09:20:52.833 INFO  [Executor task launch worker for task 45] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.833 INFO  [Executor task launch worker for task 46] org.apache.spark.executor.Executor - Running task 45.0 in stage 1.0 (TID 46)
09:20:52.833 INFO  [Executor task launch worker for task 45] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.838 INFO  [Executor task launch worker for task 46] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=45), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/45] for update
09:20:52.838 INFO  [Executor task launch worker for task 46] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=45), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/45] for update
09:20:52.838 INFO  [Executor task launch worker for task 46] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.838 INFO  [Executor task launch worker for task 46] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.838 INFO  [Executor task launch worker for task 42] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=41),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/41] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/41/1.delta
09:20:52.843 INFO  [Executor task launch worker for task 45] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=44),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/44] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/44/1.delta
09:20:52.846 INFO  [Executor task launch worker for task 46] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=45),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/45] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/45/1.delta
09:20:52.847 INFO  [Executor task launch worker for task 42] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=41),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/41]
09:20:52.849 INFO  [Executor task launch worker for task 42] org.apache.spark.executor.Executor - Finished task 41.0 in stage 1.0 (TID 42). 3408 bytes result sent to driver
09:20:52.849 INFO  [Executor task launch worker for task 45] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=44),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/44]
09:20:52.850 INFO  [Executor task launch worker for task 45] org.apache.spark.executor.Executor - Finished task 44.0 in stage 1.0 (TID 45). 3494 bytes result sent to driver
09:20:52.850 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 46.0 in stage 1.0 (TID 47, localhost, executor driver, partition 46, PROCESS_LOCAL, 4726 bytes)
09:20:52.850 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 47.0 in stage 1.0 (TID 48, localhost, executor driver, partition 47, PROCESS_LOCAL, 4726 bytes)
09:20:52.850 INFO  [Executor task launch worker for task 48] org.apache.spark.executor.Executor - Running task 47.0 in stage 1.0 (TID 48)
09:20:52.850 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 41.0 in stage 1.0 (TID 42) in 88 ms on localhost (executor driver) (44/200)
09:20:52.850 INFO  [Executor task launch worker for task 47] org.apache.spark.executor.Executor - Running task 46.0 in stage 1.0 (TID 47)
09:20:52.850 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 44.0 in stage 1.0 (TID 45) in 21 ms on localhost (executor driver) (45/200)
09:20:52.850 INFO  [Executor task launch worker for task 47] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=46), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/46] for update
09:20:52.850 INFO  [Executor task launch worker for task 48] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=47), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/47] for update
09:20:52.850 INFO  [Executor task launch worker for task 47] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=46), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/46] for update
09:20:52.850 INFO  [Executor task launch worker for task 48] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=47), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/47] for update
09:20:52.850 INFO  [Executor task launch worker for task 47] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.850 INFO  [Executor task launch worker for task 48] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.850 INFO  [Executor task launch worker for task 46] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=45),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/45]
09:20:52.866 INFO  [Executor task launch worker for task 47] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 16 ms
09:20:52.866 INFO  [Executor task launch worker for task 48] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 16 ms
09:20:52.866 INFO  [Executor task launch worker for task 46] org.apache.spark.executor.Executor - Finished task 45.0 in stage 1.0 (TID 46). 3408 bytes result sent to driver
09:20:52.866 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 48.0 in stage 1.0 (TID 49, localhost, executor driver, partition 48, PROCESS_LOCAL, 4726 bytes)
09:20:52.866 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 45.0 in stage 1.0 (TID 46) in 35 ms on localhost (executor driver) (46/200)
09:20:52.866 INFO  [Executor task launch worker for task 49] org.apache.spark.executor.Executor - Running task 48.0 in stage 1.0 (TID 49)
09:20:52.866 INFO  [Executor task launch worker for task 49] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=48), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/48] for update
09:20:52.866 INFO  [Executor task launch worker for task 49] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=48), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/48] for update
09:20:52.866 INFO  [Executor task launch worker for task 49] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.866 INFO  [Executor task launch worker for task 49] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.866 INFO  [Executor task launch worker for task 47] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=46),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/46] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/46/1.delta
09:20:52.866 INFO  [Executor task launch worker for task 48] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=47),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/47] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/47/1.delta
09:20:52.866 INFO  [Executor task launch worker for task 47] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=46),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/46]
09:20:52.866 INFO  [Executor task launch worker for task 47] org.apache.spark.executor.Executor - Finished task 46.0 in stage 1.0 (TID 47). 3322 bytes result sent to driver
09:20:52.866 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 49.0 in stage 1.0 (TID 50, localhost, executor driver, partition 49, PROCESS_LOCAL, 4726 bytes)
09:20:52.866 INFO  [Executor task launch worker for task 50] org.apache.spark.executor.Executor - Running task 49.0 in stage 1.0 (TID 50)
09:20:52.866 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 46.0 in stage 1.0 (TID 47) in 16 ms on localhost (executor driver) (47/200)
09:20:52.881 INFO  [Executor task launch worker for task 50] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=49), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/49] for update
09:20:52.881 INFO  [Executor task launch worker for task 50] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=49), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/49] for update
09:20:52.881 INFO  [Executor task launch worker for task 49] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=48),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/48] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/48/1.delta
09:20:52.881 INFO  [Executor task launch worker for task 50] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.881 INFO  [Executor task launch worker for task 50] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.881 INFO  [Executor task launch worker for task 49] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=48),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/48]
09:20:52.881 INFO  [Executor task launch worker for task 50] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=49),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/49] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/49/1.delta
09:20:52.881 INFO  [Executor task launch worker for task 49] org.apache.spark.executor.Executor - Finished task 48.0 in stage 1.0 (TID 49). 3365 bytes result sent to driver
09:20:52.881 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 50.0 in stage 1.0 (TID 51, localhost, executor driver, partition 50, PROCESS_LOCAL, 4726 bytes)
09:20:52.881 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 48.0 in stage 1.0 (TID 49) in 15 ms on localhost (executor driver) (48/200)
09:20:52.881 INFO  [Executor task launch worker for task 51] org.apache.spark.executor.Executor - Running task 50.0 in stage 1.0 (TID 51)
09:20:52.897 INFO  [Executor task launch worker for task 50] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=49),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/49]
09:20:52.897 INFO  [Executor task launch worker for task 50] org.apache.spark.executor.Executor - Finished task 49.0 in stage 1.0 (TID 50). 3365 bytes result sent to driver
09:20:52.897 INFO  [Executor task launch worker for task 51] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=50), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/50] for update
09:20:52.897 INFO  [Executor task launch worker for task 51] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=50), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/50] for update
09:20:52.897 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 51.0 in stage 1.0 (TID 52, localhost, executor driver, partition 51, PROCESS_LOCAL, 4726 bytes)
09:20:52.897 INFO  [Executor task launch worker for task 51] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.897 INFO  [Executor task launch worker for task 52] org.apache.spark.executor.Executor - Running task 51.0 in stage 1.0 (TID 52)
09:20:52.897 INFO  [Executor task launch worker for task 51] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.897 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 49.0 in stage 1.0 (TID 50) in 31 ms on localhost (executor driver) (49/200)
09:20:52.897 INFO  [Executor task launch worker for task 52] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=51), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/51] for update
09:20:52.897 INFO  [Executor task launch worker for task 52] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=51), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/51] for update
09:20:52.897 INFO  [Executor task launch worker for task 52] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.897 INFO  [Executor task launch worker for task 52] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.897 INFO  [Executor task launch worker for task 51] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=50),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/50] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/50/1.delta
09:20:52.913 INFO  [Executor task launch worker for task 52] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=51),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/51] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/51/1.delta
09:20:52.913 INFO  [Executor task launch worker for task 48] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=47),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/47]
09:20:52.913 INFO  [Executor task launch worker for task 51] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=50),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/50]
09:20:52.913 INFO  [Executor task launch worker for task 51] org.apache.spark.executor.Executor - Finished task 50.0 in stage 1.0 (TID 51). 3408 bytes result sent to driver
09:20:52.913 INFO  [Executor task launch worker for task 48] org.apache.spark.executor.Executor - Finished task 47.0 in stage 1.0 (TID 48). 3365 bytes result sent to driver
09:20:52.913 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 52.0 in stage 1.0 (TID 53, localhost, executor driver, partition 52, PROCESS_LOCAL, 4726 bytes)
09:20:52.913 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 50.0 in stage 1.0 (TID 51) in 32 ms on localhost (executor driver) (50/200)
09:20:52.913 INFO  [Executor task launch worker for task 53] org.apache.spark.executor.Executor - Running task 52.0 in stage 1.0 (TID 53)
09:20:52.913 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 47.0 in stage 1.0 (TID 48) in 63 ms on localhost (executor driver) (51/200)
09:20:52.913 INFO  [Executor task launch worker for task 52] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=51),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/51]
09:20:52.913 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 53.0 in stage 1.0 (TID 54, localhost, executor driver, partition 53, PROCESS_LOCAL, 4726 bytes)
09:20:52.913 INFO  [Executor task launch worker for task 52] org.apache.spark.executor.Executor - Finished task 51.0 in stage 1.0 (TID 52). 3365 bytes result sent to driver
09:20:52.913 INFO  [Executor task launch worker for task 54] org.apache.spark.executor.Executor - Running task 53.0 in stage 1.0 (TID 54)
09:20:52.913 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 54.0 in stage 1.0 (TID 55, localhost, executor driver, partition 54, PROCESS_LOCAL, 4726 bytes)
09:20:52.913 INFO  [Executor task launch worker for task 55] org.apache.spark.executor.Executor - Running task 54.0 in stage 1.0 (TID 55)
09:20:52.928 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 51.0 in stage 1.0 (TID 52) in 31 ms on localhost (executor driver) (52/200)
09:20:52.928 INFO  [Executor task launch worker for task 53] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=52), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/52] for update
09:20:52.928 INFO  [Executor task launch worker for task 55] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=54), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/54] for update
09:20:52.928 INFO  [Executor task launch worker for task 54] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=53), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/53] for update
09:20:52.928 INFO  [Executor task launch worker for task 55] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=54), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/54] for update
09:20:52.928 INFO  [Executor task launch worker for task 53] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=52), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/52] for update
09:20:52.928 INFO  [Executor task launch worker for task 54] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=53), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/53] for update
09:20:52.928 INFO  [Executor task launch worker for task 53] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.928 INFO  [Executor task launch worker for task 55] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.928 INFO  [Executor task launch worker for task 54] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.928 INFO  [Executor task launch worker for task 53] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.928 INFO  [Executor task launch worker for task 55] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.928 INFO  [Executor task launch worker for task 54] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.944 INFO  [Executor task launch worker for task 54] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=53),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/53] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/53/1.delta
09:20:52.944 INFO  [Executor task launch worker for task 53] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=52),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/52] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/52/1.delta
09:20:52.944 INFO  [Executor task launch worker for task 55] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=54),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/54] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/54/1.delta
09:20:52.944 INFO  [Executor task launch worker for task 53] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=52),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/52]
09:20:52.944 INFO  [Executor task launch worker for task 54] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=53),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/53]
09:20:52.944 INFO  [Executor task launch worker for task 53] org.apache.spark.executor.Executor - Finished task 52.0 in stage 1.0 (TID 53). 3451 bytes result sent to driver
09:20:52.944 INFO  [Executor task launch worker for task 54] org.apache.spark.executor.Executor - Finished task 53.0 in stage 1.0 (TID 54). 3494 bytes result sent to driver
09:20:52.944 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 55.0 in stage 1.0 (TID 56, localhost, executor driver, partition 55, PROCESS_LOCAL, 4726 bytes)
09:20:52.944 INFO  [Executor task launch worker for task 55] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=54),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/54]
09:20:52.944 INFO  [Executor task launch worker for task 56] org.apache.spark.executor.Executor - Running task 55.0 in stage 1.0 (TID 56)
09:20:52.944 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 56.0 in stage 1.0 (TID 57, localhost, executor driver, partition 56, PROCESS_LOCAL, 4726 bytes)
09:20:52.944 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 53.0 in stage 1.0 (TID 54) in 31 ms on localhost (executor driver) (53/200)
09:20:52.944 INFO  [Executor task launch worker for task 57] org.apache.spark.executor.Executor - Running task 56.0 in stage 1.0 (TID 57)
09:20:52.944 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 52.0 in stage 1.0 (TID 53) in 31 ms on localhost (executor driver) (54/200)
09:20:52.944 INFO  [Executor task launch worker for task 55] org.apache.spark.executor.Executor - Finished task 54.0 in stage 1.0 (TID 55). 3451 bytes result sent to driver
09:20:52.944 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 57.0 in stage 1.0 (TID 58, localhost, executor driver, partition 57, PROCESS_LOCAL, 4726 bytes)
09:20:52.960 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 54.0 in stage 1.0 (TID 55) in 47 ms on localhost (executor driver) (55/200)
09:20:52.960 INFO  [Executor task launch worker for task 58] org.apache.spark.executor.Executor - Running task 57.0 in stage 1.0 (TID 58)
09:20:52.960 INFO  [Executor task launch worker for task 56] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=55), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/55] for update
09:20:52.960 INFO  [Executor task launch worker for task 56] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=55), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/55] for update
09:20:52.960 INFO  [Executor task launch worker for task 57] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=56), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/56] for update
09:20:52.960 INFO  [Executor task launch worker for task 57] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=56), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/56] for update
09:20:52.960 INFO  [Executor task launch worker for task 56] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.960 INFO  [Executor task launch worker for task 56] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.960 INFO  [Executor task launch worker for task 57] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.960 INFO  [Executor task launch worker for task 57] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.960 INFO  [Executor task launch worker for task 58] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=57), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/57] for update
09:20:52.960 INFO  [Executor task launch worker for task 58] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=57), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/57] for update
09:20:52.960 INFO  [Executor task launch worker for task 58] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.960 INFO  [Executor task launch worker for task 58] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.960 INFO  [Executor task launch worker for task 56] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=55),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/55] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/55/1.delta
09:20:52.960 INFO  [Executor task launch worker for task 58] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=57),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/57] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/57/1.delta
09:20:52.960 INFO  [Executor task launch worker for task 57] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=56),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/56] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/56/1.delta
09:20:52.975 INFO  [Executor task launch worker for task 56] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=55),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/55]
09:20:52.975 INFO  [Executor task launch worker for task 56] org.apache.spark.executor.Executor - Finished task 55.0 in stage 1.0 (TID 56). 3451 bytes result sent to driver
09:20:52.975 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 58.0 in stage 1.0 (TID 59, localhost, executor driver, partition 58, PROCESS_LOCAL, 4726 bytes)
09:20:52.975 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 55.0 in stage 1.0 (TID 56) in 31 ms on localhost (executor driver) (56/200)
09:20:52.975 INFO  [Executor task launch worker for task 59] org.apache.spark.executor.Executor - Running task 58.0 in stage 1.0 (TID 59)
09:20:52.975 INFO  [Executor task launch worker for task 59] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=58), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/58] for update
09:20:52.975 INFO  [Executor task launch worker for task 59] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=58), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/58] for update
09:20:52.975 INFO  [Executor task launch worker for task 59] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.975 INFO  [Executor task launch worker for task 59] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.975 INFO  [Executor task launch worker for task 58] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=57),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/57]
09:20:52.975 INFO  [Executor task launch worker for task 58] org.apache.spark.executor.Executor - Finished task 57.0 in stage 1.0 (TID 58). 3322 bytes result sent to driver
09:20:52.975 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 59.0 in stage 1.0 (TID 60, localhost, executor driver, partition 59, PROCESS_LOCAL, 4726 bytes)
09:20:52.975 INFO  [Executor task launch worker for task 60] org.apache.spark.executor.Executor - Running task 59.0 in stage 1.0 (TID 60)
09:20:52.975 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 57.0 in stage 1.0 (TID 58) in 31 ms on localhost (executor driver) (57/200)
09:20:52.975 INFO  [Executor task launch worker for task 57] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=56),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/56]
09:20:52.975 INFO  [Executor task launch worker for task 57] org.apache.spark.executor.Executor - Finished task 56.0 in stage 1.0 (TID 57). 3408 bytes result sent to driver
09:20:52.975 INFO  [Executor task launch worker for task 60] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=59), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/59] for update
09:20:52.975 INFO  [Executor task launch worker for task 59] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=58),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/58] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/58/1.delta
09:20:52.991 INFO  [Executor task launch worker for task 60] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=59), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/59] for update
09:20:52.991 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 60.0 in stage 1.0 (TID 61, localhost, executor driver, partition 60, PROCESS_LOCAL, 4726 bytes)
09:20:52.991 INFO  [Executor task launch worker for task 60] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.991 INFO  [Executor task launch worker for task 61] org.apache.spark.executor.Executor - Running task 60.0 in stage 1.0 (TID 61)
09:20:52.991 INFO  [Executor task launch worker for task 60] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.991 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 56.0 in stage 1.0 (TID 57) in 47 ms on localhost (executor driver) (58/200)
09:20:52.991 INFO  [Executor task launch worker for task 61] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=60), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/60] for update
09:20:52.991 INFO  [Executor task launch worker for task 61] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=60), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/60] for update
09:20:52.991 INFO  [Executor task launch worker for task 61] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:52.991 INFO  [Executor task launch worker for task 61] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:52.991 INFO  [Executor task launch worker for task 59] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=58),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/58]
09:20:52.991 INFO  [Executor task launch worker for task 59] org.apache.spark.executor.Executor - Finished task 58.0 in stage 1.0 (TID 59). 3322 bytes result sent to driver
09:20:52.991 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 61.0 in stage 1.0 (TID 62, localhost, executor driver, partition 61, PROCESS_LOCAL, 4726 bytes)
09:20:52.991 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 58.0 in stage 1.0 (TID 59) in 16 ms on localhost (executor driver) (59/200)
09:20:52.991 INFO  [Executor task launch worker for task 62] org.apache.spark.executor.Executor - Running task 61.0 in stage 1.0 (TID 62)
09:20:52.991 INFO  [Executor task launch worker for task 60] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=59),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/59] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/59/1.delta
09:20:52.991 INFO  [Executor task launch worker for task 62] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=61), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/61] for update
09:20:52.991 INFO  [Executor task launch worker for task 60] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=59),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/59]
09:20:52.991 INFO  [Executor task launch worker for task 61] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=60),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/60] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/60/1.delta
09:20:53.006 INFO  [Executor task launch worker for task 62] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=61), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/61] for update
09:20:53.006 INFO  [Executor task launch worker for task 62] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.006 INFO  [Executor task launch worker for task 62] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.006 INFO  [Executor task launch worker for task 60] org.apache.spark.executor.Executor - Finished task 59.0 in stage 1.0 (TID 60). 3322 bytes result sent to driver
09:20:53.006 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 62.0 in stage 1.0 (TID 63, localhost, executor driver, partition 62, PROCESS_LOCAL, 4726 bytes)
09:20:53.006 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 59.0 in stage 1.0 (TID 60) in 31 ms on localhost (executor driver) (60/200)
09:20:53.006 INFO  [Executor task launch worker for task 63] org.apache.spark.executor.Executor - Running task 62.0 in stage 1.0 (TID 63)
09:20:53.006 INFO  [Executor task launch worker for task 63] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=62), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/62] for update
09:20:53.006 INFO  [Executor task launch worker for task 63] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=62), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/62] for update
09:20:53.006 INFO  [Executor task launch worker for task 63] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.006 INFO  [Executor task launch worker for task 63] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.006 INFO  [Executor task launch worker for task 62] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=61),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/61] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/61/1.delta
09:20:53.022 INFO  [Executor task launch worker for task 62] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=61),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/61]
09:20:53.022 INFO  [Executor task launch worker for task 62] org.apache.spark.executor.Executor - Finished task 61.0 in stage 1.0 (TID 62). 3365 bytes result sent to driver
09:20:53.022 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 63.0 in stage 1.0 (TID 64, localhost, executor driver, partition 63, PROCESS_LOCAL, 4726 bytes)
09:20:53.022 INFO  [Executor task launch worker for task 64] org.apache.spark.executor.Executor - Running task 63.0 in stage 1.0 (TID 64)
09:20:53.022 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 61.0 in stage 1.0 (TID 62) in 31 ms on localhost (executor driver) (61/200)
09:20:53.038 INFO  [Executor task launch worker for task 64] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=63), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/63] for update
09:20:53.038 INFO  [Executor task launch worker for task 64] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=63), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/63] for update
09:20:53.038 INFO  [Executor task launch worker for task 64] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.038 INFO  [Executor task launch worker for task 64] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.038 INFO  [Executor task launch worker for task 64] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=63),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/63] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/63/1.delta
09:20:53.038 INFO  [Executor task launch worker for task 63] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=62),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/62] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/62/1.delta
09:20:53.053 INFO  [Executor task launch worker for task 64] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=63),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/63]
09:20:53.053 INFO  [Executor task launch worker for task 64] org.apache.spark.executor.Executor - Finished task 63.0 in stage 1.0 (TID 64). 3365 bytes result sent to driver
09:20:53.053 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 64.0 in stage 1.0 (TID 65, localhost, executor driver, partition 64, PROCESS_LOCAL, 4726 bytes)
09:20:53.053 INFO  [Executor task launch worker for task 65] org.apache.spark.executor.Executor - Running task 64.0 in stage 1.0 (TID 65)
09:20:53.053 INFO  [Executor task launch worker for task 63] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=62),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/62]
09:20:53.053 INFO  [Executor task launch worker for task 63] org.apache.spark.executor.Executor - Finished task 62.0 in stage 1.0 (TID 63). 3365 bytes result sent to driver
09:20:53.053 INFO  [Executor task launch worker for task 65] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=64), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/64] for update
09:20:53.053 INFO  [Executor task launch worker for task 65] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=64), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/64] for update
09:20:53.053 INFO  [Executor task launch worker for task 65] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.053 INFO  [Executor task launch worker for task 65] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.053 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 63.0 in stage 1.0 (TID 64) in 31 ms on localhost (executor driver) (62/200)
09:20:53.069 INFO  [Executor task launch worker for task 65] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=64),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/64] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/64/1.delta
09:20:53.069 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 65.0 in stage 1.0 (TID 66, localhost, executor driver, partition 65, PROCESS_LOCAL, 4726 bytes)
09:20:53.069 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 62.0 in stage 1.0 (TID 63) in 63 ms on localhost (executor driver) (63/200)
09:20:53.069 INFO  [Executor task launch worker for task 66] org.apache.spark.executor.Executor - Running task 65.0 in stage 1.0 (TID 66)
09:20:53.069 INFO  [Executor task launch worker for task 66] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=65), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/65] for update
09:20:53.069 INFO  [Executor task launch worker for task 66] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=65), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/65] for update
09:20:53.069 INFO  [Executor task launch worker for task 66] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.069 INFO  [Executor task launch worker for task 66] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.084 INFO  [Executor task launch worker for task 66] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=65),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/65] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/65/1.delta
09:20:53.084 INFO  [Executor task launch worker for task 66] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=65),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/65]
09:20:53.084 INFO  [Executor task launch worker for task 61] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=60),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/60]
09:20:53.084 INFO  [Executor task launch worker for task 66] org.apache.spark.executor.Executor - Finished task 65.0 in stage 1.0 (TID 66). 3365 bytes result sent to driver
09:20:53.084 INFO  [Executor task launch worker for task 61] org.apache.spark.executor.Executor - Finished task 60.0 in stage 1.0 (TID 61). 3365 bytes result sent to driver
09:20:53.084 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 66.0 in stage 1.0 (TID 67, localhost, executor driver, partition 66, PROCESS_LOCAL, 4726 bytes)
09:20:53.084 INFO  [Executor task launch worker for task 67] org.apache.spark.executor.Executor - Running task 66.0 in stage 1.0 (TID 67)
09:20:53.084 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 67.0 in stage 1.0 (TID 68, localhost, executor driver, partition 67, PROCESS_LOCAL, 4726 bytes)
09:20:53.084 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 65.0 in stage 1.0 (TID 66) in 15 ms on localhost (executor driver) (64/200)
09:20:53.084 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 60.0 in stage 1.0 (TID 61) in 93 ms on localhost (executor driver) (65/200)
09:20:53.084 INFO  [Executor task launch worker for task 68] org.apache.spark.executor.Executor - Running task 67.0 in stage 1.0 (TID 68)
09:20:53.084 INFO  [Executor task launch worker for task 67] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=66), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/66] for update
09:20:53.084 INFO  [Executor task launch worker for task 68] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=67), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/67] for update
09:20:53.084 INFO  [Executor task launch worker for task 67] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=66), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/66] for update
09:20:53.084 INFO  [Executor task launch worker for task 68] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=67), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/67] for update
09:20:53.100 INFO  [Executor task launch worker for task 67] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.100 INFO  [Executor task launch worker for task 67] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.100 INFO  [Executor task launch worker for task 68] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.100 INFO  [Executor task launch worker for task 68] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 16 ms
09:20:53.100 INFO  [Executor task launch worker for task 67] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=66),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/66] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/66/1.delta
09:20:53.100 INFO  [Executor task launch worker for task 65] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=64),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/64]
09:20:53.100 INFO  [Executor task launch worker for task 65] org.apache.spark.executor.Executor - Finished task 64.0 in stage 1.0 (TID 65). 3365 bytes result sent to driver
09:20:53.100 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 68.0 in stage 1.0 (TID 69, localhost, executor driver, partition 68, PROCESS_LOCAL, 4726 bytes)
09:20:53.100 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 64.0 in stage 1.0 (TID 65) in 47 ms on localhost (executor driver) (66/200)
09:20:53.100 INFO  [Executor task launch worker for task 69] org.apache.spark.executor.Executor - Running task 68.0 in stage 1.0 (TID 69)
09:20:53.116 INFO  [Executor task launch worker for task 68] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=67),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/67] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/67/1.delta
09:20:53.116 INFO  [Executor task launch worker for task 69] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=68), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/68] for update
09:20:53.116 INFO  [Executor task launch worker for task 69] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=68), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/68] for update
09:20:53.116 INFO  [Executor task launch worker for task 69] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.116 INFO  [Executor task launch worker for task 69] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.116 INFO  [Executor task launch worker for task 68] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=67),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/67]
09:20:53.116 INFO  [Executor task launch worker for task 68] org.apache.spark.executor.Executor - Finished task 67.0 in stage 1.0 (TID 68). 3365 bytes result sent to driver
09:20:53.116 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 69.0 in stage 1.0 (TID 70, localhost, executor driver, partition 69, PROCESS_LOCAL, 4726 bytes)
09:20:53.116 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 67.0 in stage 1.0 (TID 68) in 32 ms on localhost (executor driver) (67/200)
09:20:53.116 INFO  [Executor task launch worker for task 70] org.apache.spark.executor.Executor - Running task 69.0 in stage 1.0 (TID 70)
09:20:53.116 INFO  [Executor task launch worker for task 67] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=66),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/66]
09:20:53.116 INFO  [Executor task launch worker for task 67] org.apache.spark.executor.Executor - Finished task 66.0 in stage 1.0 (TID 67). 3365 bytes result sent to driver
09:20:53.116 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 70.0 in stage 1.0 (TID 71, localhost, executor driver, partition 70, PROCESS_LOCAL, 4726 bytes)
09:20:53.116 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 66.0 in stage 1.0 (TID 67) in 32 ms on localhost (executor driver) (68/200)
09:20:53.116 INFO  [Executor task launch worker for task 71] org.apache.spark.executor.Executor - Running task 70.0 in stage 1.0 (TID 71)
09:20:53.131 INFO  [Executor task launch worker for task 70] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=69), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/69] for update
09:20:53.131 INFO  [Executor task launch worker for task 70] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=69), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/69] for update
09:20:53.131 INFO  [Executor task launch worker for task 70] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.131 INFO  [Executor task launch worker for task 70] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.131 INFO  [Executor task launch worker for task 71] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=70), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/70] for update
09:20:53.131 INFO  [Executor task launch worker for task 71] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=70), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/70] for update
09:20:53.131 INFO  [Executor task launch worker for task 71] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.131 INFO  [Executor task launch worker for task 71] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.131 INFO  [Executor task launch worker for task 69] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=68),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/68] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/68/1.delta
09:20:53.147 INFO  [Executor task launch worker for task 69] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=68),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/68]
09:20:53.147 INFO  [Executor task launch worker for task 69] org.apache.spark.executor.Executor - Finished task 68.0 in stage 1.0 (TID 69). 3365 bytes result sent to driver
09:20:53.147 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 71.0 in stage 1.0 (TID 72, localhost, executor driver, partition 71, PROCESS_LOCAL, 4726 bytes)
09:20:53.147 INFO  [Executor task launch worker for task 70] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=69),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/69] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/69/1.delta
09:20:53.147 INFO  [Executor task launch worker for task 72] org.apache.spark.executor.Executor - Running task 71.0 in stage 1.0 (TID 72)
09:20:53.147 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 68.0 in stage 1.0 (TID 69) in 47 ms on localhost (executor driver) (69/200)
09:20:53.147 INFO  [Executor task launch worker for task 72] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=71), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/71] for update
09:20:53.163 INFO  [Executor task launch worker for task 71] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=70),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/70] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/70/1.delta
09:20:53.163 INFO  [Executor task launch worker for task 72] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=71), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/71] for update
09:20:53.163 INFO  [Executor task launch worker for task 72] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.163 INFO  [Executor task launch worker for task 72] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.163 INFO  [Executor task launch worker for task 72] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=71),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/71] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/71/1.delta
09:20:53.163 INFO  [Executor task launch worker for task 71] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=70),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/70]
09:20:53.163 INFO  [Executor task launch worker for task 71] org.apache.spark.executor.Executor - Finished task 70.0 in stage 1.0 (TID 71). 3408 bytes result sent to driver
09:20:53.163 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 72.0 in stage 1.0 (TID 73, localhost, executor driver, partition 72, PROCESS_LOCAL, 4726 bytes)
09:20:53.163 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 70.0 in stage 1.0 (TID 71) in 47 ms on localhost (executor driver) (70/200)
09:20:53.163 INFO  [Executor task launch worker for task 73] org.apache.spark.executor.Executor - Running task 72.0 in stage 1.0 (TID 73)
09:20:53.163 INFO  [Executor task launch worker for task 72] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=71),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/71]
09:20:53.163 INFO  [Executor task launch worker for task 72] org.apache.spark.executor.Executor - Finished task 71.0 in stage 1.0 (TID 72). 3365 bytes result sent to driver
09:20:53.163 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 73.0 in stage 1.0 (TID 74, localhost, executor driver, partition 73, PROCESS_LOCAL, 4726 bytes)
09:20:53.163 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 71.0 in stage 1.0 (TID 72) in 16 ms on localhost (executor driver) (71/200)
09:20:53.163 INFO  [Executor task launch worker for task 74] org.apache.spark.executor.Executor - Running task 73.0 in stage 1.0 (TID 74)
09:20:53.163 INFO  [Executor task launch worker for task 73] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=72), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/72] for update
09:20:53.178 INFO  [Executor task launch worker for task 73] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=72), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/72] for update
09:20:53.178 INFO  [Executor task launch worker for task 73] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.178 INFO  [Executor task launch worker for task 73] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.178 INFO  [Executor task launch worker for task 74] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=73), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/73] for update
09:20:53.178 INFO  [Executor task launch worker for task 74] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=73), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/73] for update
09:20:53.178 INFO  [Executor task launch worker for task 74] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.178 INFO  [Executor task launch worker for task 74] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.178 INFO  [Executor task launch worker for task 70] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=69),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/69]
09:20:53.178 INFO  [Executor task launch worker for task 70] org.apache.spark.executor.Executor - Finished task 69.0 in stage 1.0 (TID 70). 3365 bytes result sent to driver
09:20:53.178 INFO  [Executor task launch worker for task 73] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=72),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/72] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/72/1.delta
09:20:53.178 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 74.0 in stage 1.0 (TID 75, localhost, executor driver, partition 74, PROCESS_LOCAL, 4726 bytes)
09:20:53.178 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 69.0 in stage 1.0 (TID 70) in 62 ms on localhost (executor driver) (72/200)
09:20:53.178 INFO  [Executor task launch worker for task 75] org.apache.spark.executor.Executor - Running task 74.0 in stage 1.0 (TID 75)
09:20:53.178 INFO  [Executor task launch worker for task 74] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=73),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/73] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/73/1.delta
09:20:53.178 INFO  [Executor task launch worker for task 73] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=72),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/72]
09:20:53.178 INFO  [Executor task launch worker for task 73] org.apache.spark.executor.Executor - Finished task 72.0 in stage 1.0 (TID 73). 3322 bytes result sent to driver
09:20:53.178 INFO  [Executor task launch worker for task 75] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=74), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/74] for update
09:20:53.194 INFO  [Executor task launch worker for task 75] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=74), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/74] for update
09:20:53.194 INFO  [Executor task launch worker for task 74] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=73),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/73]
09:20:53.194 INFO  [Executor task launch worker for task 75] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.194 INFO  [Executor task launch worker for task 75] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.194 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 75.0 in stage 1.0 (TID 76, localhost, executor driver, partition 75, PROCESS_LOCAL, 4726 bytes)
09:20:53.194 INFO  [Executor task launch worker for task 76] org.apache.spark.executor.Executor - Running task 75.0 in stage 1.0 (TID 76)
09:20:53.194 INFO  [Executor task launch worker for task 74] org.apache.spark.executor.Executor - Finished task 73.0 in stage 1.0 (TID 74). 3451 bytes result sent to driver
09:20:53.194 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 76.0 in stage 1.0 (TID 77, localhost, executor driver, partition 76, PROCESS_LOCAL, 4726 bytes)
09:20:53.194 INFO  [Executor task launch worker for task 77] org.apache.spark.executor.Executor - Running task 76.0 in stage 1.0 (TID 77)
09:20:53.194 INFO  [Executor task launch worker for task 76] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=75), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/75] for update
09:20:53.194 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 72.0 in stage 1.0 (TID 73) in 31 ms on localhost (executor driver) (73/200)
09:20:53.194 INFO  [Executor task launch worker for task 77] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=76), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/76] for update
09:20:53.194 INFO  [Executor task launch worker for task 76] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=75), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/75] for update
09:20:53.194 INFO  [Executor task launch worker for task 77] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=76), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/76] for update
09:20:53.194 INFO  [Executor task launch worker for task 76] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.194 INFO  [Executor task launch worker for task 76] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.194 INFO  [Executor task launch worker for task 77] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.194 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 73.0 in stage 1.0 (TID 74) in 31 ms on localhost (executor driver) (74/200)
09:20:53.194 INFO  [Executor task launch worker for task 75] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=74),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/74] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/74/1.delta
09:20:53.194 INFO  [Executor task launch worker for task 76] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=75),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/75] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/75/1.delta
09:20:53.209 INFO  [Executor task launch worker for task 77] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 15 ms
09:20:53.209 INFO  [Executor task launch worker for task 76] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=75),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/75]
09:20:53.209 INFO  [Executor task launch worker for task 76] org.apache.spark.executor.Executor - Finished task 75.0 in stage 1.0 (TID 76). 3322 bytes result sent to driver
09:20:53.209 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 77.0 in stage 1.0 (TID 78, localhost, executor driver, partition 77, PROCESS_LOCAL, 4726 bytes)
09:20:53.209 INFO  [Executor task launch worker for task 78] org.apache.spark.executor.Executor - Running task 77.0 in stage 1.0 (TID 78)
09:20:53.209 INFO  [Executor task launch worker for task 77] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=76),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/76] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/76/1.delta
09:20:53.209 INFO  [Executor task launch worker for task 78] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=77), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/77] for update
09:20:53.209 INFO  [Executor task launch worker for task 77] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=76),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/76]
09:20:53.209 INFO  [Executor task launch worker for task 78] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=77), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/77] for update
09:20:53.209 INFO  [Executor task launch worker for task 78] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.209 INFO  [Executor task launch worker for task 78] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.209 INFO  [Executor task launch worker for task 77] org.apache.spark.executor.Executor - Finished task 76.0 in stage 1.0 (TID 77). 3322 bytes result sent to driver
09:20:53.209 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 78.0 in stage 1.0 (TID 79, localhost, executor driver, partition 78, PROCESS_LOCAL, 4726 bytes)
09:20:53.209 INFO  [Executor task launch worker for task 79] org.apache.spark.executor.Executor - Running task 78.0 in stage 1.0 (TID 79)
09:20:53.209 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 75.0 in stage 1.0 (TID 76) in 15 ms on localhost (executor driver) (75/200)
09:20:53.209 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 76.0 in stage 1.0 (TID 77) in 15 ms on localhost (executor driver) (76/200)
09:20:53.225 INFO  [Executor task launch worker for task 79] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=78), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/78] for update
09:20:53.225 INFO  [Executor task launch worker for task 79] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=78), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/78] for update
09:20:53.225 INFO  [Executor task launch worker for task 79] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.225 INFO  [Executor task launch worker for task 79] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.225 INFO  [Executor task launch worker for task 79] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=78),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/78] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/78/1.delta
09:20:53.241 INFO  [Executor task launch worker for task 75] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=74),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/74]
09:20:53.241 INFO  [Executor task launch worker for task 75] org.apache.spark.executor.Executor - Finished task 74.0 in stage 1.0 (TID 75). 3322 bytes result sent to driver
09:20:53.241 INFO  [Executor task launch worker for task 79] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=78),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/78]
09:20:53.241 INFO  [Executor task launch worker for task 79] org.apache.spark.executor.Executor - Finished task 78.0 in stage 1.0 (TID 79). 3408 bytes result sent to driver
09:20:53.241 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 79.0 in stage 1.0 (TID 80, localhost, executor driver, partition 79, PROCESS_LOCAL, 4726 bytes)
09:20:53.241 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 80.0 in stage 1.0 (TID 81, localhost, executor driver, partition 80, PROCESS_LOCAL, 4726 bytes)
09:20:53.241 INFO  [Executor task launch worker for task 80] org.apache.spark.executor.Executor - Running task 79.0 in stage 1.0 (TID 80)
09:20:53.241 INFO  [Executor task launch worker for task 80] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=79), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/79] for update
09:20:53.241 INFO  [Executor task launch worker for task 80] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=79), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/79] for update
09:20:53.241 INFO  [Executor task launch worker for task 80] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.241 INFO  [Executor task launch worker for task 80] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.256 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 74.0 in stage 1.0 (TID 75) in 78 ms on localhost (executor driver) (77/200)
09:20:53.256 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 78.0 in stage 1.0 (TID 79) in 47 ms on localhost (executor driver) (78/200)
09:20:53.256 INFO  [Executor task launch worker for task 81] org.apache.spark.executor.Executor - Running task 80.0 in stage 1.0 (TID 81)
09:20:53.256 INFO  [Executor task launch worker for task 81] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=80), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/80] for update
09:20:53.256 INFO  [Executor task launch worker for task 81] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=80), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/80] for update
09:20:53.256 INFO  [Executor task launch worker for task 81] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.256 INFO  [Executor task launch worker for task 81] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.256 INFO  [Executor task launch worker for task 78] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=77),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/77] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/77/1.delta
09:20:53.272 INFO  [Executor task launch worker for task 78] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=77),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/77]
09:20:53.272 INFO  [Executor task launch worker for task 78] org.apache.spark.executor.Executor - Finished task 77.0 in stage 1.0 (TID 78). 3365 bytes result sent to driver
09:20:53.272 INFO  [Executor task launch worker for task 81] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=80),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/80] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/80/1.delta
09:20:53.272 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 81.0 in stage 1.0 (TID 82, localhost, executor driver, partition 81, PROCESS_LOCAL, 4726 bytes)
09:20:53.272 INFO  [Executor task launch worker for task 82] org.apache.spark.executor.Executor - Running task 81.0 in stage 1.0 (TID 82)
09:20:53.288 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 77.0 in stage 1.0 (TID 78) in 79 ms on localhost (executor driver) (79/200)
09:20:53.288 INFO  [Executor task launch worker for task 82] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=81), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/81] for update
09:20:53.288 INFO  [Executor task launch worker for task 82] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=81), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/81] for update
09:20:53.288 INFO  [Executor task launch worker for task 82] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.288 INFO  [Executor task launch worker for task 82] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.288 INFO  [Executor task launch worker for task 80] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=79),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/79] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/79/1.delta
09:20:53.288 INFO  [Executor task launch worker for task 81] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=80),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/80]
09:20:53.288 INFO  [Executor task launch worker for task 81] org.apache.spark.executor.Executor - Finished task 80.0 in stage 1.0 (TID 81). 3365 bytes result sent to driver
09:20:53.288 INFO  [Executor task launch worker for task 80] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=79),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/79]
09:20:53.288 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 82.0 in stage 1.0 (TID 83, localhost, executor driver, partition 82, PROCESS_LOCAL, 4726 bytes)
09:20:53.288 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 80.0 in stage 1.0 (TID 81) in 47 ms on localhost (executor driver) (80/200)
09:20:53.288 INFO  [Executor task launch worker for task 83] org.apache.spark.executor.Executor - Running task 82.0 in stage 1.0 (TID 83)
09:20:53.288 INFO  [Executor task launch worker for task 80] org.apache.spark.executor.Executor - Finished task 79.0 in stage 1.0 (TID 80). 3365 bytes result sent to driver
09:20:53.288 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 83.0 in stage 1.0 (TID 84, localhost, executor driver, partition 83, PROCESS_LOCAL, 4726 bytes)
09:20:53.288 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 79.0 in stage 1.0 (TID 80) in 47 ms on localhost (executor driver) (81/200)
09:20:53.288 INFO  [Executor task launch worker for task 84] org.apache.spark.executor.Executor - Running task 83.0 in stage 1.0 (TID 84)
09:20:53.288 INFO  [Executor task launch worker for task 83] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=82), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/82] for update
09:20:53.288 INFO  [Executor task launch worker for task 83] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=82), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/82] for update
09:20:53.288 INFO  [Executor task launch worker for task 83] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.288 INFO  [Executor task launch worker for task 83] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.288 INFO  [Executor task launch worker for task 84] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=83), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/83] for update
09:20:53.288 INFO  [Executor task launch worker for task 82] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=81),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/81] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/81/1.delta
09:20:53.303 INFO  [Executor task launch worker for task 84] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=83), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/83] for update
09:20:53.303 INFO  [Executor task launch worker for task 84] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.303 INFO  [Executor task launch worker for task 84] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.319 INFO  [Executor task launch worker for task 83] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=82),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/82] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/82/1.delta
09:20:53.319 INFO  [Executor task launch worker for task 83] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=82),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/82]
09:20:53.319 INFO  [Executor task launch worker for task 83] org.apache.spark.executor.Executor - Finished task 82.0 in stage 1.0 (TID 83). 3365 bytes result sent to driver
09:20:53.319 INFO  [Executor task launch worker for task 84] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=83),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/83] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/83/1.delta
09:20:53.319 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 84.0 in stage 1.0 (TID 85, localhost, executor driver, partition 84, PROCESS_LOCAL, 4726 bytes)
09:20:53.319 INFO  [Executor task launch worker for task 85] org.apache.spark.executor.Executor - Running task 84.0 in stage 1.0 (TID 85)
09:20:53.319 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 82.0 in stage 1.0 (TID 83) in 31 ms on localhost (executor driver) (82/200)
09:20:53.319 INFO  [Executor task launch worker for task 82] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=81),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/81]
09:20:53.319 INFO  [Executor task launch worker for task 82] org.apache.spark.executor.Executor - Finished task 81.0 in stage 1.0 (TID 82). 3365 bytes result sent to driver
09:20:53.319 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 85.0 in stage 1.0 (TID 86, localhost, executor driver, partition 85, PROCESS_LOCAL, 4726 bytes)
09:20:53.319 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 81.0 in stage 1.0 (TID 82) in 47 ms on localhost (executor driver) (83/200)
09:20:53.319 INFO  [Executor task launch worker for task 86] org.apache.spark.executor.Executor - Running task 85.0 in stage 1.0 (TID 86)
09:20:53.319 INFO  [Executor task launch worker for task 85] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=84), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/84] for update
09:20:53.319 INFO  [Executor task launch worker for task 85] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=84), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/84] for update
09:20:53.319 INFO  [Executor task launch worker for task 85] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.319 INFO  [Executor task launch worker for task 85] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.334 INFO  [Executor task launch worker for task 84] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=83),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/83]
09:20:53.334 INFO  [Executor task launch worker for task 84] org.apache.spark.executor.Executor - Finished task 83.0 in stage 1.0 (TID 84). 3365 bytes result sent to driver
09:20:53.334 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 86.0 in stage 1.0 (TID 87, localhost, executor driver, partition 86, PROCESS_LOCAL, 4726 bytes)
09:20:53.334 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 83.0 in stage 1.0 (TID 84) in 46 ms on localhost (executor driver) (84/200)
09:20:53.334 INFO  [Executor task launch worker for task 87] org.apache.spark.executor.Executor - Running task 86.0 in stage 1.0 (TID 87)
09:20:53.334 INFO  [Executor task launch worker for task 86] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=85), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/85] for update
09:20:53.334 INFO  [Executor task launch worker for task 87] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=86), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/86] for update
09:20:53.334 INFO  [Executor task launch worker for task 86] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=85), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/85] for update
09:20:53.334 INFO  [Executor task launch worker for task 87] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=86), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/86] for update
09:20:53.334 INFO  [Executor task launch worker for task 86] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.334 INFO  [Executor task launch worker for task 87] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.334 INFO  [Executor task launch worker for task 86] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.334 INFO  [Executor task launch worker for task 87] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.350 INFO  [Executor task launch worker for task 85] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=84),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/84] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/84/1.delta
09:20:53.350 INFO  [Executor task launch worker for task 87] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=86),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/86] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/86/1.delta
09:20:53.350 INFO  [Executor task launch worker for task 86] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=85),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/85] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/85/1.delta
09:20:53.350 INFO  [Executor task launch worker for task 85] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=84),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/84]
09:20:53.350 INFO  [Executor task launch worker for task 87] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=86),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/86]
09:20:53.350 INFO  [Executor task launch worker for task 86] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=85),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/85]
09:20:53.350 INFO  [Executor task launch worker for task 85] org.apache.spark.executor.Executor - Finished task 84.0 in stage 1.0 (TID 85). 3322 bytes result sent to driver
09:20:53.350 INFO  [Executor task launch worker for task 87] org.apache.spark.executor.Executor - Finished task 86.0 in stage 1.0 (TID 87). 3365 bytes result sent to driver
09:20:53.350 INFO  [Executor task launch worker for task 86] org.apache.spark.executor.Executor - Finished task 85.0 in stage 1.0 (TID 86). 3451 bytes result sent to driver
09:20:53.350 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 87.0 in stage 1.0 (TID 88, localhost, executor driver, partition 87, PROCESS_LOCAL, 4726 bytes)
09:20:53.350 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 84.0 in stage 1.0 (TID 85) in 31 ms on localhost (executor driver) (85/200)
09:20:53.350 INFO  [Executor task launch worker for task 88] org.apache.spark.executor.Executor - Running task 87.0 in stage 1.0 (TID 88)
09:20:53.350 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 88.0 in stage 1.0 (TID 89, localhost, executor driver, partition 88, PROCESS_LOCAL, 4726 bytes)
09:20:53.350 INFO  [Executor task launch worker for task 89] org.apache.spark.executor.Executor - Running task 88.0 in stage 1.0 (TID 89)
09:20:53.350 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 89.0 in stage 1.0 (TID 90, localhost, executor driver, partition 89, PROCESS_LOCAL, 4726 bytes)
09:20:53.350 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 85.0 in stage 1.0 (TID 86) in 31 ms on localhost (executor driver) (86/200)
09:20:53.350 INFO  [Executor task launch worker for task 90] org.apache.spark.executor.Executor - Running task 89.0 in stage 1.0 (TID 90)
09:20:53.350 INFO  [Executor task launch worker for task 89] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=88), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/88] for update
09:20:53.350 INFO  [Executor task launch worker for task 88] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=87), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/87] for update
09:20:53.366 INFO  [Executor task launch worker for task 89] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=88), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/88] for update
09:20:53.366 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 86.0 in stage 1.0 (TID 87) in 32 ms on localhost (executor driver) (87/200)
09:20:53.366 INFO  [Executor task launch worker for task 88] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=87), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/87] for update
09:20:53.366 INFO  [Executor task launch worker for task 89] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.366 INFO  [Executor task launch worker for task 88] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.366 INFO  [Executor task launch worker for task 89] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.366 INFO  [Executor task launch worker for task 88] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.366 INFO  [Executor task launch worker for task 90] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=89), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/89] for update
09:20:53.366 INFO  [Executor task launch worker for task 90] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=89), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/89] for update
09:20:53.366 INFO  [Executor task launch worker for task 90] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.366 INFO  [Executor task launch worker for task 90] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.366 INFO  [Executor task launch worker for task 89] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=88),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/88] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/88/1.delta
09:20:53.366 INFO  [Executor task launch worker for task 88] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=87),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/87] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/87/1.delta
09:20:53.461 INFO  [Executor task launch worker for task 90] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=89),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/89] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/89/1.delta
09:20:53.476 INFO  [Executor task launch worker for task 88] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=87),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/87]
09:20:53.476 INFO  [Executor task launch worker for task 89] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=88),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/88]
09:20:53.476 INFO  [Executor task launch worker for task 89] org.apache.spark.executor.Executor - Finished task 88.0 in stage 1.0 (TID 89). 3365 bytes result sent to driver
09:20:53.476 INFO  [Executor task launch worker for task 88] org.apache.spark.executor.Executor - Finished task 87.0 in stage 1.0 (TID 88). 3365 bytes result sent to driver
09:20:53.476 INFO  [Executor task launch worker for task 90] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=89),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/89]
09:20:53.476 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 90.0 in stage 1.0 (TID 91, localhost, executor driver, partition 90, PROCESS_LOCAL, 4726 bytes)
09:20:53.476 INFO  [Executor task launch worker for task 90] org.apache.spark.executor.Executor - Finished task 89.0 in stage 1.0 (TID 90). 3451 bytes result sent to driver
09:20:53.476 INFO  [Executor task launch worker for task 91] org.apache.spark.executor.Executor - Running task 90.0 in stage 1.0 (TID 91)
09:20:53.476 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 91.0 in stage 1.0 (TID 92, localhost, executor driver, partition 91, PROCESS_LOCAL, 4726 bytes)
09:20:53.476 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 92.0 in stage 1.0 (TID 93, localhost, executor driver, partition 92, PROCESS_LOCAL, 4726 bytes)
09:20:53.476 INFO  [Executor task launch worker for task 92] org.apache.spark.executor.Executor - Running task 91.0 in stage 1.0 (TID 92)
09:20:53.476 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 87.0 in stage 1.0 (TID 88) in 126 ms on localhost (executor driver) (88/200)
09:20:53.476 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 89.0 in stage 1.0 (TID 90) in 126 ms on localhost (executor driver) (89/200)
09:20:53.476 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 88.0 in stage 1.0 (TID 89) in 126 ms on localhost (executor driver) (90/200)
09:20:53.476 INFO  [Executor task launch worker for task 93] org.apache.spark.executor.Executor - Running task 92.0 in stage 1.0 (TID 93)
09:20:53.476 INFO  [Executor task launch worker for task 91] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=90), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/90] for update
09:20:53.476 INFO  [Executor task launch worker for task 92] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=91), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/91] for update
09:20:53.476 INFO  [Executor task launch worker for task 91] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=90), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/90] for update
09:20:53.476 INFO  [Executor task launch worker for task 92] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=91), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/91] for update
09:20:53.476 INFO  [Executor task launch worker for task 93] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=92), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/92] for update
09:20:53.492 INFO  [Executor task launch worker for task 93] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=92), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/92] for update
09:20:53.492 INFO  [Executor task launch worker for task 92] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.492 INFO  [Executor task launch worker for task 91] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.492 INFO  [Executor task launch worker for task 92] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.492 INFO  [Executor task launch worker for task 91] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.492 INFO  [Executor task launch worker for task 93] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.492 INFO  [Executor task launch worker for task 93] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.507 INFO  [Executor task launch worker for task 92] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=91),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/91] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/91/1.delta
09:20:53.507 INFO  [Executor task launch worker for task 92] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=91),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/91]
09:20:53.507 INFO  [Executor task launch worker for task 93] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=92),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/92] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/92/1.delta
09:20:53.507 INFO  [Executor task launch worker for task 91] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=90),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/90] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/90/1.delta
09:20:53.507 INFO  [Executor task launch worker for task 92] org.apache.spark.executor.Executor - Finished task 91.0 in stage 1.0 (TID 92). 3365 bytes result sent to driver
09:20:53.507 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 93.0 in stage 1.0 (TID 94, localhost, executor driver, partition 93, PROCESS_LOCAL, 4726 bytes)
09:20:53.507 INFO  [Executor task launch worker for task 94] org.apache.spark.executor.Executor - Running task 93.0 in stage 1.0 (TID 94)
09:20:53.507 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 91.0 in stage 1.0 (TID 92) in 31 ms on localhost (executor driver) (91/200)
09:20:53.507 INFO  [Executor task launch worker for task 94] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=93), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/93] for update
09:20:53.507 INFO  [Executor task launch worker for task 94] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=93), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/93] for update
09:20:53.507 INFO  [Executor task launch worker for task 94] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.507 INFO  [Executor task launch worker for task 94] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.507 INFO  [Executor task launch worker for task 91] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=90),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/90]
09:20:53.507 INFO  [Executor task launch worker for task 93] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=92),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/92]
09:20:53.507 INFO  [Executor task launch worker for task 91] org.apache.spark.executor.Executor - Finished task 90.0 in stage 1.0 (TID 91). 3365 bytes result sent to driver
09:20:53.523 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 94.0 in stage 1.0 (TID 95, localhost, executor driver, partition 94, PROCESS_LOCAL, 4726 bytes)
09:20:53.523 INFO  [Executor task launch worker for task 93] org.apache.spark.executor.Executor - Finished task 92.0 in stage 1.0 (TID 93). 3365 bytes result sent to driver
09:20:53.523 INFO  [Executor task launch worker for task 95] org.apache.spark.executor.Executor - Running task 94.0 in stage 1.0 (TID 95)
09:20:53.523 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 90.0 in stage 1.0 (TID 91) in 47 ms on localhost (executor driver) (92/200)
09:20:53.523 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 95.0 in stage 1.0 (TID 96, localhost, executor driver, partition 95, PROCESS_LOCAL, 4726 bytes)
09:20:53.523 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 92.0 in stage 1.0 (TID 93) in 47 ms on localhost (executor driver) (93/200)
09:20:53.523 INFO  [Executor task launch worker for task 96] org.apache.spark.executor.Executor - Running task 95.0 in stage 1.0 (TID 96)
09:20:53.523 INFO  [Executor task launch worker for task 94] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=93),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/93] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/93/1.delta
09:20:53.523 INFO  [Executor task launch worker for task 95] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=94), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/94] for update
09:20:53.523 INFO  [Executor task launch worker for task 96] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=95), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/95] for update
09:20:53.523 INFO  [Executor task launch worker for task 95] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=94), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/94] for update
09:20:53.523 INFO  [Executor task launch worker for task 96] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=95), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/95] for update
09:20:53.523 INFO  [Executor task launch worker for task 96] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.523 INFO  [Executor task launch worker for task 95] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.523 INFO  [Executor task launch worker for task 96] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.523 INFO  [Executor task launch worker for task 95] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.523 INFO  [Executor task launch worker for task 94] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=93),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/93]
09:20:53.523 INFO  [Executor task launch worker for task 95] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=94),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/94] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/94/1.delta
09:20:53.523 INFO  [Executor task launch worker for task 96] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=95),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/95] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/95/1.delta
09:20:53.539 INFO  [Executor task launch worker for task 94] org.apache.spark.executor.Executor - Finished task 93.0 in stage 1.0 (TID 94). 3365 bytes result sent to driver
09:20:53.539 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 96.0 in stage 1.0 (TID 97, localhost, executor driver, partition 96, PROCESS_LOCAL, 4726 bytes)
09:20:53.539 INFO  [Executor task launch worker for task 97] org.apache.spark.executor.Executor - Running task 96.0 in stage 1.0 (TID 97)
09:20:53.539 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 93.0 in stage 1.0 (TID 94) in 32 ms on localhost (executor driver) (94/200)
09:20:53.539 INFO  [Executor task launch worker for task 97] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=96), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/96] for update
09:20:53.539 INFO  [Executor task launch worker for task 97] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=96), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/96] for update
09:20:53.539 INFO  [Executor task launch worker for task 97] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.539 INFO  [Executor task launch worker for task 96] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=95),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/95]
09:20:53.539 INFO  [Executor task launch worker for task 97] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.539 INFO  [Executor task launch worker for task 95] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=94),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/94]
09:20:53.539 INFO  [Executor task launch worker for task 96] org.apache.spark.executor.Executor - Finished task 95.0 in stage 1.0 (TID 96). 3322 bytes result sent to driver
09:20:53.539 INFO  [Executor task launch worker for task 95] org.apache.spark.executor.Executor - Finished task 94.0 in stage 1.0 (TID 95). 3322 bytes result sent to driver
09:20:53.539 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 97.0 in stage 1.0 (TID 98, localhost, executor driver, partition 97, PROCESS_LOCAL, 4726 bytes)
09:20:53.539 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 95.0 in stage 1.0 (TID 96) in 16 ms on localhost (executor driver) (95/200)
09:20:53.539 INFO  [Executor task launch worker for task 98] org.apache.spark.executor.Executor - Running task 97.0 in stage 1.0 (TID 98)
09:20:53.539 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 98.0 in stage 1.0 (TID 99, localhost, executor driver, partition 98, PROCESS_LOCAL, 4726 bytes)
09:20:53.539 INFO  [Executor task launch worker for task 98] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=97), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/97] for update
09:20:53.539 INFO  [Executor task launch worker for task 97] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=96),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/96] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/96/1.delta
09:20:53.554 INFO  [Executor task launch worker for task 99] org.apache.spark.executor.Executor - Running task 98.0 in stage 1.0 (TID 99)
09:20:53.554 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 94.0 in stage 1.0 (TID 95) in 31 ms on localhost (executor driver) (96/200)
09:20:53.554 INFO  [Executor task launch worker for task 98] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=97), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/97] for update
09:20:53.554 INFO  [Executor task launch worker for task 98] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.554 INFO  [Executor task launch worker for task 98] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.554 INFO  [Executor task launch worker for task 99] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=98), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/98] for update
09:20:53.554 INFO  [Executor task launch worker for task 99] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=98), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/98] for update
09:20:53.554 INFO  [Executor task launch worker for task 99] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.554 INFO  [Executor task launch worker for task 99] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.554 INFO  [Executor task launch worker for task 97] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=96),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/96]
09:20:53.554 INFO  [Executor task launch worker for task 97] org.apache.spark.executor.Executor - Finished task 96.0 in stage 1.0 (TID 97). 3322 bytes result sent to driver
09:20:53.554 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 99.0 in stage 1.0 (TID 100, localhost, executor driver, partition 99, PROCESS_LOCAL, 4726 bytes)
09:20:53.554 INFO  [Executor task launch worker for task 100] org.apache.spark.executor.Executor - Running task 99.0 in stage 1.0 (TID 100)
09:20:53.554 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 96.0 in stage 1.0 (TID 97) in 15 ms on localhost (executor driver) (97/200)
09:20:53.554 INFO  [Executor task launch worker for task 98] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=97),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/97] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/97/1.delta
09:20:53.554 INFO  [Executor task launch worker for task 100] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=99), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/99] for update
09:20:53.554 INFO  [Executor task launch worker for task 100] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=99), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/99] for update
09:20:53.570 INFO  [Executor task launch worker for task 100] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.570 INFO  [Executor task launch worker for task 100] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.570 INFO  [Executor task launch worker for task 99] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=98),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/98] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/98/1.delta
09:20:53.570 INFO  [Executor task launch worker for task 98] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=97),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/97]
09:20:53.570 INFO  [Executor task launch worker for task 98] org.apache.spark.executor.Executor - Finished task 97.0 in stage 1.0 (TID 98). 3365 bytes result sent to driver
09:20:53.570 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 100.0 in stage 1.0 (TID 101, localhost, executor driver, partition 100, PROCESS_LOCAL, 4726 bytes)
09:20:53.570 INFO  [Executor task launch worker for task 101] org.apache.spark.executor.Executor - Running task 100.0 in stage 1.0 (TID 101)
09:20:53.570 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 97.0 in stage 1.0 (TID 98) in 31 ms on localhost (executor driver) (98/200)
09:20:53.570 INFO  [Executor task launch worker for task 99] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=98),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/98]
09:20:53.570 INFO  [Executor task launch worker for task 99] org.apache.spark.executor.Executor - Finished task 98.0 in stage 1.0 (TID 99). 3322 bytes result sent to driver
09:20:53.570 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 101.0 in stage 1.0 (TID 102, localhost, executor driver, partition 101, PROCESS_LOCAL, 4726 bytes)
09:20:53.570 INFO  [Executor task launch worker for task 102] org.apache.spark.executor.Executor - Running task 101.0 in stage 1.0 (TID 102)
09:20:53.570 INFO  [Executor task launch worker for task 101] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=100), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/100] for update
09:20:53.570 INFO  [Executor task launch worker for task 101] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=100), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/100] for update
09:20:53.570 INFO  [Executor task launch worker for task 101] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.570 INFO  [Executor task launch worker for task 101] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.570 INFO  [Executor task launch worker for task 100] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=99),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/99] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/99/1.delta
09:20:53.570 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 98.0 in stage 1.0 (TID 99) in 31 ms on localhost (executor driver) (99/200)
09:20:53.570 INFO  [Executor task launch worker for task 102] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=101), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/101] for update
09:20:53.570 INFO  [Executor task launch worker for task 101] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=100),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/100] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/100/1.delta
09:20:53.585 INFO  [Executor task launch worker for task 102] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=101), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/101] for update
09:20:53.585 INFO  [Executor task launch worker for task 102] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.585 INFO  [Executor task launch worker for task 102] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.585 INFO  [Executor task launch worker for task 101] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=100),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/100]
09:20:53.585 INFO  [Executor task launch worker for task 100] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=99),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/99]
09:20:53.585 INFO  [Executor task launch worker for task 100] org.apache.spark.executor.Executor - Finished task 99.0 in stage 1.0 (TID 100). 3322 bytes result sent to driver
09:20:53.585 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 102.0 in stage 1.0 (TID 103, localhost, executor driver, partition 102, PROCESS_LOCAL, 4726 bytes)
09:20:53.585 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 99.0 in stage 1.0 (TID 100) in 31 ms on localhost (executor driver) (100/200)
09:20:53.585 INFO  [Executor task launch worker for task 103] org.apache.spark.executor.Executor - Running task 102.0 in stage 1.0 (TID 103)
09:20:53.585 INFO  [Executor task launch worker for task 102] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=101),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/101] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/101/1.delta
09:20:53.585 INFO  [Executor task launch worker for task 103] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=102), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/102] for update
09:20:53.585 INFO  [Executor task launch worker for task 103] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=102), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/102] for update
09:20:53.585 INFO  [Executor task launch worker for task 102] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=101),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/101]
09:20:53.601 INFO  [Executor task launch worker for task 103] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.601 INFO  [Executor task launch worker for task 103] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.601 INFO  [Executor task launch worker for task 102] org.apache.spark.executor.Executor - Finished task 101.0 in stage 1.0 (TID 102). 3322 bytes result sent to driver
09:20:53.601 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 103.0 in stage 1.0 (TID 104, localhost, executor driver, partition 103, PROCESS_LOCAL, 4726 bytes)
09:20:53.601 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 101.0 in stage 1.0 (TID 102) in 31 ms on localhost (executor driver) (101/200)
09:20:53.601 INFO  [Executor task launch worker for task 104] org.apache.spark.executor.Executor - Running task 103.0 in stage 1.0 (TID 104)
09:20:53.601 INFO  [Executor task launch worker for task 104] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=103), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/103] for update
09:20:53.601 INFO  [Executor task launch worker for task 104] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=103), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/103] for update
09:20:53.601 INFO  [Executor task launch worker for task 104] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.601 INFO  [Executor task launch worker for task 104] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.601 INFO  [Executor task launch worker for task 103] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=102),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/102] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/102/1.delta
09:20:53.601 INFO  [Executor task launch worker for task 101] org.apache.spark.executor.Executor - Finished task 100.0 in stage 1.0 (TID 101). 3365 bytes result sent to driver
09:20:53.601 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 104.0 in stage 1.0 (TID 105, localhost, executor driver, partition 104, PROCESS_LOCAL, 4726 bytes)
09:20:53.601 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 100.0 in stage 1.0 (TID 101) in 31 ms on localhost (executor driver) (102/200)
09:20:53.601 INFO  [Executor task launch worker for task 105] org.apache.spark.executor.Executor - Running task 104.0 in stage 1.0 (TID 105)
09:20:53.601 INFO  [Executor task launch worker for task 105] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=104), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/104] for update
09:20:53.601 INFO  [Executor task launch worker for task 103] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=102),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/102]
09:20:53.601 INFO  [Executor task launch worker for task 104] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=103),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/103] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/103/1.delta
09:20:53.617 INFO  [Executor task launch worker for task 105] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=104), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/104] for update
09:20:53.617 INFO  [Executor task launch worker for task 105] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.617 INFO  [Executor task launch worker for task 103] org.apache.spark.executor.Executor - Finished task 102.0 in stage 1.0 (TID 103). 3322 bytes result sent to driver
09:20:53.617 INFO  [Executor task launch worker for task 105] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.617 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 105.0 in stage 1.0 (TID 106, localhost, executor driver, partition 105, PROCESS_LOCAL, 4726 bytes)
09:20:53.617 INFO  [Executor task launch worker for task 106] org.apache.spark.executor.Executor - Running task 105.0 in stage 1.0 (TID 106)
09:20:53.617 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 102.0 in stage 1.0 (TID 103) in 32 ms on localhost (executor driver) (103/200)
09:20:53.617 INFO  [Executor task launch worker for task 106] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=105), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/105] for update
09:20:53.617 INFO  [Executor task launch worker for task 106] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=105), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/105] for update
09:20:53.617 INFO  [Executor task launch worker for task 106] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.617 INFO  [Executor task launch worker for task 106] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.617 INFO  [Executor task launch worker for task 104] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=103),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/103]
09:20:53.617 INFO  [Executor task launch worker for task 104] org.apache.spark.executor.Executor - Finished task 103.0 in stage 1.0 (TID 104). 3322 bytes result sent to driver
09:20:53.617 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 106.0 in stage 1.0 (TID 107, localhost, executor driver, partition 106, PROCESS_LOCAL, 4726 bytes)
09:20:53.617 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 103.0 in stage 1.0 (TID 104) in 16 ms on localhost (executor driver) (104/200)
09:20:53.617 INFO  [Executor task launch worker for task 107] org.apache.spark.executor.Executor - Running task 106.0 in stage 1.0 (TID 107)
09:20:53.617 INFO  [Executor task launch worker for task 105] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=104),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/104] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/104/1.delta
09:20:53.617 INFO  [Executor task launch worker for task 107] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=106), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/106] for update
09:20:53.617 INFO  [Executor task launch worker for task 106] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=105),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/105] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/105/1.delta
09:20:53.617 INFO  [Executor task launch worker for task 105] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=104),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/104]
09:20:53.632 INFO  [Executor task launch worker for task 107] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=106), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/106] for update
09:20:53.632 INFO  [Executor task launch worker for task 105] org.apache.spark.executor.Executor - Finished task 104.0 in stage 1.0 (TID 105). 3322 bytes result sent to driver
09:20:53.632 INFO  [Executor task launch worker for task 107] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.632 INFO  [Executor task launch worker for task 107] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.632 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 107.0 in stage 1.0 (TID 108, localhost, executor driver, partition 107, PROCESS_LOCAL, 4726 bytes)
09:20:53.632 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 104.0 in stage 1.0 (TID 105) in 31 ms on localhost (executor driver) (105/200)
09:20:53.632 INFO  [Executor task launch worker for task 108] org.apache.spark.executor.Executor - Running task 107.0 in stage 1.0 (TID 108)
09:20:53.632 INFO  [Executor task launch worker for task 108] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=107), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/107] for update
09:20:53.632 INFO  [Executor task launch worker for task 108] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=107), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/107] for update
09:20:53.632 INFO  [Executor task launch worker for task 108] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.632 INFO  [Executor task launch worker for task 108] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.632 INFO  [Executor task launch worker for task 106] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=105),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/105]
09:20:53.632 INFO  [Executor task launch worker for task 106] org.apache.spark.executor.Executor - Finished task 105.0 in stage 1.0 (TID 106). 3322 bytes result sent to driver
09:20:53.632 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 108.0 in stage 1.0 (TID 109, localhost, executor driver, partition 108, PROCESS_LOCAL, 4726 bytes)
09:20:53.632 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 105.0 in stage 1.0 (TID 106) in 15 ms on localhost (executor driver) (106/200)
09:20:53.632 INFO  [Executor task launch worker for task 109] org.apache.spark.executor.Executor - Running task 108.0 in stage 1.0 (TID 109)
09:20:53.632 INFO  [Executor task launch worker for task 107] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=106),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/106] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/106/1.delta
09:20:53.632 INFO  [Executor task launch worker for task 109] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=108), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/108] for update
09:20:53.632 INFO  [Executor task launch worker for task 108] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=107),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/107] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/107/1.delta
09:20:53.648 INFO  [Executor task launch worker for task 109] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=108), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/108] for update
09:20:53.648 INFO  [Executor task launch worker for task 109] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.648 INFO  [Executor task launch worker for task 109] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.648 INFO  [Executor task launch worker for task 107] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=106),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/106]
09:20:53.648 INFO  [Executor task launch worker for task 107] org.apache.spark.executor.Executor - Finished task 106.0 in stage 1.0 (TID 107). 3322 bytes result sent to driver
09:20:53.648 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 109.0 in stage 1.0 (TID 110, localhost, executor driver, partition 109, PROCESS_LOCAL, 4726 bytes)
09:20:53.648 INFO  [Executor task launch worker for task 110] org.apache.spark.executor.Executor - Running task 109.0 in stage 1.0 (TID 110)
09:20:53.648 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 106.0 in stage 1.0 (TID 107) in 31 ms on localhost (executor driver) (107/200)
09:20:53.648 INFO  [Executor task launch worker for task 108] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=107),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/107]
09:20:53.648 INFO  [Executor task launch worker for task 108] org.apache.spark.executor.Executor - Finished task 107.0 in stage 1.0 (TID 108). 3322 bytes result sent to driver
09:20:53.648 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 110.0 in stage 1.0 (TID 111, localhost, executor driver, partition 110, PROCESS_LOCAL, 4726 bytes)
09:20:53.648 INFO  [Executor task launch worker for task 111] org.apache.spark.executor.Executor - Running task 110.0 in stage 1.0 (TID 111)
09:20:53.648 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 107.0 in stage 1.0 (TID 108) in 16 ms on localhost (executor driver) (108/200)
09:20:53.664 INFO  [Executor task launch worker for task 110] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=109), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/109] for update
09:20:53.664 INFO  [Executor task launch worker for task 109] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=108),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/108] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/108/1.delta
09:20:53.664 INFO  [Executor task launch worker for task 110] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=109), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/109] for update
09:20:53.664 INFO  [Executor task launch worker for task 110] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.664 INFO  [Executor task launch worker for task 110] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.664 INFO  [Executor task launch worker for task 111] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=110), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/110] for update
09:20:53.664 INFO  [Executor task launch worker for task 111] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=110), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/110] for update
09:20:53.664 INFO  [Executor task launch worker for task 111] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.664 INFO  [Executor task launch worker for task 111] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.664 INFO  [Executor task launch worker for task 109] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=108),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/108]
09:20:53.664 INFO  [Executor task launch worker for task 109] org.apache.spark.executor.Executor - Finished task 108.0 in stage 1.0 (TID 109). 3365 bytes result sent to driver
09:20:53.664 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 111.0 in stage 1.0 (TID 112, localhost, executor driver, partition 111, PROCESS_LOCAL, 4726 bytes)
09:20:53.664 INFO  [Executor task launch worker for task 112] org.apache.spark.executor.Executor - Running task 111.0 in stage 1.0 (TID 112)
09:20:53.664 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 108.0 in stage 1.0 (TID 109) in 32 ms on localhost (executor driver) (109/200)
09:20:53.664 INFO  [Executor task launch worker for task 112] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=111), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/111] for update
09:20:53.664 INFO  [Executor task launch worker for task 112] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=111), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/111] for update
09:20:53.679 INFO  [Executor task launch worker for task 112] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.679 INFO  [Executor task launch worker for task 112] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.679 INFO  [Executor task launch worker for task 110] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=109),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/109] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/109/1.delta
09:20:53.679 INFO  [Executor task launch worker for task 111] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=110),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/110] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/110/1.delta
09:20:53.679 INFO  [Executor task launch worker for task 112] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=111),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/111] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/111/1.delta
09:20:53.679 INFO  [Executor task launch worker for task 110] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=109),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/109]
09:20:53.679 INFO  [Executor task launch worker for task 110] org.apache.spark.executor.Executor - Finished task 109.0 in stage 1.0 (TID 110). 3408 bytes result sent to driver
09:20:53.679 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 112.0 in stage 1.0 (TID 113, localhost, executor driver, partition 112, PROCESS_LOCAL, 4726 bytes)
09:20:53.679 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 109.0 in stage 1.0 (TID 110) in 31 ms on localhost (executor driver) (110/200)
09:20:53.679 INFO  [Executor task launch worker for task 113] org.apache.spark.executor.Executor - Running task 112.0 in stage 1.0 (TID 113)
09:20:53.679 INFO  [Executor task launch worker for task 113] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=112), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/112] for update
09:20:53.679 INFO  [Executor task launch worker for task 113] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=112), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/112] for update
09:20:53.679 INFO  [Executor task launch worker for task 113] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.679 INFO  [Executor task launch worker for task 111] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=110),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/110]
09:20:53.679 INFO  [Executor task launch worker for task 113] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.695 INFO  [Executor task launch worker for task 112] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=111),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/111]
09:20:53.695 INFO  [Executor task launch worker for task 111] org.apache.spark.executor.Executor - Finished task 110.0 in stage 1.0 (TID 111). 3451 bytes result sent to driver
09:20:53.695 INFO  [Executor task launch worker for task 112] org.apache.spark.executor.Executor - Finished task 111.0 in stage 1.0 (TID 112). 3365 bytes result sent to driver
09:20:53.695 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 113.0 in stage 1.0 (TID 114, localhost, executor driver, partition 113, PROCESS_LOCAL, 4726 bytes)
09:20:53.695 INFO  [Executor task launch worker for task 114] org.apache.spark.executor.Executor - Running task 113.0 in stage 1.0 (TID 114)
09:20:53.695 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 114.0 in stage 1.0 (TID 115, localhost, executor driver, partition 114, PROCESS_LOCAL, 4726 bytes)
09:20:53.695 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 111.0 in stage 1.0 (TID 112) in 31 ms on localhost (executor driver) (111/200)
09:20:53.695 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 110.0 in stage 1.0 (TID 111) in 47 ms on localhost (executor driver) (112/200)
09:20:53.695 INFO  [Executor task launch worker for task 115] org.apache.spark.executor.Executor - Running task 114.0 in stage 1.0 (TID 115)
09:20:53.695 INFO  [Executor task launch worker for task 114] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=113), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/113] for update
09:20:53.695 INFO  [Executor task launch worker for task 114] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=113), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/113] for update
09:20:53.695 INFO  [Executor task launch worker for task 114] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.695 INFO  [Executor task launch worker for task 114] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.695 INFO  [Executor task launch worker for task 115] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=114), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/114] for update
09:20:53.695 INFO  [Executor task launch worker for task 115] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=114), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/114] for update
09:20:53.695 INFO  [Executor task launch worker for task 115] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.695 INFO  [Executor task launch worker for task 115] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.695 INFO  [Executor task launch worker for task 114] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=113),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/113] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/113/1.delta
09:20:53.695 INFO  [Executor task launch worker for task 113] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=112),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/112] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/112/1.delta
09:20:53.710 INFO  [Executor task launch worker for task 113] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=112),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/112]
09:20:53.710 INFO  [Executor task launch worker for task 113] org.apache.spark.executor.Executor - Finished task 112.0 in stage 1.0 (TID 113). 3322 bytes result sent to driver
09:20:53.710 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 115.0 in stage 1.0 (TID 116, localhost, executor driver, partition 115, PROCESS_LOCAL, 4726 bytes)
09:20:53.710 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 112.0 in stage 1.0 (TID 113) in 31 ms on localhost (executor driver) (113/200)
09:20:53.710 INFO  [Executor task launch worker for task 116] org.apache.spark.executor.Executor - Running task 115.0 in stage 1.0 (TID 116)
09:20:53.710 INFO  [Executor task launch worker for task 115] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=114),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/114] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/114/1.delta
09:20:53.710 INFO  [Executor task launch worker for task 116] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=115), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/115] for update
09:20:53.710 INFO  [Executor task launch worker for task 116] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=115), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/115] for update
09:20:53.710 INFO  [Executor task launch worker for task 116] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.710 INFO  [Executor task launch worker for task 116] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.710 INFO  [Executor task launch worker for task 114] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=113),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/113]
09:20:53.710 INFO  [Executor task launch worker for task 114] org.apache.spark.executor.Executor - Finished task 113.0 in stage 1.0 (TID 114). 3322 bytes result sent to driver
09:20:53.710 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 116.0 in stage 1.0 (TID 117, localhost, executor driver, partition 116, PROCESS_LOCAL, 4726 bytes)
09:20:53.710 INFO  [Executor task launch worker for task 115] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=114),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/114]
09:20:53.727 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 113.0 in stage 1.0 (TID 114) in 32 ms on localhost (executor driver) (114/200)
09:20:53.727 INFO  [Executor task launch worker for task 115] org.apache.spark.executor.Executor - Finished task 114.0 in stage 1.0 (TID 115). 3322 bytes result sent to driver
09:20:53.727 INFO  [Executor task launch worker for task 117] org.apache.spark.executor.Executor - Running task 116.0 in stage 1.0 (TID 117)
09:20:53.729 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 117.0 in stage 1.0 (TID 118, localhost, executor driver, partition 117, PROCESS_LOCAL, 4726 bytes)
09:20:53.730 INFO  [Executor task launch worker for task 116] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=115),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/115] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/115/1.delta
09:20:53.730 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 114.0 in stage 1.0 (TID 115) in 35 ms on localhost (executor driver) (115/200)
09:20:53.731 INFO  [Executor task launch worker for task 118] org.apache.spark.executor.Executor - Running task 117.0 in stage 1.0 (TID 118)
09:20:53.731 INFO  [Executor task launch worker for task 117] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=116), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/116] for update
09:20:53.731 INFO  [Executor task launch worker for task 117] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=116), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/116] for update
09:20:53.732 INFO  [Executor task launch worker for task 117] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.733 INFO  [Executor task launch worker for task 117] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
09:20:53.734 INFO  [Executor task launch worker for task 118] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=117), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/117] for update
09:20:53.735 INFO  [Executor task launch worker for task 118] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=117), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/117] for update
09:20:53.735 INFO  [Executor task launch worker for task 116] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=115),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/115]
09:20:53.735 INFO  [Executor task launch worker for task 118] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.735 INFO  [Executor task launch worker for task 118] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.736 INFO  [Executor task launch worker for task 116] org.apache.spark.executor.Executor - Finished task 115.0 in stage 1.0 (TID 116). 3365 bytes result sent to driver
09:20:53.736 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 118.0 in stage 1.0 (TID 119, localhost, executor driver, partition 118, PROCESS_LOCAL, 4726 bytes)
09:20:53.737 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 115.0 in stage 1.0 (TID 116) in 27 ms on localhost (executor driver) (116/200)
09:20:53.737 INFO  [Executor task launch worker for task 119] org.apache.spark.executor.Executor - Running task 118.0 in stage 1.0 (TID 119)
09:20:53.741 INFO  [Executor task launch worker for task 119] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=118), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/118] for update
09:20:53.747 INFO  [Executor task launch worker for task 119] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=118), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/118] for update
09:20:53.748 INFO  [Executor task launch worker for task 119] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.748 INFO  [Executor task launch worker for task 119] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.750 INFO  [Executor task launch worker for task 118] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=117),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/117] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/117/1.delta
09:20:53.756 INFO  [Executor task launch worker for task 117] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=116),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/116] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/116/1.delta
09:20:53.757 INFO  [Executor task launch worker for task 118] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=117),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/117]
09:20:53.757 INFO  [Executor task launch worker for task 119] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=118),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/118] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/118/1.delta
09:20:53.758 INFO  [Executor task launch worker for task 118] org.apache.spark.executor.Executor - Finished task 117.0 in stage 1.0 (TID 118). 3408 bytes result sent to driver
09:20:53.758 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 119.0 in stage 1.0 (TID 120, localhost, executor driver, partition 119, PROCESS_LOCAL, 4726 bytes)
09:20:53.759 INFO  [Executor task launch worker for task 120] org.apache.spark.executor.Executor - Running task 119.0 in stage 1.0 (TID 120)
09:20:53.759 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 117.0 in stage 1.0 (TID 118) in 31 ms on localhost (executor driver) (117/200)
09:20:53.762 INFO  [Executor task launch worker for task 120] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=119), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/119] for update
09:20:53.762 INFO  [Executor task launch worker for task 120] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=119), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/119] for update
09:20:53.762 INFO  [Executor task launch worker for task 120] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.763 INFO  [Executor task launch worker for task 119] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=118),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/118]
09:20:53.763 INFO  [Executor task launch worker for task 120] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
09:20:53.763 INFO  [Executor task launch worker for task 119] org.apache.spark.executor.Executor - Finished task 118.0 in stage 1.0 (TID 119). 3408 bytes result sent to driver
09:20:53.764 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 120.0 in stage 1.0 (TID 121, localhost, executor driver, partition 120, PROCESS_LOCAL, 4726 bytes)
09:20:53.765 INFO  [Executor task launch worker for task 121] org.apache.spark.executor.Executor - Running task 120.0 in stage 1.0 (TID 121)
09:20:53.765 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 118.0 in stage 1.0 (TID 119) in 29 ms on localhost (executor driver) (118/200)
09:20:53.766 INFO  [Executor task launch worker for task 117] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=116),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/116]
09:20:53.767 INFO  [Executor task launch worker for task 117] org.apache.spark.executor.Executor - Finished task 116.0 in stage 1.0 (TID 117). 3408 bytes result sent to driver
09:20:53.768 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 121.0 in stage 1.0 (TID 122, localhost, executor driver, partition 121, PROCESS_LOCAL, 4726 bytes)
09:20:53.768 INFO  [Executor task launch worker for task 122] org.apache.spark.executor.Executor - Running task 121.0 in stage 1.0 (TID 122)
09:20:53.768 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 116.0 in stage 1.0 (TID 117) in 58 ms on localhost (executor driver) (119/200)
09:20:53.770 INFO  [Executor task launch worker for task 121] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=120), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/120] for update
09:20:53.770 INFO  [Executor task launch worker for task 120] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=119),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/119] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/119/1.delta
09:20:53.770 INFO  [Executor task launch worker for task 121] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=120), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/120] for update
09:20:53.770 INFO  [Executor task launch worker for task 122] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=121), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/121] for update
09:20:53.770 INFO  [Executor task launch worker for task 122] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=121), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/121] for update
09:20:53.770 INFO  [Executor task launch worker for task 121] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.770 INFO  [Executor task launch worker for task 121] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.770 INFO  [Executor task launch worker for task 122] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.770 INFO  [Executor task launch worker for task 122] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.770 INFO  [Executor task launch worker for task 120] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=119),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/119]
09:20:53.770 INFO  [Executor task launch worker for task 120] org.apache.spark.executor.Executor - Finished task 119.0 in stage 1.0 (TID 120). 3408 bytes result sent to driver
09:20:53.770 INFO  [Executor task launch worker for task 122] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=121),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/121] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/121/1.delta
09:20:53.770 INFO  [Executor task launch worker for task 121] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=120),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/120] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/120/1.delta
09:20:53.786 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 122.0 in stage 1.0 (TID 123, localhost, executor driver, partition 122, PROCESS_LOCAL, 4726 bytes)
09:20:53.786 INFO  [Executor task launch worker for task 123] org.apache.spark.executor.Executor - Running task 122.0 in stage 1.0 (TID 123)
09:20:53.786 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 119.0 in stage 1.0 (TID 120) in 28 ms on localhost (executor driver) (120/200)
09:20:53.786 INFO  [Executor task launch worker for task 123] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=122), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/122] for update
09:20:53.786 INFO  [Executor task launch worker for task 123] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=122), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/122] for update
09:20:53.786 INFO  [Executor task launch worker for task 123] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.786 INFO  [Executor task launch worker for task 123] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.786 INFO  [Executor task launch worker for task 121] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=120),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/120]
09:20:53.786 INFO  [Executor task launch worker for task 121] org.apache.spark.executor.Executor - Finished task 120.0 in stage 1.0 (TID 121). 3365 bytes result sent to driver
09:20:53.786 INFO  [Executor task launch worker for task 122] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=121),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/121]
09:20:53.786 INFO  [Executor task launch worker for task 122] org.apache.spark.executor.Executor - Finished task 121.0 in stage 1.0 (TID 122). 3408 bytes result sent to driver
09:20:53.786 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 123.0 in stage 1.0 (TID 124, localhost, executor driver, partition 123, PROCESS_LOCAL, 4726 bytes)
09:20:53.786 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 124.0 in stage 1.0 (TID 125, localhost, executor driver, partition 124, PROCESS_LOCAL, 4726 bytes)
09:20:53.786 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 120.0 in stage 1.0 (TID 121) in 23 ms on localhost (executor driver) (121/200)
09:20:53.786 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 121.0 in stage 1.0 (TID 122) in 19 ms on localhost (executor driver) (122/200)
09:20:53.786 INFO  [Executor task launch worker for task 123] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=122),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/122] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/122/1.delta
09:20:53.786 INFO  [Executor task launch worker for task 125] org.apache.spark.executor.Executor - Running task 124.0 in stage 1.0 (TID 125)
09:20:53.786 INFO  [Executor task launch worker for task 124] org.apache.spark.executor.Executor - Running task 123.0 in stage 1.0 (TID 124)
09:20:53.802 INFO  [Executor task launch worker for task 125] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=124), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/124] for update
09:20:53.802 INFO  [Executor task launch worker for task 125] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=124), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/124] for update
09:20:53.802 INFO  [Executor task launch worker for task 125] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.802 INFO  [Executor task launch worker for task 125] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.802 INFO  [Executor task launch worker for task 124] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=123), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/123] for update
09:20:53.802 INFO  [Executor task launch worker for task 124] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=123), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/123] for update
09:20:53.802 INFO  [Executor task launch worker for task 123] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=122),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/122]
09:20:53.802 INFO  [Executor task launch worker for task 124] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.802 INFO  [Executor task launch worker for task 124] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.802 INFO  [Executor task launch worker for task 123] org.apache.spark.executor.Executor - Finished task 122.0 in stage 1.0 (TID 123). 3322 bytes result sent to driver
09:20:53.802 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 125.0 in stage 1.0 (TID 126, localhost, executor driver, partition 125, PROCESS_LOCAL, 4726 bytes)
09:20:53.802 INFO  [Executor task launch worker for task 126] org.apache.spark.executor.Executor - Running task 125.0 in stage 1.0 (TID 126)
09:20:53.802 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 122.0 in stage 1.0 (TID 123) in 16 ms on localhost (executor driver) (123/200)
09:20:53.802 INFO  [Executor task launch worker for task 126] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=125), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/125] for update
09:20:53.802 INFO  [Executor task launch worker for task 126] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=125), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/125] for update
09:20:53.802 INFO  [Executor task launch worker for task 125] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=124),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/124] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/124/1.delta
09:20:53.802 INFO  [Executor task launch worker for task 124] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=123),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/123] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/123/1.delta
09:20:53.817 INFO  [Executor task launch worker for task 126] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.817 INFO  [Executor task launch worker for task 126] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.817 INFO  [Executor task launch worker for task 124] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=123),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/123]
09:20:53.817 INFO  [Executor task launch worker for task 124] org.apache.spark.executor.Executor - Finished task 123.0 in stage 1.0 (TID 124). 3365 bytes result sent to driver
09:20:53.817 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 126.0 in stage 1.0 (TID 127, localhost, executor driver, partition 126, PROCESS_LOCAL, 4726 bytes)
09:20:53.817 INFO  [Executor task launch worker for task 127] org.apache.spark.executor.Executor - Running task 126.0 in stage 1.0 (TID 127)
09:20:53.817 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 123.0 in stage 1.0 (TID 124) in 31 ms on localhost (executor driver) (124/200)
09:20:53.817 INFO  [Executor task launch worker for task 127] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=126), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/126] for update
09:20:53.817 INFO  [Executor task launch worker for task 127] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=126), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/126] for update
09:20:53.817 INFO  [Executor task launch worker for task 127] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.817 INFO  [Executor task launch worker for task 127] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.833 INFO  [Executor task launch worker for task 127] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=126),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/126] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/126/1.delta
09:20:53.833 INFO  [Executor task launch worker for task 127] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=126),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/126]
09:20:53.833 INFO  [Executor task launch worker for task 127] org.apache.spark.executor.Executor - Finished task 126.0 in stage 1.0 (TID 127). 3365 bytes result sent to driver
09:20:53.833 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 127.0 in stage 1.0 (TID 128, localhost, executor driver, partition 127, PROCESS_LOCAL, 4726 bytes)
09:20:53.833 INFO  [Executor task launch worker for task 128] org.apache.spark.executor.Executor - Running task 127.0 in stage 1.0 (TID 128)
09:20:53.833 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 126.0 in stage 1.0 (TID 127) in 16 ms on localhost (executor driver) (125/200)
09:20:53.833 INFO  [Executor task launch worker for task 126] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=125),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/125] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/125/1.delta
09:20:53.833 INFO  [Executor task launch worker for task 128] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=127), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/127] for update
09:20:53.833 INFO  [Executor task launch worker for task 128] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=127), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/127] for update
09:20:53.833 INFO  [Executor task launch worker for task 128] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.833 INFO  [Executor task launch worker for task 128] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.849 INFO  [Executor task launch worker for task 125] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=124),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/124]
09:20:53.849 INFO  [Executor task launch worker for task 125] org.apache.spark.executor.Executor - Finished task 124.0 in stage 1.0 (TID 125). 3408 bytes result sent to driver
09:20:53.849 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 128.0 in stage 1.0 (TID 129, localhost, executor driver, partition 128, PROCESS_LOCAL, 4726 bytes)
09:20:53.849 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 124.0 in stage 1.0 (TID 125) in 63 ms on localhost (executor driver) (126/200)
09:20:53.849 INFO  [Executor task launch worker for task 129] org.apache.spark.executor.Executor - Running task 128.0 in stage 1.0 (TID 129)
09:20:53.849 INFO  [Executor task launch worker for task 126] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=125),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/125]
09:20:53.849 INFO  [Executor task launch worker for task 126] org.apache.spark.executor.Executor - Finished task 125.0 in stage 1.0 (TID 126). 3322 bytes result sent to driver
09:20:53.849 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 129.0 in stage 1.0 (TID 130, localhost, executor driver, partition 129, PROCESS_LOCAL, 4726 bytes)
09:20:53.849 INFO  [Executor task launch worker for task 129] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=128), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/128] for update
09:20:53.849 INFO  [Executor task launch worker for task 130] org.apache.spark.executor.Executor - Running task 129.0 in stage 1.0 (TID 130)
09:20:53.849 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 125.0 in stage 1.0 (TID 126) in 47 ms on localhost (executor driver) (127/200)
09:20:53.849 INFO  [Executor task launch worker for task 129] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=128), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/128] for update
09:20:53.849 INFO  [Executor task launch worker for task 129] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.849 INFO  [Executor task launch worker for task 129] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.849 INFO  [Executor task launch worker for task 130] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=129), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/129] for update
09:20:53.849 INFO  [Executor task launch worker for task 130] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=129), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/129] for update
09:20:53.849 INFO  [Executor task launch worker for task 130] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.864 INFO  [Executor task launch worker for task 130] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 15 ms
09:20:53.864 INFO  [Executor task launch worker for task 129] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=128),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/128] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/128/1.delta
09:20:53.849 INFO  [Executor task launch worker for task 128] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=127),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/127] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/127/1.delta
09:20:53.864 INFO  [Executor task launch worker for task 129] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=128),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/128]
09:20:53.864 INFO  [Executor task launch worker for task 130] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=129),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/129] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/129/1.delta
09:20:53.864 INFO  [Executor task launch worker for task 129] org.apache.spark.executor.Executor - Finished task 128.0 in stage 1.0 (TID 129). 3365 bytes result sent to driver
09:20:53.864 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 130.0 in stage 1.0 (TID 131, localhost, executor driver, partition 130, PROCESS_LOCAL, 4726 bytes)
09:20:53.864 INFO  [Executor task launch worker for task 131] org.apache.spark.executor.Executor - Running task 130.0 in stage 1.0 (TID 131)
09:20:53.864 INFO  [Executor task launch worker for task 128] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=127),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/127]
09:20:53.864 INFO  [Executor task launch worker for task 128] org.apache.spark.executor.Executor - Finished task 127.0 in stage 1.0 (TID 128). 3322 bytes result sent to driver
09:20:53.864 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 128.0 in stage 1.0 (TID 129) in 15 ms on localhost (executor driver) (128/200)
09:20:53.864 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 131.0 in stage 1.0 (TID 132, localhost, executor driver, partition 131, PROCESS_LOCAL, 4726 bytes)
09:20:53.864 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 127.0 in stage 1.0 (TID 128) in 31 ms on localhost (executor driver) (129/200)
09:20:53.864 INFO  [Executor task launch worker for task 132] org.apache.spark.executor.Executor - Running task 131.0 in stage 1.0 (TID 132)
09:20:53.864 INFO  [Executor task launch worker for task 131] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=130), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/130] for update
09:20:53.864 INFO  [Executor task launch worker for task 130] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=129),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/129]
09:20:53.864 INFO  [Executor task launch worker for task 132] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=131), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/131] for update
09:20:53.880 INFO  [Executor task launch worker for task 131] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=130), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/130] for update
09:20:53.880 INFO  [Executor task launch worker for task 132] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=131), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/131] for update
09:20:53.880 INFO  [Executor task launch worker for task 132] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.880 INFO  [Executor task launch worker for task 131] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.880 INFO  [Executor task launch worker for task 130] org.apache.spark.executor.Executor - Finished task 129.0 in stage 1.0 (TID 130). 3322 bytes result sent to driver
09:20:53.880 INFO  [Executor task launch worker for task 132] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.880 INFO  [Executor task launch worker for task 131] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.880 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 132.0 in stage 1.0 (TID 133, localhost, executor driver, partition 132, PROCESS_LOCAL, 4726 bytes)
09:20:53.880 INFO  [Executor task launch worker for task 133] org.apache.spark.executor.Executor - Running task 132.0 in stage 1.0 (TID 133)
09:20:53.880 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 129.0 in stage 1.0 (TID 130) in 31 ms on localhost (executor driver) (130/200)
09:20:53.880 INFO  [Executor task launch worker for task 133] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=132), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/132] for update
09:20:53.880 INFO  [Executor task launch worker for task 133] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=132), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/132] for update
09:20:53.880 INFO  [Executor task launch worker for task 133] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.880 INFO  [Executor task launch worker for task 133] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.880 INFO  [Executor task launch worker for task 131] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=130),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/130] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/130/1.delta
09:20:53.880 INFO  [Executor task launch worker for task 133] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=132),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/132] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/132/1.delta
09:20:53.895 INFO  [Executor task launch worker for task 131] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=130),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/130]
09:20:53.895 INFO  [Executor task launch worker for task 131] org.apache.spark.executor.Executor - Finished task 130.0 in stage 1.0 (TID 131). 3322 bytes result sent to driver
09:20:53.895 INFO  [Executor task launch worker for task 132] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=131),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/131] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/131/1.delta
09:20:53.895 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 133.0 in stage 1.0 (TID 134, localhost, executor driver, partition 133, PROCESS_LOCAL, 4726 bytes)
09:20:53.895 INFO  [Executor task launch worker for task 134] org.apache.spark.executor.Executor - Running task 133.0 in stage 1.0 (TID 134)
09:20:53.895 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 130.0 in stage 1.0 (TID 131) in 31 ms on localhost (executor driver) (131/200)
09:20:53.895 INFO  [Executor task launch worker for task 133] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=132),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/132]
09:20:53.895 INFO  [Executor task launch worker for task 133] org.apache.spark.executor.Executor - Finished task 132.0 in stage 1.0 (TID 133). 3322 bytes result sent to driver
09:20:53.895 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 134.0 in stage 1.0 (TID 135, localhost, executor driver, partition 134, PROCESS_LOCAL, 4726 bytes)
09:20:53.895 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 132.0 in stage 1.0 (TID 133) in 15 ms on localhost (executor driver) (132/200)
09:20:53.895 INFO  [Executor task launch worker for task 134] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=133), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/133] for update
09:20:53.895 INFO  [Executor task launch worker for task 134] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=133), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/133] for update
09:20:53.895 INFO  [Executor task launch worker for task 135] org.apache.spark.executor.Executor - Running task 134.0 in stage 1.0 (TID 135)
09:20:53.895 INFO  [Executor task launch worker for task 134] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.895 INFO  [Executor task launch worker for task 134] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.911 INFO  [Executor task launch worker for task 135] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=134), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/134] for update
09:20:53.911 INFO  [Executor task launch worker for task 135] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=134), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/134] for update
09:20:53.911 INFO  [Executor task launch worker for task 135] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.911 INFO  [Executor task launch worker for task 135] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.911 INFO  [Executor task launch worker for task 134] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=133),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/133] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/133/1.delta
09:20:53.911 INFO  [Executor task launch worker for task 132] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=131),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/131]
09:20:53.911 INFO  [Executor task launch worker for task 132] org.apache.spark.executor.Executor - Finished task 131.0 in stage 1.0 (TID 132). 3322 bytes result sent to driver
09:20:53.911 INFO  [Executor task launch worker for task 134] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=133),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/133]
09:20:53.911 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 135.0 in stage 1.0 (TID 136, localhost, executor driver, partition 135, PROCESS_LOCAL, 4726 bytes)
09:20:53.911 INFO  [Executor task launch worker for task 134] org.apache.spark.executor.Executor - Finished task 133.0 in stage 1.0 (TID 134). 3365 bytes result sent to driver
09:20:53.911 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 131.0 in stage 1.0 (TID 132) in 47 ms on localhost (executor driver) (133/200)
09:20:53.911 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 136.0 in stage 1.0 (TID 137, localhost, executor driver, partition 136, PROCESS_LOCAL, 4726 bytes)
09:20:53.911 INFO  [Executor task launch worker for task 136] org.apache.spark.executor.Executor - Running task 135.0 in stage 1.0 (TID 136)
09:20:53.911 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 133.0 in stage 1.0 (TID 134) in 16 ms on localhost (executor driver) (134/200)
09:20:53.911 INFO  [Executor task launch worker for task 137] org.apache.spark.executor.Executor - Running task 136.0 in stage 1.0 (TID 137)
09:20:53.927 INFO  [Executor task launch worker for task 137] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=136), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/136] for update
09:20:53.927 INFO  [Executor task launch worker for task 137] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=136), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/136] for update
09:20:53.927 INFO  [Executor task launch worker for task 137] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.927 INFO  [Executor task launch worker for task 137] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.927 INFO  [Executor task launch worker for task 137] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=136),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/136] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/136/1.delta
09:20:53.927 INFO  [Executor task launch worker for task 135] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=134),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/134] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/134/1.delta
09:20:53.927 INFO  [Executor task launch worker for task 136] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=135), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/135] for update
09:20:53.927 INFO  [Executor task launch worker for task 136] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=135), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/135] for update
09:20:53.927 INFO  [Executor task launch worker for task 136] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.927 INFO  [Executor task launch worker for task 136] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.942 INFO  [Executor task launch worker for task 137] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=136),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/136]
09:20:53.942 INFO  [Executor task launch worker for task 137] org.apache.spark.executor.Executor - Finished task 136.0 in stage 1.0 (TID 137). 3451 bytes result sent to driver
09:20:53.942 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 137.0 in stage 1.0 (TID 138, localhost, executor driver, partition 137, PROCESS_LOCAL, 4726 bytes)
09:20:53.942 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 136.0 in stage 1.0 (TID 137) in 31 ms on localhost (executor driver) (135/200)
09:20:53.942 INFO  [Executor task launch worker for task 138] org.apache.spark.executor.Executor - Running task 137.0 in stage 1.0 (TID 138)
09:20:53.942 INFO  [Executor task launch worker for task 136] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=135),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/135] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/135/1.delta
09:20:53.942 INFO  [Executor task launch worker for task 138] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=137), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/137] for update
09:20:53.958 INFO  [Executor task launch worker for task 138] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=137), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/137] for update
09:20:53.958 INFO  [Executor task launch worker for task 138] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.958 INFO  [Executor task launch worker for task 138] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.958 INFO  [Executor task launch worker for task 135] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=134),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/134]
09:20:53.958 INFO  [Executor task launch worker for task 135] org.apache.spark.executor.Executor - Finished task 134.0 in stage 1.0 (TID 135). 3365 bytes result sent to driver
09:20:53.958 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 138.0 in stage 1.0 (TID 139, localhost, executor driver, partition 138, PROCESS_LOCAL, 4726 bytes)
09:20:53.958 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 134.0 in stage 1.0 (TID 135) in 63 ms on localhost (executor driver) (136/200)
09:20:53.958 INFO  [Executor task launch worker for task 138] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=137),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/137] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/137/1.delta
09:20:53.958 INFO  [Executor task launch worker for task 139] org.apache.spark.executor.Executor - Running task 138.0 in stage 1.0 (TID 139)
09:20:53.958 INFO  [Executor task launch worker for task 136] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=135),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/135]
09:20:53.958 INFO  [Executor task launch worker for task 136] org.apache.spark.executor.Executor - Finished task 135.0 in stage 1.0 (TID 136). 3451 bytes result sent to driver
09:20:53.958 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 139.0 in stage 1.0 (TID 140, localhost, executor driver, partition 139, PROCESS_LOCAL, 4726 bytes)
09:20:53.958 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 135.0 in stage 1.0 (TID 136) in 47 ms on localhost (executor driver) (137/200)
09:20:53.958 INFO  [Executor task launch worker for task 140] org.apache.spark.executor.Executor - Running task 139.0 in stage 1.0 (TID 140)
09:20:53.958 INFO  [Executor task launch worker for task 139] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=138), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/138] for update
09:20:53.958 INFO  [Executor task launch worker for task 139] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=138), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/138] for update
09:20:53.958 INFO  [Executor task launch worker for task 139] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.958 INFO  [Executor task launch worker for task 139] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.958 INFO  [Executor task launch worker for task 140] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=139), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/139] for update
09:20:53.973 INFO  [Executor task launch worker for task 138] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=137),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/137]
09:20:53.973 INFO  [Executor task launch worker for task 140] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=139), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/139] for update
09:20:53.973 INFO  [Executor task launch worker for task 140] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.973 INFO  [Executor task launch worker for task 140] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.973 INFO  [Executor task launch worker for task 138] org.apache.spark.executor.Executor - Finished task 137.0 in stage 1.0 (TID 138). 3365 bytes result sent to driver
09:20:53.973 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 140.0 in stage 1.0 (TID 141, localhost, executor driver, partition 140, PROCESS_LOCAL, 4726 bytes)
09:20:53.973 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 137.0 in stage 1.0 (TID 138) in 31 ms on localhost (executor driver) (138/200)
09:20:53.973 INFO  [Executor task launch worker for task 141] org.apache.spark.executor.Executor - Running task 140.0 in stage 1.0 (TID 141)
09:20:53.973 INFO  [Executor task launch worker for task 139] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=138),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/138] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/138/1.delta
09:20:53.973 INFO  [Executor task launch worker for task 141] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=140), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/140] for update
09:20:53.973 INFO  [Executor task launch worker for task 141] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=140), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/140] for update
09:20:53.973 INFO  [Executor task launch worker for task 141] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.973 INFO  [Executor task launch worker for task 141] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.973 INFO  [Executor task launch worker for task 140] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=139),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/139] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/139/1.delta
09:20:53.973 INFO  [Executor task launch worker for task 139] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=138),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/138]
09:20:53.989 INFO  [Executor task launch worker for task 140] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=139),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/139]
09:20:53.989 INFO  [Executor task launch worker for task 139] org.apache.spark.executor.Executor - Finished task 138.0 in stage 1.0 (TID 139). 3365 bytes result sent to driver
09:20:53.989 INFO  [Executor task launch worker for task 141] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=140),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/140] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/140/1.delta
09:20:53.989 INFO  [Executor task launch worker for task 140] org.apache.spark.executor.Executor - Finished task 139.0 in stage 1.0 (TID 140). 3365 bytes result sent to driver
09:20:53.989 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 141.0 in stage 1.0 (TID 142, localhost, executor driver, partition 141, PROCESS_LOCAL, 4726 bytes)
09:20:53.989 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 142.0 in stage 1.0 (TID 143, localhost, executor driver, partition 142, PROCESS_LOCAL, 4726 bytes)
09:20:53.989 INFO  [Executor task launch worker for task 143] org.apache.spark.executor.Executor - Running task 142.0 in stage 1.0 (TID 143)
09:20:53.989 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 139.0 in stage 1.0 (TID 140) in 31 ms on localhost (executor driver) (139/200)
09:20:53.989 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 138.0 in stage 1.0 (TID 139) in 31 ms on localhost (executor driver) (140/200)
09:20:53.989 INFO  [Executor task launch worker for task 142] org.apache.spark.executor.Executor - Running task 141.0 in stage 1.0 (TID 142)
09:20:53.989 INFO  [Executor task launch worker for task 143] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=142), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/142] for update
09:20:53.989 INFO  [Executor task launch worker for task 143] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=142), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/142] for update
09:20:53.989 INFO  [Executor task launch worker for task 143] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:53.989 INFO  [Executor task launch worker for task 143] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:53.989 INFO  [Executor task launch worker for task 141] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=140),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/140]
09:20:53.989 INFO  [Executor task launch worker for task 141] org.apache.spark.executor.Executor - Finished task 140.0 in stage 1.0 (TID 141). 3365 bytes result sent to driver
09:20:53.989 INFO  [Executor task launch worker for task 142] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=141), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/141] for update
09:20:53.989 INFO  [Executor task launch worker for task 143] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=142),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/142] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/142/1.delta
09:20:53.989 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 143.0 in stage 1.0 (TID 144, localhost, executor driver, partition 143, PROCESS_LOCAL, 4726 bytes)
09:20:54.005 INFO  [Executor task launch worker for task 142] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=141), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/141] for update
09:20:54.005 INFO  [Executor task launch worker for task 144] org.apache.spark.executor.Executor - Running task 143.0 in stage 1.0 (TID 144)
09:20:54.005 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 140.0 in stage 1.0 (TID 141) in 32 ms on localhost (executor driver) (141/200)
09:20:54.005 INFO  [Executor task launch worker for task 142] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.005 INFO  [Executor task launch worker for task 142] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.005 INFO  [Executor task launch worker for task 144] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=143), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/143] for update
09:20:54.005 INFO  [Executor task launch worker for task 144] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=143), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/143] for update
09:20:54.005 INFO  [Executor task launch worker for task 144] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.005 INFO  [Executor task launch worker for task 144] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.005 INFO  [Executor task launch worker for task 143] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=142),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/142]
09:20:54.005 INFO  [Executor task launch worker for task 143] org.apache.spark.executor.Executor - Finished task 142.0 in stage 1.0 (TID 143). 3322 bytes result sent to driver
09:20:54.005 INFO  [Executor task launch worker for task 142] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=141),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/141] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/141/1.delta
09:20:54.005 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 144.0 in stage 1.0 (TID 145, localhost, executor driver, partition 144, PROCESS_LOCAL, 4726 bytes)
09:20:54.005 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 142.0 in stage 1.0 (TID 143) in 16 ms on localhost (executor driver) (142/200)
09:20:54.005 INFO  [Executor task launch worker for task 145] org.apache.spark.executor.Executor - Running task 144.0 in stage 1.0 (TID 145)
09:20:54.005 INFO  [Executor task launch worker for task 145] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=144), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/144] for update
09:20:54.005 INFO  [Executor task launch worker for task 142] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=141),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/141]
09:20:54.005 INFO  [Executor task launch worker for task 144] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=143),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/143] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/143/1.delta
09:20:54.020 INFO  [Executor task launch worker for task 145] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=144), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/144] for update
09:20:54.020 INFO  [Executor task launch worker for task 145] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.020 INFO  [Executor task launch worker for task 142] org.apache.spark.executor.Executor - Finished task 141.0 in stage 1.0 (TID 142). 3322 bytes result sent to driver
09:20:54.020 INFO  [Executor task launch worker for task 145] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.020 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 145.0 in stage 1.0 (TID 146, localhost, executor driver, partition 145, PROCESS_LOCAL, 4726 bytes)
09:20:54.020 INFO  [Executor task launch worker for task 146] org.apache.spark.executor.Executor - Running task 145.0 in stage 1.0 (TID 146)
09:20:54.020 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 141.0 in stage 1.0 (TID 142) in 31 ms on localhost (executor driver) (143/200)
09:20:54.020 INFO  [Executor task launch worker for task 146] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=145), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/145] for update
09:20:54.020 INFO  [Executor task launch worker for task 146] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=145), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/145] for update
09:20:54.020 INFO  [Executor task launch worker for task 146] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.020 INFO  [Executor task launch worker for task 146] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.020 INFO  [Executor task launch worker for task 145] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=144),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/144] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/144/1.delta
09:20:54.020 INFO  [Executor task launch worker for task 145] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=144),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/144]
09:20:54.020 INFO  [Executor task launch worker for task 144] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=143),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/143]
09:20:54.036 INFO  [Executor task launch worker for task 146] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=145),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/145] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/145/1.delta
09:20:54.036 INFO  [Executor task launch worker for task 145] org.apache.spark.executor.Executor - Finished task 144.0 in stage 1.0 (TID 145). 3322 bytes result sent to driver
09:20:54.036 INFO  [Executor task launch worker for task 144] org.apache.spark.executor.Executor - Finished task 143.0 in stage 1.0 (TID 144). 3322 bytes result sent to driver
09:20:54.036 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 146.0 in stage 1.0 (TID 147, localhost, executor driver, partition 146, PROCESS_LOCAL, 4726 bytes)
09:20:54.036 INFO  [Executor task launch worker for task 147] org.apache.spark.executor.Executor - Running task 146.0 in stage 1.0 (TID 147)
09:20:54.036 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 147.0 in stage 1.0 (TID 148, localhost, executor driver, partition 147, PROCESS_LOCAL, 4726 bytes)
09:20:54.036 INFO  [Executor task launch worker for task 148] org.apache.spark.executor.Executor - Running task 147.0 in stage 1.0 (TID 148)
09:20:54.036 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 144.0 in stage 1.0 (TID 145) in 31 ms on localhost (executor driver) (144/200)
09:20:54.036 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 143.0 in stage 1.0 (TID 144) in 47 ms on localhost (executor driver) (145/200)
09:20:54.036 INFO  [Executor task launch worker for task 148] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=147), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/147] for update
09:20:54.036 INFO  [Executor task launch worker for task 148] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=147), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/147] for update
09:20:54.036 INFO  [Executor task launch worker for task 148] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.036 INFO  [Executor task launch worker for task 148] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.036 INFO  [Executor task launch worker for task 147] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=146), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/146] for update
09:20:54.036 INFO  [Executor task launch worker for task 147] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=146), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/146] for update
09:20:54.036 INFO  [Executor task launch worker for task 146] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=145),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/145]
09:20:54.036 INFO  [Executor task launch worker for task 148] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=147),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/147] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/147/1.delta
09:20:54.052 INFO  [Executor task launch worker for task 147] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.052 INFO  [Executor task launch worker for task 147] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.052 INFO  [Executor task launch worker for task 146] org.apache.spark.executor.Executor - Finished task 145.0 in stage 1.0 (TID 146). 3365 bytes result sent to driver
09:20:54.052 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 148.0 in stage 1.0 (TID 149, localhost, executor driver, partition 148, PROCESS_LOCAL, 4726 bytes)
09:20:54.052 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 145.0 in stage 1.0 (TID 146) in 32 ms on localhost (executor driver) (146/200)
09:20:54.052 INFO  [Executor task launch worker for task 149] org.apache.spark.executor.Executor - Running task 148.0 in stage 1.0 (TID 149)
09:20:54.052 INFO  [Executor task launch worker for task 149] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=148), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/148] for update
09:20:54.052 INFO  [Executor task launch worker for task 149] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=148), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/148] for update
09:20:54.052 INFO  [Executor task launch worker for task 149] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.052 INFO  [Executor task launch worker for task 149] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.052 INFO  [Executor task launch worker for task 148] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=147),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/147]
09:20:54.052 INFO  [Executor task launch worker for task 148] org.apache.spark.executor.Executor - Finished task 147.0 in stage 1.0 (TID 148). 3322 bytes result sent to driver
09:20:54.052 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 149.0 in stage 1.0 (TID 150, localhost, executor driver, partition 149, PROCESS_LOCAL, 4726 bytes)
09:20:54.052 INFO  [Executor task launch worker for task 150] org.apache.spark.executor.Executor - Running task 149.0 in stage 1.0 (TID 150)
09:20:54.052 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 147.0 in stage 1.0 (TID 148) in 16 ms on localhost (executor driver) (147/200)
09:20:54.052 INFO  [Executor task launch worker for task 147] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=146),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/146] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/146/1.delta
09:20:54.052 INFO  [Executor task launch worker for task 150] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=149), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/149] for update
09:20:54.052 INFO  [Executor task launch worker for task 149] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=148),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/148] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/148/1.delta
09:20:54.052 INFO  [Executor task launch worker for task 147] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=146),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/146]
09:20:54.067 INFO  [Executor task launch worker for task 150] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=149), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/149] for update
09:20:54.067 INFO  [Executor task launch worker for task 150] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.067 INFO  [Executor task launch worker for task 150] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.067 INFO  [Executor task launch worker for task 147] org.apache.spark.executor.Executor - Finished task 146.0 in stage 1.0 (TID 147). 3322 bytes result sent to driver
09:20:54.067 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 150.0 in stage 1.0 (TID 151, localhost, executor driver, partition 150, PROCESS_LOCAL, 4726 bytes)
09:20:54.067 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 146.0 in stage 1.0 (TID 147) in 31 ms on localhost (executor driver) (148/200)
09:20:54.067 INFO  [Executor task launch worker for task 151] org.apache.spark.executor.Executor - Running task 150.0 in stage 1.0 (TID 151)
09:20:54.067 INFO  [Executor task launch worker for task 151] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=150), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/150] for update
09:20:54.067 INFO  [Executor task launch worker for task 151] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=150), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/150] for update
09:20:54.067 INFO  [Executor task launch worker for task 151] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.067 INFO  [Executor task launch worker for task 151] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.067 INFO  [Executor task launch worker for task 149] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=148),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/148]
09:20:54.067 INFO  [Executor task launch worker for task 149] org.apache.spark.executor.Executor - Finished task 148.0 in stage 1.0 (TID 149). 3322 bytes result sent to driver
09:20:54.067 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 151.0 in stage 1.0 (TID 152, localhost, executor driver, partition 151, PROCESS_LOCAL, 4726 bytes)
09:20:54.067 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 148.0 in stage 1.0 (TID 149) in 15 ms on localhost (executor driver) (149/200)
09:20:54.067 INFO  [Executor task launch worker for task 152] org.apache.spark.executor.Executor - Running task 151.0 in stage 1.0 (TID 152)
09:20:54.067 INFO  [Executor task launch worker for task 150] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=149),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/149] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/149/1.delta
09:20:54.067 INFO  [Executor task launch worker for task 152] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=151), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/151] for update
09:20:54.067 INFO  [Executor task launch worker for task 151] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=150),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/150] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/150/1.delta
09:20:54.083 INFO  [Executor task launch worker for task 152] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=151), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/151] for update
09:20:54.083 INFO  [Executor task launch worker for task 152] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.083 INFO  [Executor task launch worker for task 152] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.083 INFO  [Executor task launch worker for task 151] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=150),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/150]
09:20:54.083 INFO  [Executor task launch worker for task 150] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=149),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/149]
09:20:54.083 INFO  [Executor task launch worker for task 151] org.apache.spark.executor.Executor - Finished task 150.0 in stage 1.0 (TID 151). 3322 bytes result sent to driver
09:20:54.083 INFO  [Executor task launch worker for task 150] org.apache.spark.executor.Executor - Finished task 149.0 in stage 1.0 (TID 150). 3322 bytes result sent to driver
09:20:54.083 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 152.0 in stage 1.0 (TID 153, localhost, executor driver, partition 152, PROCESS_LOCAL, 4726 bytes)
09:20:54.083 INFO  [Executor task launch worker for task 153] org.apache.spark.executor.Executor - Running task 152.0 in stage 1.0 (TID 153)
09:20:54.083 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 153.0 in stage 1.0 (TID 154, localhost, executor driver, partition 153, PROCESS_LOCAL, 4726 bytes)
09:20:54.083 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 150.0 in stage 1.0 (TID 151) in 16 ms on localhost (executor driver) (150/200)
09:20:54.083 INFO  [Executor task launch worker for task 154] org.apache.spark.executor.Executor - Running task 153.0 in stage 1.0 (TID 154)
09:20:54.083 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 149.0 in stage 1.0 (TID 150) in 31 ms on localhost (executor driver) (151/200)
09:20:54.083 INFO  [Executor task launch worker for task 153] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=152), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/152] for update
09:20:54.083 INFO  [Executor task launch worker for task 153] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=152), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/152] for update
09:20:54.083 INFO  [Executor task launch worker for task 152] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=151),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/151] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/151/1.delta
09:20:54.083 INFO  [Executor task launch worker for task 153] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.083 INFO  [Executor task launch worker for task 154] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=153), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/153] for update
09:20:54.098 INFO  [Executor task launch worker for task 153] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 15 ms
09:20:54.098 INFO  [Executor task launch worker for task 154] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=153), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/153] for update
09:20:54.098 INFO  [Executor task launch worker for task 154] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.098 INFO  [Executor task launch worker for task 154] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.098 INFO  [Executor task launch worker for task 152] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=151),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/151]
09:20:54.098 INFO  [Executor task launch worker for task 152] org.apache.spark.executor.Executor - Finished task 151.0 in stage 1.0 (TID 152). 3322 bytes result sent to driver
09:20:54.098 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 154.0 in stage 1.0 (TID 155, localhost, executor driver, partition 154, PROCESS_LOCAL, 4726 bytes)
09:20:54.098 INFO  [Executor task launch worker for task 155] org.apache.spark.executor.Executor - Running task 154.0 in stage 1.0 (TID 155)
09:20:54.098 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 151.0 in stage 1.0 (TID 152) in 31 ms on localhost (executor driver) (152/200)
09:20:54.098 INFO  [Executor task launch worker for task 154] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=153),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/153] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/153/1.delta
09:20:54.098 INFO  [Executor task launch worker for task 153] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=152),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/152] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/152/1.delta
09:20:54.098 INFO  [Executor task launch worker for task 155] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=154), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/154] for update
09:20:54.098 INFO  [Executor task launch worker for task 155] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=154), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/154] for update
09:20:54.098 INFO  [Executor task launch worker for task 155] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.098 INFO  [Executor task launch worker for task 155] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.098 INFO  [Executor task launch worker for task 153] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=152),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/152]
09:20:54.114 INFO  [Executor task launch worker for task 153] org.apache.spark.executor.Executor - Finished task 152.0 in stage 1.0 (TID 153). 3322 bytes result sent to driver
09:20:54.114 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 155.0 in stage 1.0 (TID 156, localhost, executor driver, partition 155, PROCESS_LOCAL, 4726 bytes)
09:20:54.114 INFO  [Executor task launch worker for task 156] org.apache.spark.executor.Executor - Running task 155.0 in stage 1.0 (TID 156)
09:20:54.114 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 152.0 in stage 1.0 (TID 153) in 31 ms on localhost (executor driver) (153/200)
09:20:54.114 INFO  [Executor task launch worker for task 154] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=153),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/153]
09:20:54.114 INFO  [Executor task launch worker for task 154] org.apache.spark.executor.Executor - Finished task 153.0 in stage 1.0 (TID 154). 3365 bytes result sent to driver
09:20:54.114 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 157.0 in stage 1.0 (TID 157, localhost, executor driver, partition 157, PROCESS_LOCAL, 4726 bytes)
09:20:54.114 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 153.0 in stage 1.0 (TID 154) in 31 ms on localhost (executor driver) (154/200)
09:20:54.114 INFO  [Executor task launch worker for task 157] org.apache.spark.executor.Executor - Running task 157.0 in stage 1.0 (TID 157)
09:20:54.114 INFO  [Executor task launch worker for task 156] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=155), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/155] for update
09:20:54.114 INFO  [Executor task launch worker for task 156] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=155), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/155] for update
09:20:54.114 INFO  [Executor task launch worker for task 156] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.114 INFO  [Executor task launch worker for task 156] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.114 INFO  [Executor task launch worker for task 155] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=154),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/154] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/154/1.delta
09:20:54.114 INFO  [Executor task launch worker for task 157] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=157), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/157] for update
09:20:54.114 INFO  [Executor task launch worker for task 157] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=157), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/157] for update
09:20:54.114 INFO  [Executor task launch worker for task 155] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=154),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/154]
09:20:54.114 INFO  [Executor task launch worker for task 156] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=155),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/155] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/155/1.delta
09:20:54.130 INFO  [Executor task launch worker for task 157] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.130 INFO  [Executor task launch worker for task 157] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.130 INFO  [Executor task launch worker for task 155] org.apache.spark.executor.Executor - Finished task 154.0 in stage 1.0 (TID 155). 3365 bytes result sent to driver
09:20:54.130 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 158.0 in stage 1.0 (TID 158, localhost, executor driver, partition 158, PROCESS_LOCAL, 4726 bytes)
09:20:54.130 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 154.0 in stage 1.0 (TID 155) in 32 ms on localhost (executor driver) (155/200)
09:20:54.130 INFO  [Executor task launch worker for task 158] org.apache.spark.executor.Executor - Running task 158.0 in stage 1.0 (TID 158)
09:20:54.130 INFO  [Executor task launch worker for task 158] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=158), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/158] for update
09:20:54.130 INFO  [Executor task launch worker for task 158] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=158), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/158] for update
09:20:54.130 INFO  [Executor task launch worker for task 158] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.130 INFO  [Executor task launch worker for task 156] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=155),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/155]
09:20:54.130 INFO  [Executor task launch worker for task 158] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.130 INFO  [Executor task launch worker for task 156] org.apache.spark.executor.Executor - Finished task 155.0 in stage 1.0 (TID 156). 3322 bytes result sent to driver
09:20:54.130 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 159.0 in stage 1.0 (TID 159, localhost, executor driver, partition 159, PROCESS_LOCAL, 4726 bytes)
09:20:54.130 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 155.0 in stage 1.0 (TID 156) in 16 ms on localhost (executor driver) (156/200)
09:20:54.130 INFO  [Executor task launch worker for task 159] org.apache.spark.executor.Executor - Running task 159.0 in stage 1.0 (TID 159)
09:20:54.130 INFO  [Executor task launch worker for task 157] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=157),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/157] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/157/1.delta
09:20:54.130 INFO  [Executor task launch worker for task 158] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=158),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/158] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/158/1.delta
09:20:54.145 INFO  [Executor task launch worker for task 159] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=159), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/159] for update
09:20:54.145 INFO  [Executor task launch worker for task 159] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=159), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/159] for update
09:20:54.145 INFO  [Executor task launch worker for task 159] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.145 INFO  [Executor task launch worker for task 159] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.145 INFO  [Executor task launch worker for task 157] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=157),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/157]
09:20:54.145 INFO  [Executor task launch worker for task 157] org.apache.spark.executor.Executor - Finished task 157.0 in stage 1.0 (TID 157). 3322 bytes result sent to driver
09:20:54.145 INFO  [Executor task launch worker for task 158] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=158),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/158]
09:20:54.145 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 160.0 in stage 1.0 (TID 160, localhost, executor driver, partition 160, PROCESS_LOCAL, 4726 bytes)
09:20:54.145 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 157.0 in stage 1.0 (TID 157) in 31 ms on localhost (executor driver) (157/200)
09:20:54.145 INFO  [Executor task launch worker for task 160] org.apache.spark.executor.Executor - Running task 160.0 in stage 1.0 (TID 160)
09:20:54.145 INFO  [Executor task launch worker for task 158] org.apache.spark.executor.Executor - Finished task 158.0 in stage 1.0 (TID 158). 3322 bytes result sent to driver
09:20:54.145 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 161.0 in stage 1.0 (TID 161, localhost, executor driver, partition 161, PROCESS_LOCAL, 4726 bytes)
09:20:54.145 INFO  [Executor task launch worker for task 161] org.apache.spark.executor.Executor - Running task 161.0 in stage 1.0 (TID 161)
09:20:54.145 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 158.0 in stage 1.0 (TID 158) in 15 ms on localhost (executor driver) (158/200)
09:20:54.145 INFO  [Executor task launch worker for task 161] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=161), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/161] for update
09:20:54.145 INFO  [Executor task launch worker for task 160] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=160), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/160] for update
09:20:54.145 INFO  [Executor task launch worker for task 159] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=159),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/159] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/159/1.delta
09:20:54.161 INFO  [Executor task launch worker for task 161] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=161), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/161] for update
09:20:54.161 INFO  [Executor task launch worker for task 160] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=160), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/160] for update
09:20:54.161 INFO  [Executor task launch worker for task 161] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.161 INFO  [Executor task launch worker for task 160] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.161 INFO  [Executor task launch worker for task 161] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.161 INFO  [Executor task launch worker for task 160] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.192 INFO  [Executor task launch worker for task 159] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=159),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/159]
09:20:54.192 INFO  [Executor task launch worker for task 159] org.apache.spark.executor.Executor - Finished task 159.0 in stage 1.0 (TID 159). 3408 bytes result sent to driver
09:20:54.192 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 162.0 in stage 1.0 (TID 162, localhost, executor driver, partition 162, PROCESS_LOCAL, 4726 bytes)
09:20:54.192 INFO  [Executor task launch worker for task 162] org.apache.spark.executor.Executor - Running task 162.0 in stage 1.0 (TID 162)
09:20:54.192 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 159.0 in stage 1.0 (TID 159) in 62 ms on localhost (executor driver) (159/200)
09:20:54.192 INFO  [Executor task launch worker for task 162] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=162), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/162] for update
09:20:54.192 INFO  [Executor task launch worker for task 162] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=162), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/162] for update
09:20:54.192 INFO  [Executor task launch worker for task 162] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.192 INFO  [Executor task launch worker for task 162] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.192 INFO  [Executor task launch worker for task 160] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=160),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/160] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/160/1.delta
09:20:54.192 INFO  [Executor task launch worker for task 161] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=161),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/161] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/161/1.delta
09:20:54.192 INFO  [Executor task launch worker for task 162] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=162),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/162] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/162/1.delta
09:20:54.208 INFO  [Executor task launch worker for task 160] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=160),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/160]
09:20:54.208 INFO  [Executor task launch worker for task 161] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=161),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/161]
09:20:54.208 INFO  [Executor task launch worker for task 160] org.apache.spark.executor.Executor - Finished task 160.0 in stage 1.0 (TID 160). 3408 bytes result sent to driver
09:20:54.208 INFO  [Executor task launch worker for task 161] org.apache.spark.executor.Executor - Finished task 161.0 in stage 1.0 (TID 161). 3408 bytes result sent to driver
09:20:54.208 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 163.0 in stage 1.0 (TID 163, localhost, executor driver, partition 163, PROCESS_LOCAL, 4726 bytes)
09:20:54.208 INFO  [Executor task launch worker for task 163] org.apache.spark.executor.Executor - Running task 163.0 in stage 1.0 (TID 163)
09:20:54.208 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 164.0 in stage 1.0 (TID 164, localhost, executor driver, partition 164, PROCESS_LOCAL, 4726 bytes)
09:20:54.208 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 161.0 in stage 1.0 (TID 161) in 63 ms on localhost (executor driver) (160/200)
09:20:54.208 INFO  [Executor task launch worker for task 164] org.apache.spark.executor.Executor - Running task 164.0 in stage 1.0 (TID 164)
09:20:54.208 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 160.0 in stage 1.0 (TID 160) in 63 ms on localhost (executor driver) (161/200)
09:20:54.208 INFO  [Executor task launch worker for task 162] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=162),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/162]
09:20:54.208 INFO  [Executor task launch worker for task 162] org.apache.spark.executor.Executor - Finished task 162.0 in stage 1.0 (TID 162). 3365 bytes result sent to driver
09:20:54.208 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 165.0 in stage 1.0 (TID 165, localhost, executor driver, partition 165, PROCESS_LOCAL, 4726 bytes)
09:20:54.208 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 162.0 in stage 1.0 (TID 162) in 16 ms on localhost (executor driver) (162/200)
09:20:54.208 INFO  [Executor task launch worker for task 165] org.apache.spark.executor.Executor - Running task 165.0 in stage 1.0 (TID 165)
09:20:54.208 INFO  [Executor task launch worker for task 163] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=163), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/163] for update
09:20:54.208 INFO  [Executor task launch worker for task 164] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=164), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/164] for update
09:20:54.208 INFO  [Executor task launch worker for task 163] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=163), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/163] for update
09:20:54.208 INFO  [Executor task launch worker for task 165] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=165), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/165] for update
09:20:54.223 INFO  [Executor task launch worker for task 164] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=164), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/164] for update
09:20:54.223 INFO  [Executor task launch worker for task 163] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.223 INFO  [Executor task launch worker for task 165] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=165), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/165] for update
09:20:54.223 INFO  [Executor task launch worker for task 163] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.223 INFO  [Executor task launch worker for task 165] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.223 INFO  [Executor task launch worker for task 164] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.223 INFO  [Executor task launch worker for task 165] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.223 INFO  [Executor task launch worker for task 164] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.223 INFO  [Executor task launch worker for task 163] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=163),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/163] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/163/1.delta
09:20:54.239 INFO  [Executor task launch worker for task 164] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=164),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/164] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/164/1.delta
09:20:54.239 INFO  [Executor task launch worker for task 163] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=163),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/163]
09:20:54.239 INFO  [Executor task launch worker for task 165] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=165),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/165] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/165/1.delta
09:20:54.239 INFO  [Executor task launch worker for task 163] org.apache.spark.executor.Executor - Finished task 163.0 in stage 1.0 (TID 163). 3365 bytes result sent to driver
09:20:54.239 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 166.0 in stage 1.0 (TID 166, localhost, executor driver, partition 166, PROCESS_LOCAL, 4726 bytes)
09:20:54.239 INFO  [Executor task launch worker for task 166] org.apache.spark.executor.Executor - Running task 166.0 in stage 1.0 (TID 166)
09:20:54.239 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 163.0 in stage 1.0 (TID 163) in 31 ms on localhost (executor driver) (163/200)
09:20:54.239 INFO  [Executor task launch worker for task 164] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=164),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/164]
09:20:54.239 INFO  [Executor task launch worker for task 164] org.apache.spark.executor.Executor - Finished task 164.0 in stage 1.0 (TID 164). 3365 bytes result sent to driver
09:20:54.239 INFO  [Executor task launch worker for task 165] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=165),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/165]
09:20:54.239 INFO  [Executor task launch worker for task 165] org.apache.spark.executor.Executor - Finished task 165.0 in stage 1.0 (TID 165). 3365 bytes result sent to driver
09:20:54.239 INFO  [Executor task launch worker for task 166] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=166), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/166] for update
09:20:54.239 INFO  [Executor task launch worker for task 166] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=166), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/166] for update
09:20:54.239 INFO  [Executor task launch worker for task 166] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.239 INFO  [Executor task launch worker for task 166] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.239 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 167.0 in stage 1.0 (TID 167, localhost, executor driver, partition 167, PROCESS_LOCAL, 4726 bytes)
09:20:54.255 INFO  [Executor task launch worker for task 167] org.apache.spark.executor.Executor - Running task 167.0 in stage 1.0 (TID 167)
09:20:54.255 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 164.0 in stage 1.0 (TID 164) in 47 ms on localhost (executor driver) (164/200)
09:20:54.255 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 168.0 in stage 1.0 (TID 168, localhost, executor driver, partition 168, PROCESS_LOCAL, 4726 bytes)
09:20:54.255 INFO  [Executor task launch worker for task 168] org.apache.spark.executor.Executor - Running task 168.0 in stage 1.0 (TID 168)
09:20:54.255 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 165.0 in stage 1.0 (TID 165) in 47 ms on localhost (executor driver) (165/200)
09:20:54.255 INFO  [Executor task launch worker for task 167] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=167), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/167] for update
09:20:54.255 INFO  [Executor task launch worker for task 168] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=168), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/168] for update
09:20:54.255 INFO  [Executor task launch worker for task 167] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=167), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/167] for update
09:20:54.255 INFO  [Executor task launch worker for task 168] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=168), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/168] for update
09:20:54.255 INFO  [Executor task launch worker for task 167] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.255 INFO  [Executor task launch worker for task 168] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.255 INFO  [Executor task launch worker for task 167] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.255 INFO  [Executor task launch worker for task 168] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.255 INFO  [Executor task launch worker for task 166] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=166),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/166] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/166/1.delta
09:20:54.255 INFO  [Executor task launch worker for task 168] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=168),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/168] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/168/1.delta
09:20:54.255 INFO  [Executor task launch worker for task 167] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=167),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/167] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/167/1.delta
09:20:54.255 INFO  [Executor task launch worker for task 166] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=166),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/166]
09:20:54.255 INFO  [Executor task launch worker for task 168] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=168),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/168]
09:20:54.270 INFO  [Executor task launch worker for task 168] org.apache.spark.executor.Executor - Finished task 168.0 in stage 1.0 (TID 168). 3322 bytes result sent to driver
09:20:54.270 INFO  [Executor task launch worker for task 166] org.apache.spark.executor.Executor - Finished task 166.0 in stage 1.0 (TID 166). 3322 bytes result sent to driver
09:20:54.270 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 169.0 in stage 1.0 (TID 169, localhost, executor driver, partition 169, PROCESS_LOCAL, 4726 bytes)
09:20:54.270 INFO  [Executor task launch worker for task 169] org.apache.spark.executor.Executor - Running task 169.0 in stage 1.0 (TID 169)
09:20:54.270 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 170.0 in stage 1.0 (TID 170, localhost, executor driver, partition 170, PROCESS_LOCAL, 4726 bytes)
09:20:54.270 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 168.0 in stage 1.0 (TID 168) in 15 ms on localhost (executor driver) (166/200)
09:20:54.270 INFO  [Executor task launch worker for task 170] org.apache.spark.executor.Executor - Running task 170.0 in stage 1.0 (TID 170)
09:20:54.270 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 166.0 in stage 1.0 (TID 166) in 31 ms on localhost (executor driver) (167/200)
09:20:54.270 INFO  [Executor task launch worker for task 170] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=170), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/170] for update
09:20:54.270 INFO  [Executor task launch worker for task 169] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=169), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/169] for update
09:20:54.270 INFO  [Executor task launch worker for task 170] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=170), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/170] for update
09:20:54.270 INFO  [Executor task launch worker for task 169] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=169), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/169] for update
09:20:54.270 INFO  [Executor task launch worker for task 167] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=167),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/167]
09:20:54.270 INFO  [Executor task launch worker for task 170] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.270 INFO  [Executor task launch worker for task 169] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.270 INFO  [Executor task launch worker for task 170] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.270 INFO  [Executor task launch worker for task 169] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.270 INFO  [Executor task launch worker for task 167] org.apache.spark.executor.Executor - Finished task 167.0 in stage 1.0 (TID 167). 3322 bytes result sent to driver
09:20:54.286 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 171.0 in stage 1.0 (TID 171, localhost, executor driver, partition 171, PROCESS_LOCAL, 4726 bytes)
09:20:54.286 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 167.0 in stage 1.0 (TID 167) in 47 ms on localhost (executor driver) (168/200)
09:20:54.286 INFO  [Executor task launch worker for task 171] org.apache.spark.executor.Executor - Running task 171.0 in stage 1.0 (TID 171)
09:20:54.286 INFO  [Executor task launch worker for task 171] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=171), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/171] for update
09:20:54.286 INFO  [Executor task launch worker for task 171] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=171), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/171] for update
09:20:54.286 INFO  [Executor task launch worker for task 171] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.286 INFO  [Executor task launch worker for task 171] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.286 INFO  [Executor task launch worker for task 169] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=169),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/169] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/169/1.delta
09:20:54.286 INFO  [Executor task launch worker for task 170] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=170),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/170] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/170/1.delta
09:20:54.286 INFO  [Executor task launch worker for task 171] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=171),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/171] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/171/1.delta
09:20:54.286 INFO  [Executor task launch worker for task 169] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=169),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/169]
09:20:54.286 INFO  [Executor task launch worker for task 169] org.apache.spark.executor.Executor - Finished task 169.0 in stage 1.0 (TID 169). 3322 bytes result sent to driver
09:20:54.286 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 172.0 in stage 1.0 (TID 172, localhost, executor driver, partition 172, PROCESS_LOCAL, 4726 bytes)
09:20:54.286 INFO  [Executor task launch worker for task 172] org.apache.spark.executor.Executor - Running task 172.0 in stage 1.0 (TID 172)
09:20:54.286 INFO  [Executor task launch worker for task 171] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=171),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/171]
09:20:54.286 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 169.0 in stage 1.0 (TID 169) in 16 ms on localhost (executor driver) (169/200)
09:20:54.286 INFO  [Executor task launch worker for task 170] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=170),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/170]
09:20:54.302 INFO  [Executor task launch worker for task 172] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=172), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/172] for update
09:20:54.302 INFO  [Executor task launch worker for task 171] org.apache.spark.executor.Executor - Finished task 171.0 in stage 1.0 (TID 171). 3322 bytes result sent to driver
09:20:54.302 INFO  [Executor task launch worker for task 172] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=172), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/172] for update
09:20:54.302 INFO  [Executor task launch worker for task 172] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.302 INFO  [Executor task launch worker for task 170] org.apache.spark.executor.Executor - Finished task 170.0 in stage 1.0 (TID 170). 3322 bytes result sent to driver
09:20:54.302 INFO  [Executor task launch worker for task 172] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.302 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 173.0 in stage 1.0 (TID 173, localhost, executor driver, partition 173, PROCESS_LOCAL, 4726 bytes)
09:20:54.302 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 174.0 in stage 1.0 (TID 174, localhost, executor driver, partition 174, PROCESS_LOCAL, 4726 bytes)
09:20:54.302 INFO  [Executor task launch worker for task 174] org.apache.spark.executor.Executor - Running task 174.0 in stage 1.0 (TID 174)
09:20:54.302 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 171.0 in stage 1.0 (TID 171) in 16 ms on localhost (executor driver) (170/200)
09:20:54.302 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 170.0 in stage 1.0 (TID 170) in 32 ms on localhost (executor driver) (171/200)
09:20:54.302 INFO  [Executor task launch worker for task 173] org.apache.spark.executor.Executor - Running task 173.0 in stage 1.0 (TID 173)
09:20:54.302 INFO  [Executor task launch worker for task 174] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=174), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/174] for update
09:20:54.302 INFO  [Executor task launch worker for task 174] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=174), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/174] for update
09:20:54.302 INFO  [Executor task launch worker for task 174] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.302 INFO  [Executor task launch worker for task 172] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=172),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/172] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/172/1.delta
09:20:54.302 INFO  [Executor task launch worker for task 173] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=173), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/173] for update
09:20:54.317 INFO  [Executor task launch worker for task 174] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 15 ms
09:20:54.317 INFO  [Executor task launch worker for task 173] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=173), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/173] for update
09:20:54.317 INFO  [Executor task launch worker for task 173] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.317 INFO  [Executor task launch worker for task 173] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.317 INFO  [Executor task launch worker for task 172] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=172),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/172]
09:20:54.317 INFO  [Executor task launch worker for task 172] org.apache.spark.executor.Executor - Finished task 172.0 in stage 1.0 (TID 172). 3365 bytes result sent to driver
09:20:54.317 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 175.0 in stage 1.0 (TID 175, localhost, executor driver, partition 175, PROCESS_LOCAL, 4726 bytes)
09:20:54.317 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 172.0 in stage 1.0 (TID 172) in 31 ms on localhost (executor driver) (172/200)
09:20:54.317 INFO  [Executor task launch worker for task 175] org.apache.spark.executor.Executor - Running task 175.0 in stage 1.0 (TID 175)
09:20:54.317 INFO  [Executor task launch worker for task 174] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=174),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/174] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/174/1.delta
09:20:54.317 INFO  [Executor task launch worker for task 173] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=173),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/173] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/173/1.delta
09:20:54.317 INFO  [Executor task launch worker for task 175] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=175), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/175] for update
09:20:54.317 INFO  [Executor task launch worker for task 175] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=175), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/175] for update
09:20:54.317 INFO  [Executor task launch worker for task 175] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.317 INFO  [Executor task launch worker for task 175] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.317 INFO  [Executor task launch worker for task 173] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=173),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/173]
09:20:54.317 INFO  [Executor task launch worker for task 174] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=174),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/174]
09:20:54.333 INFO  [Executor task launch worker for task 174] org.apache.spark.executor.Executor - Finished task 174.0 in stage 1.0 (TID 174). 3322 bytes result sent to driver
09:20:54.333 INFO  [Executor task launch worker for task 173] org.apache.spark.executor.Executor - Finished task 173.0 in stage 1.0 (TID 173). 3322 bytes result sent to driver
09:20:54.333 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 176.0 in stage 1.0 (TID 176, localhost, executor driver, partition 176, PROCESS_LOCAL, 4726 bytes)
09:20:54.333 INFO  [Executor task launch worker for task 176] org.apache.spark.executor.Executor - Running task 176.0 in stage 1.0 (TID 176)
09:20:54.333 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 174.0 in stage 1.0 (TID 174) in 31 ms on localhost (executor driver) (173/200)
09:20:54.333 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 177.0 in stage 1.0 (TID 177, localhost, executor driver, partition 177, PROCESS_LOCAL, 4726 bytes)
09:20:54.333 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 173.0 in stage 1.0 (TID 173) in 31 ms on localhost (executor driver) (174/200)
09:20:54.333 INFO  [Executor task launch worker for task 177] org.apache.spark.executor.Executor - Running task 177.0 in stage 1.0 (TID 177)
09:20:54.333 INFO  [Executor task launch worker for task 175] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=175),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/175] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/175/1.delta
09:20:54.333 INFO  [Executor task launch worker for task 176] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=176), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/176] for update
09:20:54.333 INFO  [Executor task launch worker for task 177] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=177), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/177] for update
09:20:54.333 INFO  [Executor task launch worker for task 176] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=176), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/176] for update
09:20:54.333 INFO  [Executor task launch worker for task 177] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=177), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/177] for update
09:20:54.333 INFO  [Executor task launch worker for task 177] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.333 INFO  [Executor task launch worker for task 176] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.333 INFO  [Executor task launch worker for task 177] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.333 INFO  [Executor task launch worker for task 175] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=175),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/175]
09:20:54.348 INFO  [Executor task launch worker for task 176] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 15 ms
09:20:54.348 INFO  [Executor task launch worker for task 175] org.apache.spark.executor.Executor - Finished task 175.0 in stage 1.0 (TID 175). 3365 bytes result sent to driver
09:20:54.348 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 178.0 in stage 1.0 (TID 178, localhost, executor driver, partition 178, PROCESS_LOCAL, 4726 bytes)
09:20:54.348 INFO  [Executor task launch worker for task 178] org.apache.spark.executor.Executor - Running task 178.0 in stage 1.0 (TID 178)
09:20:54.348 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 175.0 in stage 1.0 (TID 175) in 31 ms on localhost (executor driver) (175/200)
09:20:54.348 INFO  [Executor task launch worker for task 178] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=178), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/178] for update
09:20:54.348 INFO  [Executor task launch worker for task 178] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=178), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/178] for update
09:20:54.348 INFO  [Executor task launch worker for task 178] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.348 INFO  [Executor task launch worker for task 178] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.348 INFO  [Executor task launch worker for task 176] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=176),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/176] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/176/1.delta
09:20:54.348 INFO  [Executor task launch worker for task 177] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=177),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/177] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/177/1.delta
09:20:54.364 INFO  [Executor task launch worker for task 178] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=178),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/178] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/178/1.delta
09:20:54.364 INFO  [Executor task launch worker for task 177] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=177),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/177]
09:20:54.364 INFO  [Executor task launch worker for task 176] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=176),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/176]
09:20:54.364 INFO  [Executor task launch worker for task 176] org.apache.spark.executor.Executor - Finished task 176.0 in stage 1.0 (TID 176). 3365 bytes result sent to driver
09:20:54.364 INFO  [Executor task launch worker for task 177] org.apache.spark.executor.Executor - Finished task 177.0 in stage 1.0 (TID 177). 3365 bytes result sent to driver
09:20:54.364 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 179.0 in stage 1.0 (TID 179, localhost, executor driver, partition 179, PROCESS_LOCAL, 4726 bytes)
09:20:54.364 INFO  [Executor task launch worker for task 179] org.apache.spark.executor.Executor - Running task 179.0 in stage 1.0 (TID 179)
09:20:54.364 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 176.0 in stage 1.0 (TID 176) in 31 ms on localhost (executor driver) (176/200)
09:20:54.364 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 177.0 in stage 1.0 (TID 177) in 31 ms on localhost (executor driver) (177/200)
09:20:54.364 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 180.0 in stage 1.0 (TID 180, localhost, executor driver, partition 180, PROCESS_LOCAL, 4726 bytes)
09:20:54.364 INFO  [Executor task launch worker for task 180] org.apache.spark.executor.Executor - Running task 180.0 in stage 1.0 (TID 180)
09:20:54.364 INFO  [Executor task launch worker for task 178] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=178),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/178]
09:20:54.364 INFO  [Executor task launch worker for task 179] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=179), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/179] for update
09:20:54.364 INFO  [Executor task launch worker for task 178] org.apache.spark.executor.Executor - Finished task 178.0 in stage 1.0 (TID 178). 3365 bytes result sent to driver
09:20:54.364 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 181.0 in stage 1.0 (TID 181, localhost, executor driver, partition 181, PROCESS_LOCAL, 4726 bytes)
09:20:54.364 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 178.0 in stage 1.0 (TID 178) in 16 ms on localhost (executor driver) (178/200)
09:20:54.364 INFO  [Executor task launch worker for task 181] org.apache.spark.executor.Executor - Running task 181.0 in stage 1.0 (TID 181)
09:20:54.364 INFO  [Executor task launch worker for task 179] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=179), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/179] for update
09:20:54.364 INFO  [Executor task launch worker for task 180] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=180), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/180] for update
09:20:54.380 INFO  [Executor task launch worker for task 179] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.380 INFO  [Executor task launch worker for task 180] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=180), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/180] for update
09:20:54.380 INFO  [Executor task launch worker for task 179] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.380 INFO  [Executor task launch worker for task 180] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.380 INFO  [Executor task launch worker for task 180] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.380 INFO  [Executor task launch worker for task 181] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=181), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/181] for update
09:20:54.380 INFO  [Executor task launch worker for task 181] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=181), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/181] for update
09:20:54.380 INFO  [Executor task launch worker for task 181] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.380 INFO  [Executor task launch worker for task 181] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.380 INFO  [Executor task launch worker for task 180] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=180),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/180] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/180/1.delta
09:20:54.380 INFO  [Executor task launch worker for task 179] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=179),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/179] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/179/1.delta
09:20:54.380 INFO  [Executor task launch worker for task 181] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=181),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/181] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/181/1.delta
09:20:54.380 INFO  [Executor task launch worker for task 180] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=180),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/180]
09:20:54.380 INFO  [Executor task launch worker for task 180] org.apache.spark.executor.Executor - Finished task 180.0 in stage 1.0 (TID 180). 3322 bytes result sent to driver
09:20:54.380 INFO  [Executor task launch worker for task 179] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=179),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/179]
09:20:54.380 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 182.0 in stage 1.0 (TID 182, localhost, executor driver, partition 182, PROCESS_LOCAL, 4726 bytes)
09:20:54.380 INFO  [Executor task launch worker for task 181] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=181),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/181]
09:20:54.395 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 180.0 in stage 1.0 (TID 180) in 31 ms on localhost (executor driver) (179/200)
09:20:54.395 INFO  [Executor task launch worker for task 182] org.apache.spark.executor.Executor - Running task 182.0 in stage 1.0 (TID 182)
09:20:54.395 INFO  [Executor task launch worker for task 181] org.apache.spark.executor.Executor - Finished task 181.0 in stage 1.0 (TID 181). 3365 bytes result sent to driver
09:20:54.395 INFO  [Executor task launch worker for task 179] org.apache.spark.executor.Executor - Finished task 179.0 in stage 1.0 (TID 179). 3322 bytes result sent to driver
09:20:54.395 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 183.0 in stage 1.0 (TID 183, localhost, executor driver, partition 183, PROCESS_LOCAL, 4726 bytes)
09:20:54.395 INFO  [Executor task launch worker for task 183] org.apache.spark.executor.Executor - Running task 183.0 in stage 1.0 (TID 183)
09:20:54.395 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 181.0 in stage 1.0 (TID 181) in 31 ms on localhost (executor driver) (180/200)
09:20:54.395 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 184.0 in stage 1.0 (TID 184, localhost, executor driver, partition 184, PROCESS_LOCAL, 4726 bytes)
09:20:54.395 INFO  [Executor task launch worker for task 184] org.apache.spark.executor.Executor - Running task 184.0 in stage 1.0 (TID 184)
09:20:54.395 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 179.0 in stage 1.0 (TID 179) in 31 ms on localhost (executor driver) (181/200)
09:20:54.395 INFO  [Executor task launch worker for task 182] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=182), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/182] for update
09:20:54.395 INFO  [Executor task launch worker for task 184] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=184), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/184] for update
09:20:54.395 INFO  [Executor task launch worker for task 183] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=183), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/183] for update
09:20:54.395 INFO  [Executor task launch worker for task 184] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=184), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/184] for update
09:20:54.395 INFO  [Executor task launch worker for task 182] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=182), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/182] for update
09:20:54.395 INFO  [Executor task launch worker for task 183] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=183), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/183] for update
09:20:54.395 INFO  [Executor task launch worker for task 182] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.395 INFO  [Executor task launch worker for task 184] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.411 INFO  [Executor task launch worker for task 182] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 16 ms
09:20:54.411 INFO  [Executor task launch worker for task 184] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 16 ms
09:20:54.411 INFO  [Executor task launch worker for task 183] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.411 INFO  [Executor task launch worker for task 183] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.426 INFO  [Executor task launch worker for task 184] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=184),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/184] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/184/1.delta
09:20:54.426 INFO  [Executor task launch worker for task 182] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=182),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/182] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/182/1.delta
09:20:54.426 INFO  [Executor task launch worker for task 183] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=183),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/183] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/183/1.delta
09:20:54.442 INFO  [Executor task launch worker for task 184] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=184),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/184]
09:20:54.442 INFO  [Executor task launch worker for task 184] org.apache.spark.executor.Executor - Finished task 184.0 in stage 1.0 (TID 184). 3365 bytes result sent to driver
09:20:54.442 INFO  [Executor task launch worker for task 183] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=183),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/183]
09:20:54.442 INFO  [Executor task launch worker for task 182] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=182),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/182]
09:20:54.442 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 185.0 in stage 1.0 (TID 185, localhost, executor driver, partition 185, PROCESS_LOCAL, 4726 bytes)
09:20:54.442 INFO  [Executor task launch worker for task 185] org.apache.spark.executor.Executor - Running task 185.0 in stage 1.0 (TID 185)
09:20:54.442 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 184.0 in stage 1.0 (TID 184) in 47 ms on localhost (executor driver) (182/200)
09:20:54.442 INFO  [Executor task launch worker for task 183] org.apache.spark.executor.Executor - Finished task 183.0 in stage 1.0 (TID 183). 3365 bytes result sent to driver
09:20:54.442 INFO  [Executor task launch worker for task 182] org.apache.spark.executor.Executor - Finished task 182.0 in stage 1.0 (TID 182). 3365 bytes result sent to driver
09:20:54.442 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 186.0 in stage 1.0 (TID 186, localhost, executor driver, partition 186, PROCESS_LOCAL, 4726 bytes)
09:20:54.442 INFO  [Executor task launch worker for task 186] org.apache.spark.executor.Executor - Running task 186.0 in stage 1.0 (TID 186)
09:20:54.442 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 183.0 in stage 1.0 (TID 183) in 47 ms on localhost (executor driver) (183/200)
09:20:54.442 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 187.0 in stage 1.0 (TID 187, localhost, executor driver, partition 187, PROCESS_LOCAL, 4726 bytes)
09:20:54.442 INFO  [Executor task launch worker for task 187] org.apache.spark.executor.Executor - Running task 187.0 in stage 1.0 (TID 187)
09:20:54.442 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 182.0 in stage 1.0 (TID 182) in 62 ms on localhost (executor driver) (184/200)
09:20:54.442 INFO  [Executor task launch worker for task 186] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=186), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/186] for update
09:20:54.442 INFO  [Executor task launch worker for task 185] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=185), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/185] for update
09:20:54.442 INFO  [Executor task launch worker for task 187] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=187), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/187] for update
09:20:54.442 INFO  [Executor task launch worker for task 186] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=186), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/186] for update
09:20:54.458 INFO  [Executor task launch worker for task 185] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=185), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/185] for update
09:20:54.458 INFO  [Executor task launch worker for task 187] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=187), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/187] for update
09:20:54.458 INFO  [Executor task launch worker for task 187] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.458 INFO  [Executor task launch worker for task 186] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.458 INFO  [Executor task launch worker for task 185] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.458 INFO  [Executor task launch worker for task 187] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.458 INFO  [Executor task launch worker for task 186] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.458 INFO  [Executor task launch worker for task 185] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.458 INFO  [Executor task launch worker for task 187] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=187),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/187] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/187/1.delta
09:20:54.458 INFO  [Executor task launch worker for task 186] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=186),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/186] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/186/1.delta
09:20:54.458 INFO  [Executor task launch worker for task 185] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=185),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/185] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/185/1.delta
09:20:54.458 INFO  [Executor task launch worker for task 187] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=187),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/187]
09:20:54.458 INFO  [Executor task launch worker for task 186] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=186),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/186]
09:20:54.458 INFO  [Executor task launch worker for task 187] org.apache.spark.executor.Executor - Finished task 187.0 in stage 1.0 (TID 187). 3322 bytes result sent to driver
09:20:54.458 INFO  [Executor task launch worker for task 185] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=185),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/185]
09:20:54.473 INFO  [Executor task launch worker for task 186] org.apache.spark.executor.Executor - Finished task 186.0 in stage 1.0 (TID 186). 3322 bytes result sent to driver
09:20:54.473 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 188.0 in stage 1.0 (TID 188, localhost, executor driver, partition 188, PROCESS_LOCAL, 4726 bytes)
09:20:54.473 INFO  [Executor task launch worker for task 185] org.apache.spark.executor.Executor - Finished task 185.0 in stage 1.0 (TID 185). 3322 bytes result sent to driver
09:20:54.473 INFO  [Executor task launch worker for task 188] org.apache.spark.executor.Executor - Running task 188.0 in stage 1.0 (TID 188)
09:20:54.473 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 189.0 in stage 1.0 (TID 189, localhost, executor driver, partition 189, PROCESS_LOCAL, 4726 bytes)
09:20:54.473 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 190.0 in stage 1.0 (TID 190, localhost, executor driver, partition 190, PROCESS_LOCAL, 4726 bytes)
09:20:54.473 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 187.0 in stage 1.0 (TID 187) in 31 ms on localhost (executor driver) (185/200)
09:20:54.473 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 186.0 in stage 1.0 (TID 186) in 31 ms on localhost (executor driver) (186/200)
09:20:54.473 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 185.0 in stage 1.0 (TID 185) in 31 ms on localhost (executor driver) (187/200)
09:20:54.473 INFO  [Executor task launch worker for task 190] org.apache.spark.executor.Executor - Running task 190.0 in stage 1.0 (TID 190)
09:20:54.473 INFO  [Executor task launch worker for task 189] org.apache.spark.executor.Executor - Running task 189.0 in stage 1.0 (TID 189)
09:20:54.473 INFO  [Executor task launch worker for task 188] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=188), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/188] for update
09:20:54.473 INFO  [Executor task launch worker for task 188] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=188), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/188] for update
09:20:54.473 INFO  [Executor task launch worker for task 188] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.473 INFO  [Executor task launch worker for task 188] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.473 INFO  [Executor task launch worker for task 190] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=190), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/190] for update
09:20:54.473 INFO  [Executor task launch worker for task 189] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=189), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/189] for update
09:20:54.473 INFO  [Executor task launch worker for task 188] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=188),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/188] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/188/1.delta
09:20:54.489 INFO  [Executor task launch worker for task 190] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=190), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/190] for update
09:20:54.489 INFO  [Executor task launch worker for task 189] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=189), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/189] for update
09:20:54.489 INFO  [Executor task launch worker for task 189] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.489 INFO  [Executor task launch worker for task 190] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.489 INFO  [Executor task launch worker for task 189] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.489 INFO  [Executor task launch worker for task 190] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.489 INFO  [Executor task launch worker for task 188] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=188),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/188]
09:20:54.489 INFO  [Executor task launch worker for task 188] org.apache.spark.executor.Executor - Finished task 188.0 in stage 1.0 (TID 188). 3322 bytes result sent to driver
09:20:54.489 INFO  [Executor task launch worker for task 190] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=190),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/190] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/190/1.delta
09:20:54.489 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 191.0 in stage 1.0 (TID 191, localhost, executor driver, partition 191, PROCESS_LOCAL, 4726 bytes)
09:20:54.489 INFO  [Executor task launch worker for task 191] org.apache.spark.executor.Executor - Running task 191.0 in stage 1.0 (TID 191)
09:20:54.489 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 188.0 in stage 1.0 (TID 188) in 16 ms on localhost (executor driver) (188/200)
09:20:54.489 INFO  [Executor task launch worker for task 191] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=191), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/191] for update
09:20:54.489 INFO  [Executor task launch worker for task 191] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=191), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/191] for update
09:20:54.489 INFO  [Executor task launch worker for task 191] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.489 INFO  [Executor task launch worker for task 191] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.489 INFO  [Executor task launch worker for task 189] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=189),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/189] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/189/1.delta
09:20:54.505 INFO  [Executor task launch worker for task 189] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=189),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/189]
09:20:54.505 INFO  [Executor task launch worker for task 189] org.apache.spark.executor.Executor - Finished task 189.0 in stage 1.0 (TID 189). 3322 bytes result sent to driver
09:20:54.505 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 192.0 in stage 1.0 (TID 192, localhost, executor driver, partition 192, PROCESS_LOCAL, 4726 bytes)
09:20:54.505 INFO  [Executor task launch worker for task 192] org.apache.spark.executor.Executor - Running task 192.0 in stage 1.0 (TID 192)
09:20:54.505 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 189.0 in stage 1.0 (TID 189) in 32 ms on localhost (executor driver) (189/200)
09:20:54.505 INFO  [Executor task launch worker for task 192] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=192), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/192] for update
09:20:54.505 INFO  [Executor task launch worker for task 192] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=192), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/192] for update
09:20:54.505 INFO  [Executor task launch worker for task 192] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.505 INFO  [Executor task launch worker for task 192] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.505 INFO  [Executor task launch worker for task 192] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=192),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/192] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/192/1.delta
09:20:54.520 INFO  [Executor task launch worker for task 191] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=191),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/191] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/191/1.delta
09:20:54.520 INFO  [Executor task launch worker for task 192] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=192),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/192]
09:20:54.520 INFO  [Executor task launch worker for task 192] org.apache.spark.executor.Executor - Finished task 192.0 in stage 1.0 (TID 192). 3365 bytes result sent to driver
09:20:54.520 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 193.0 in stage 1.0 (TID 193, localhost, executor driver, partition 193, PROCESS_LOCAL, 4726 bytes)
09:20:54.520 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 192.0 in stage 1.0 (TID 192) in 15 ms on localhost (executor driver) (190/200)
09:20:54.520 INFO  [Executor task launch worker for task 193] org.apache.spark.executor.Executor - Running task 193.0 in stage 1.0 (TID 193)
09:20:54.520 INFO  [Executor task launch worker for task 190] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=190),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/190]
09:20:54.520 INFO  [Executor task launch worker for task 190] org.apache.spark.executor.Executor - Finished task 190.0 in stage 1.0 (TID 190). 3365 bytes result sent to driver
09:20:54.520 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 194.0 in stage 1.0 (TID 194, localhost, executor driver, partition 194, PROCESS_LOCAL, 4726 bytes)
09:20:54.520 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 190.0 in stage 1.0 (TID 190) in 47 ms on localhost (executor driver) (191/200)
09:20:54.520 INFO  [Executor task launch worker for task 194] org.apache.spark.executor.Executor - Running task 194.0 in stage 1.0 (TID 194)
09:20:54.520 INFO  [Executor task launch worker for task 191] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=191),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/191]
09:20:54.520 INFO  [Executor task launch worker for task 191] org.apache.spark.executor.Executor - Finished task 191.0 in stage 1.0 (TID 191). 3322 bytes result sent to driver
09:20:54.520 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 195.0 in stage 1.0 (TID 195, localhost, executor driver, partition 195, PROCESS_LOCAL, 4726 bytes)
09:20:54.520 INFO  [Executor task launch worker for task 195] org.apache.spark.executor.Executor - Running task 195.0 in stage 1.0 (TID 195)
09:20:54.520 INFO  [Executor task launch worker for task 193] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=193), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/193] for update
09:20:54.520 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 191.0 in stage 1.0 (TID 191) in 31 ms on localhost (executor driver) (192/200)
09:20:54.520 INFO  [Executor task launch worker for task 193] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=193), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/193] for update
09:20:54.520 INFO  [Executor task launch worker for task 194] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=194), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/194] for update
09:20:54.520 INFO  [Executor task launch worker for task 195] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=195), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/195] for update
09:20:54.536 INFO  [Executor task launch worker for task 193] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.536 INFO  [Executor task launch worker for task 194] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=194), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/194] for update
09:20:54.536 INFO  [Executor task launch worker for task 195] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=195), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/195] for update
09:20:54.536 INFO  [Executor task launch worker for task 193] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.536 INFO  [Executor task launch worker for task 195] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.536 INFO  [Executor task launch worker for task 194] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.536 INFO  [Executor task launch worker for task 195] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.536 INFO  [Executor task launch worker for task 194] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.536 INFO  [Executor task launch worker for task 195] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=195),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/195] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/195/1.delta
09:20:54.536 INFO  [Executor task launch worker for task 194] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=194),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/194] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/194/1.delta
09:20:54.536 INFO  [Executor task launch worker for task 193] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=193),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/193] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/193/1.delta
09:20:54.536 INFO  [Executor task launch worker for task 194] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=194),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/194]
09:20:54.536 INFO  [Executor task launch worker for task 195] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=195),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/195]
09:20:54.536 INFO  [Executor task launch worker for task 193] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=193),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/193]
09:20:54.551 INFO  [Executor task launch worker for task 193] org.apache.spark.executor.Executor - Finished task 193.0 in stage 1.0 (TID 193). 3322 bytes result sent to driver
09:20:54.551 INFO  [Executor task launch worker for task 195] org.apache.spark.executor.Executor - Finished task 195.0 in stage 1.0 (TID 195). 3322 bytes result sent to driver
09:20:54.551 INFO  [Executor task launch worker for task 194] org.apache.spark.executor.Executor - Finished task 194.0 in stage 1.0 (TID 194). 3322 bytes result sent to driver
09:20:54.551 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 196.0 in stage 1.0 (TID 196, localhost, executor driver, partition 196, PROCESS_LOCAL, 4726 bytes)
09:20:54.551 INFO  [Executor task launch worker for task 196] org.apache.spark.executor.Executor - Running task 196.0 in stage 1.0 (TID 196)
09:20:54.551 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 193.0 in stage 1.0 (TID 193) in 31 ms on localhost (executor driver) (193/200)
09:20:54.551 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 197.0 in stage 1.0 (TID 197, localhost, executor driver, partition 197, PROCESS_LOCAL, 4726 bytes)
09:20:54.551 INFO  [Executor task launch worker for task 197] org.apache.spark.executor.Executor - Running task 197.0 in stage 1.0 (TID 197)
09:20:54.551 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 195.0 in stage 1.0 (TID 195) in 31 ms on localhost (executor driver) (194/200)
09:20:54.551 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 198.0 in stage 1.0 (TID 198, localhost, executor driver, partition 198, PROCESS_LOCAL, 4726 bytes)
09:20:54.551 INFO  [Executor task launch worker for task 198] org.apache.spark.executor.Executor - Running task 198.0 in stage 1.0 (TID 198)
09:20:54.551 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 194.0 in stage 1.0 (TID 194) in 31 ms on localhost (executor driver) (195/200)
09:20:54.551 INFO  [Executor task launch worker for task 197] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=197), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/197] for update
09:20:54.551 INFO  [Executor task launch worker for task 198] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=198), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/198] for update
09:20:54.551 INFO  [Executor task launch worker for task 197] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=197), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/197] for update
09:20:54.551 INFO  [Executor task launch worker for task 197] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.551 INFO  [Executor task launch worker for task 197] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.551 INFO  [Executor task launch worker for task 196] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=196), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/196] for update
09:20:54.551 INFO  [Executor task launch worker for task 198] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=198), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/198] for update
09:20:54.551 INFO  [Executor task launch worker for task 197] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=197),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/197] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/197/1.delta
09:20:54.567 INFO  [Executor task launch worker for task 196] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=196), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/196] for update
09:20:54.567 INFO  [Executor task launch worker for task 198] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.567 INFO  [Executor task launch worker for task 198] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.567 INFO  [Executor task launch worker for task 196] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.567 INFO  [Executor task launch worker for task 196] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.567 INFO  [Executor task launch worker for task 197] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=197),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/197]
09:20:54.567 INFO  [Executor task launch worker for task 197] org.apache.spark.executor.Executor - Finished task 197.0 in stage 1.0 (TID 197). 3322 bytes result sent to driver
09:20:54.567 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 199.0 in stage 1.0 (TID 199, localhost, executor driver, partition 199, PROCESS_LOCAL, 4726 bytes)
09:20:54.567 INFO  [Executor task launch worker for task 199] org.apache.spark.executor.Executor - Running task 199.0 in stage 1.0 (TID 199)
09:20:54.567 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 197.0 in stage 1.0 (TID 197) in 16 ms on localhost (executor driver) (196/200)
09:20:54.567 INFO  [Executor task launch worker for task 198] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=198),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/198] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/198/1.delta
09:20:54.567 INFO  [Executor task launch worker for task 196] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=196),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/196] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/196/1.delta
09:20:54.567 INFO  [Executor task launch worker for task 199] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=199), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/199] for update
09:20:54.567 INFO  [Executor task launch worker for task 199] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=199), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/199] for update
09:20:54.567 INFO  [Executor task launch worker for task 199] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:20:54.567 INFO  [Executor task launch worker for task 199] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.567 INFO  [Executor task launch worker for task 198] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=198),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/198]
09:20:54.567 INFO  [Executor task launch worker for task 196] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=196),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/196]
09:20:54.583 INFO  [Executor task launch worker for task 198] org.apache.spark.executor.Executor - Finished task 198.0 in stage 1.0 (TID 198). 3322 bytes result sent to driver
09:20:54.583 INFO  [Executor task launch worker for task 196] org.apache.spark.executor.Executor - Finished task 196.0 in stage 1.0 (TID 196). 3322 bytes result sent to driver
09:20:54.583 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 156.0 in stage 1.0 (TID 200, localhost, executor driver, partition 156, ANY, 4726 bytes)
09:20:54.583 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 198.0 in stage 1.0 (TID 198) in 32 ms on localhost (executor driver) (197/200)
09:20:54.583 INFO  [Executor task launch worker for task 200] org.apache.spark.executor.Executor - Running task 156.0 in stage 1.0 (TID 200)
09:20:54.583 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 196.0 in stage 1.0 (TID 196) in 32 ms on localhost (executor driver) (198/200)
09:20:54.583 INFO  [Executor task launch worker for task 200] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=156), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/156] for update
09:20:54.583 INFO  [Executor task launch worker for task 200] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 0 of HDFSStateStoreProvider[id = (op=0, part=156), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/156] for update
09:20:54.583 INFO  [Executor task launch worker for task 200] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
09:20:54.583 INFO  [Executor task launch worker for task 200] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:54.583 INFO  [Executor task launch worker for task 199] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=199),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/199] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/199/1.delta
09:20:54.583 INFO  [Executor task launch worker for task 199] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=199),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/199]
09:20:54.583 INFO  [Executor task launch worker for task 199] org.apache.spark.executor.Executor - Finished task 199.0 in stage 1.0 (TID 199). 3322 bytes result sent to driver
09:20:54.583 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 199.0 in stage 1.0 (TID 199) in 16 ms on localhost (executor driver) (199/200)
09:20:54.598 INFO  [Executor task launch worker for task 200] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 1 for HDFSStateStore[id=(op=0,part=156),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/156] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/156/1.delta
09:20:54.614 INFO  [Executor task launch worker for task 200] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 1 for HDFSStateStore[id=(op=0,part=156),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/156]
09:20:54.614 INFO  [Executor task launch worker for task 200] org.apache.spark.executor.Executor - Finished task 156.0 in stage 1.0 (TID 200). 3394 bytes result sent to driver
09:20:54.614 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 156.0 in stage 1.0 (TID 200) in 31 ms on localhost (executor driver) (200/200)
09:20:54.614 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
09:20:54.614 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - ResultStage 1 (start at demo.scala:28) finished in 2.932 s
09:20:54.614 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.scheduler.DAGScheduler - Job 0 finished: start at demo.scala:28, took 3.331939 s
09:20:54.661 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.SparkContext - Starting job: start at demo.scala:28
09:20:54.661 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Got job 1 (start at demo.scala:28) with 1 output partitions
09:20:54.661 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (start at demo.scala:28)
09:20:54.661 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
09:20:54.661 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
09:20:54.661 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[16] at start at demo.scala:28), which has no missing parents
09:20:54.661 INFO  [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 8.4 KB, free 1953.9 MB)
09:20:54.661 INFO  [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1953.9 MB)
09:20:54.661 INFO  [dispatcher-event-loop-6] org.apache.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on 172.16.2.246:51465 (size: 4.6 KB, free: 1954.4 MB)
09:20:54.661 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext - Created broadcast 4 from broadcast at DAGScheduler.scala:1004
09:20:54.661 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[16] at start at demo.scala:28) (first 15 tasks are for partitions Vector(0))
09:20:54.661 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks
09:20:54.661 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 201, localhost, executor driver, partition 0, PROCESS_LOCAL, 4835 bytes)
09:20:54.661 INFO  [Executor task launch worker for task 201] org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 201)
09:20:54.676 INFO  [Executor task launch worker for task 201] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 6.9128 ms
09:20:54.676 INFO  [Executor task launch worker for task 201] org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 201). 913 bytes result sent to driver
09:20:54.676 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 201) in 15 ms on localhost (executor driver) (1/1)
09:20:54.676 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
09:20:54.676 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - ResultStage 2 (start at demo.scala:28) finished in 0.015 s
09:20:54.676 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.scheduler.DAGScheduler - Job 1 finished: start at demo.scala:28, took 0.018929 s
09:20:54.676 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.SparkContext - Starting job: start at demo.scala:28
09:20:54.676 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Got job 2 (start at demo.scala:28) with 2 output partitions
09:20:54.676 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (start at demo.scala:28)
09:20:54.676 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
09:20:54.676 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
09:20:54.676 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[16] at start at demo.scala:28), which has no missing parents
09:20:54.676 INFO  [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 8.4 KB, free 1953.9 MB)
09:20:54.676 INFO  [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1953.9 MB)
09:20:54.676 INFO  [dispatcher-event-loop-1] org.apache.spark.storage.BlockManagerInfo - Added broadcast_5_piece0 in memory on 172.16.2.246:51465 (size: 4.6 KB, free: 1954.4 MB)
09:20:54.676 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext - Created broadcast 5 from broadcast at DAGScheduler.scala:1004
09:20:54.676 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from ResultStage 3 (MapPartitionsRDD[16] at start at demo.scala:28) (first 15 tasks are for partitions Vector(1, 2))
09:20:54.676 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 2 tasks
09:20:54.692 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 202, localhost, executor driver, partition 1, PROCESS_LOCAL, 4835 bytes)
09:20:54.692 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 3.0 (TID 203, localhost, executor driver, partition 2, PROCESS_LOCAL, 5927 bytes)
09:20:54.692 INFO  [Executor task launch worker for task 202] org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 202)
09:20:54.692 INFO  [Executor task launch worker for task 203] org.apache.spark.executor.Executor - Running task 1.0 in stage 3.0 (TID 203)
09:20:54.692 INFO  [Executor task launch worker for task 202] org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 202). 827 bytes result sent to driver
09:20:54.692 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 202) in 16 ms on localhost (executor driver) (1/2)
09:20:54.708 INFO  [Executor task launch worker for task 203] org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 15.1686 ms
09:20:54.714 INFO  [Executor task launch worker for task 203] org.apache.spark.executor.Executor - Finished task 1.0 in stage 3.0 (TID 203). 942 bytes result sent to driver
09:20:54.714 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 3.0 (TID 203) in 22 ms on localhost (executor driver) (2/2)
09:20:54.715 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
09:20:54.715 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - ResultStage 3 (start at demo.scala:28) finished in 0.039 s
09:20:54.715 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.scheduler.DAGScheduler - Job 2 finished: start at demo.scala:28, took 0.027549 s
09:20:54.759 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.sql.execution.streaming.StreamExecution - Streaming query made progress: {
  "id" : "20adb406-fa0e-4b6d-891d-3b838da918df",
  "runId" : "042f103f-d70f-40a8-8188-bbfcfa159ed0",
  "name" : null,
  "timestamp" : "2020-10-12T01:20:48.707Z",
  "numInputRows" : 1,
  "processedRowsPerSecond" : 0.16608536787908987,
  "durationMs" : {
    "addBatch" : 4184,
    "getBatch" : 347,
    "getOffset" : 0,
    "queryPlanning" : 296,
    "triggerExecution" : 6020,
    "walCommit" : 1186
  },
  "stateOperators" : [ {
    "numRowsTotal" : 1,
    "numRowsUpdated" : 1
  } ],
  "sources" : [ {
    "description" : "TextSocketSource[host: 10.112.0.8, port: 1122]",
    "startOffset" : null,
    "endOffset" : 0,
    "numInputRows" : 1,
    "processedRowsPerSecond" : 0.16608536787908987
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSink@ee7e03"
  }
}
09:20:55.009 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.sql.execution.streaming.StreamExecution - Committed offsets for batch 1. Metadata OffsetSeqMetadata(0,1602465654900,Map(spark.sql.shuffle.partitions -> 200))
09:20:55.103 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner - Cleaned accumulator 99
09:20:55.119 INFO  [dispatcher-event-loop-1] org.apache.spark.storage.BlockManagerInfo - Removed broadcast_4_piece0 on 172.16.2.246:51465 in memory (size: 4.6 KB, free: 1954.4 MB)
09:20:55.119 INFO  [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerInfo - Removed broadcast_5_piece0 on 172.16.2.246:51465 in memory (size: 4.6 KB, free: 1954.4 MB)
09:20:55.119 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner - Cleaned accumulator 148
09:20:55.119 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.storage.memory.MemoryStore - Block broadcast_6 stored as values in memory (estimated size 250.7 KB, free 1953.7 MB)
09:20:55.134 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.storage.memory.MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 21.2 KB, free 1953.6 MB)
09:20:55.134 INFO  [dispatcher-event-loop-6] org.apache.spark.storage.BlockManagerInfo - Added broadcast_6_piece0 in memory on 172.16.2.246:51465 (size: 21.2 KB, free: 1954.4 MB)
09:20:55.134 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.SparkContext - Created broadcast 6 from start at demo.scala:28
09:20:55.150 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.storage.memory.MemoryStore - Block broadcast_7 stored as values in memory (estimated size 250.7 KB, free 1953.4 MB)
09:20:55.166 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.storage.memory.MemoryStore - Block broadcast_7_piece0 stored as bytes in memory (estimated size 21.2 KB, free 1953.4 MB)
09:20:55.166 INFO  [dispatcher-event-loop-0] org.apache.spark.storage.BlockManagerInfo - Added broadcast_7_piece0 in memory on 172.16.2.246:51465 (size: 21.2 KB, free: 1954.4 MB)
09:20:55.166 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.SparkContext - Created broadcast 7 from start at demo.scala:28
09:20:55.166 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.SparkContext - Starting job: start at demo.scala:28
09:20:55.166 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Registering RDD 22 (start at demo.scala:28)
09:20:55.166 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Got job 3 (start at demo.scala:28) with 200 output partitions
09:20:55.166 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 5 (start at demo.scala:28)
09:20:55.166 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 4)
09:20:55.166 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 4)
09:20:55.166 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 4 (MapPartitionsRDD[22] at start at demo.scala:28), which has no missing parents
09:20:55.166 INFO  [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore - Block broadcast_8 stored as values in memory (estimated size 23.8 KB, free 1953.4 MB)
09:20:55.166 INFO  [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore - Block broadcast_8_piece0 stored as bytes in memory (estimated size 10.7 KB, free 1953.3 MB)
09:20:55.166 INFO  [dispatcher-event-loop-4] org.apache.spark.storage.BlockManagerInfo - Added broadcast_8_piece0 in memory on 172.16.2.246:51465 (size: 10.7 KB, free: 1954.4 MB)
09:20:55.166 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext - Created broadcast 8 from broadcast at DAGScheduler.scala:1004
09:20:55.166 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[22] at start at demo.scala:28) (first 15 tasks are for partitions Vector(0, 1))
09:20:55.166 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 4.0 with 2 tasks
09:20:55.181 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 4.0 (TID 204, localhost, executor driver, partition 0, PROCESS_LOCAL, 5000 bytes)
09:20:55.181 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 4.0 (TID 205, localhost, executor driver, partition 1, PROCESS_LOCAL, 5000 bytes)
09:20:55.181 INFO  [Executor task launch worker for task 205] org.apache.spark.executor.Executor - Running task 1.0 in stage 4.0 (TID 205)
09:20:55.181 INFO  [Executor task launch worker for task 204] org.apache.spark.executor.Executor - Running task 0.0 in stage 4.0 (TID 204)
09:20:55.212 INFO  [Executor task launch worker for task 205] org.apache.spark.executor.Executor - Finished task 1.0 in stage 4.0 (TID 205). 1846 bytes result sent to driver
09:20:55.212 INFO  [Executor task launch worker for task 204] org.apache.spark.executor.Executor - Finished task 0.0 in stage 4.0 (TID 204). 1846 bytes result sent to driver
09:20:55.212 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 4.0 (TID 205) in 31 ms on localhost (executor driver) (1/2)
09:20:55.212 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 4.0 (TID 204) in 31 ms on localhost (executor driver) (2/2)
09:20:55.212 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
09:20:55.212 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 4 (start at demo.scala:28) finished in 0.031 s
09:20:55.212 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
09:20:55.212 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - running: Set()
09:20:55.212 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 5)
09:20:55.212 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - failed: Set()
09:20:55.212 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 5 (MapPartitionsRDD[29] at start at demo.scala:28), which has no missing parents
09:20:55.244 INFO  [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore - Block broadcast_9 stored as values in memory (estimated size 45.4 KB, free 1953.3 MB)
09:20:55.244 INFO  [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore - Block broadcast_9_piece0 stored as bytes in memory (estimated size 16.7 KB, free 1953.3 MB)
09:20:55.244 INFO  [dispatcher-event-loop-6] org.apache.spark.storage.BlockManagerInfo - Added broadcast_9_piece0 in memory on 172.16.2.246:51465 (size: 16.7 KB, free: 1954.4 MB)
09:20:55.244 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext - Created broadcast 9 from broadcast at DAGScheduler.scala:1004
09:20:55.244 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Submitting 200 missing tasks from ResultStage 5 (MapPartitionsRDD[29] at start at demo.scala:28) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
09:20:55.244 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 5.0 with 200 tasks
09:20:55.244 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 5.0 (TID 206, localhost, executor driver, partition 0, PROCESS_LOCAL, 4726 bytes)
09:20:55.244 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 5.0 (TID 207, localhost, executor driver, partition 1, PROCESS_LOCAL, 4726 bytes)
09:20:55.244 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 5.0 (TID 208, localhost, executor driver, partition 2, PROCESS_LOCAL, 4726 bytes)
09:20:55.244 INFO  [Executor task launch worker for task 206] org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 206)
09:20:55.244 INFO  [Executor task launch worker for task 208] org.apache.spark.executor.Executor - Running task 2.0 in stage 5.0 (TID 208)
09:20:55.244 INFO  [Executor task launch worker for task 207] org.apache.spark.executor.Executor - Running task 1.0 in stage 5.0 (TID 207)
09:20:55.259 INFO  [Executor task launch worker for task 206] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=0), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/0] for update
09:20:55.259 INFO  [Executor task launch worker for task 207] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=1), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/1] for update
09:20:55.259 INFO  [Executor task launch worker for task 206] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=0), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/0] for update
09:20:55.259 INFO  [Executor task launch worker for task 208] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=2), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/2] for update
09:20:55.259 INFO  [Executor task launch worker for task 207] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=1), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/1] for update
09:20:55.259 INFO  [Executor task launch worker for task 208] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=2), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/2] for update
09:20:55.259 INFO  [Executor task launch worker for task 207] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.259 INFO  [Executor task launch worker for task 206] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.259 INFO  [Executor task launch worker for task 208] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.259 INFO  [Executor task launch worker for task 207] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.259 INFO  [Executor task launch worker for task 206] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.259 INFO  [Executor task launch worker for task 208] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.275 INFO  [Executor task launch worker for task 206] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=0),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/0] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/0/2.delta
09:20:55.275 INFO  [Executor task launch worker for task 207] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=1),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/1] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/1/2.delta
09:20:55.275 INFO  [Executor task launch worker for task 206] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=0),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/0]
09:20:55.275 INFO  [Executor task launch worker for task 206] org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 206). 3322 bytes result sent to driver
09:20:55.275 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 5.0 (TID 209, localhost, executor driver, partition 3, PROCESS_LOCAL, 4726 bytes)
09:20:55.275 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 5.0 (TID 206) in 31 ms on localhost (executor driver) (1/200)
09:20:55.275 INFO  [Executor task launch worker for task 209] org.apache.spark.executor.Executor - Running task 3.0 in stage 5.0 (TID 209)
09:20:55.275 INFO  [Executor task launch worker for task 207] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=1),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/1]
09:20:55.275 INFO  [Executor task launch worker for task 207] org.apache.spark.executor.Executor - Finished task 1.0 in stage 5.0 (TID 207). 3451 bytes result sent to driver
09:20:55.275 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 5.0 (TID 210, localhost, executor driver, partition 4, PROCESS_LOCAL, 4726 bytes)
09:20:55.275 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 5.0 (TID 207) in 31 ms on localhost (executor driver) (2/200)
09:20:55.275 INFO  [Executor task launch worker for task 210] org.apache.spark.executor.Executor - Running task 4.0 in stage 5.0 (TID 210)
09:20:55.275 INFO  [Executor task launch worker for task 209] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=3), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/3] for update
09:20:55.275 INFO  [Executor task launch worker for task 209] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=3), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/3] for update
09:20:55.275 INFO  [Executor task launch worker for task 209] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.275 INFO  [Executor task launch worker for task 209] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.275 INFO  [Executor task launch worker for task 210] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=4), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/4] for update
09:20:55.275 INFO  [Executor task launch worker for task 208] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=2),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/2] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/2/2.delta
09:20:55.290 INFO  [Executor task launch worker for task 210] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=4), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/4] for update
09:20:55.290 INFO  [Executor task launch worker for task 210] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.290 INFO  [Executor task launch worker for task 210] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.290 INFO  [Executor task launch worker for task 209] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=3),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/3] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/3/2.delta
09:20:55.290 INFO  [Executor task launch worker for task 210] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=4),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/4] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/4/2.delta
09:20:55.290 INFO  [Executor task launch worker for task 208] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=2),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/2]
09:20:55.290 INFO  [Executor task launch worker for task 208] org.apache.spark.executor.Executor - Finished task 2.0 in stage 5.0 (TID 208). 3451 bytes result sent to driver
09:20:55.290 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 5.0 (TID 211, localhost, executor driver, partition 5, PROCESS_LOCAL, 4726 bytes)
09:20:55.290 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 5.0 (TID 208) in 46 ms on localhost (executor driver) (3/200)
09:20:55.290 INFO  [Executor task launch worker for task 211] org.apache.spark.executor.Executor - Running task 5.0 in stage 5.0 (TID 211)
09:20:55.290 INFO  [Executor task launch worker for task 209] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=3),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/3]
09:20:55.290 INFO  [Executor task launch worker for task 209] org.apache.spark.executor.Executor - Finished task 3.0 in stage 5.0 (TID 209). 3322 bytes result sent to driver
09:20:55.290 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 6.0 in stage 5.0 (TID 212, localhost, executor driver, partition 6, PROCESS_LOCAL, 4726 bytes)
09:20:55.290 INFO  [Executor task launch worker for task 211] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=5), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/5] for update
09:20:55.290 INFO  [Executor task launch worker for task 210] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=4),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/4]
09:20:55.306 INFO  [Executor task launch worker for task 211] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=5), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/5] for update
09:20:55.306 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 5.0 (TID 209) in 31 ms on localhost (executor driver) (4/200)
09:20:55.306 INFO  [Executor task launch worker for task 212] org.apache.spark.executor.Executor - Running task 6.0 in stage 5.0 (TID 212)
09:20:55.306 INFO  [Executor task launch worker for task 210] org.apache.spark.executor.Executor - Finished task 4.0 in stage 5.0 (TID 210). 3322 bytes result sent to driver
09:20:55.306 INFO  [Executor task launch worker for task 211] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.306 INFO  [Executor task launch worker for task 211] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.306 INFO  [Executor task launch worker for task 212] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=6), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/6] for update
09:20:55.306 INFO  [Executor task launch worker for task 212] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=6), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/6] for update
09:20:55.306 INFO  [Executor task launch worker for task 212] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.306 INFO  [Executor task launch worker for task 212] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.306 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 7.0 in stage 5.0 (TID 213, localhost, executor driver, partition 7, PROCESS_LOCAL, 4726 bytes)
09:20:55.306 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 5.0 (TID 210) in 31 ms on localhost (executor driver) (5/200)
09:20:55.306 INFO  [Executor task launch worker for task 213] org.apache.spark.executor.Executor - Running task 7.0 in stage 5.0 (TID 213)
09:20:55.306 INFO  [Executor task launch worker for task 213] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=7), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/7] for update
09:20:55.306 INFO  [Executor task launch worker for task 213] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=7), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/7] for update
09:20:55.306 INFO  [Executor task launch worker for task 211] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=5),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/5] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/5/2.delta
09:20:55.306 INFO  [Executor task launch worker for task 212] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=6),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/6] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/6/2.delta
09:20:55.322 INFO  [Executor task launch worker for task 213] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.322 INFO  [Executor task launch worker for task 213] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.322 INFO  [Executor task launch worker for task 212] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=6),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/6]
09:20:55.322 INFO  [Executor task launch worker for task 212] org.apache.spark.executor.Executor - Finished task 6.0 in stage 5.0 (TID 212). 3322 bytes result sent to driver
09:20:55.322 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 8.0 in stage 5.0 (TID 214, localhost, executor driver, partition 8, PROCESS_LOCAL, 4726 bytes)
09:20:55.322 INFO  [Executor task launch worker for task 214] org.apache.spark.executor.Executor - Running task 8.0 in stage 5.0 (TID 214)
09:20:55.322 INFO  [Executor task launch worker for task 213] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=7),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/7] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/7/2.delta
09:20:55.322 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 6.0 in stage 5.0 (TID 212) in 32 ms on localhost (executor driver) (6/200)
09:20:55.322 INFO  [Executor task launch worker for task 211] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=5),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/5]
09:20:55.322 INFO  [Executor task launch worker for task 211] org.apache.spark.executor.Executor - Finished task 5.0 in stage 5.0 (TID 211). 3322 bytes result sent to driver
09:20:55.322 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 9.0 in stage 5.0 (TID 215, localhost, executor driver, partition 9, PROCESS_LOCAL, 4726 bytes)
09:20:55.322 INFO  [Executor task launch worker for task 215] org.apache.spark.executor.Executor - Running task 9.0 in stage 5.0 (TID 215)
09:20:55.322 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 5.0 (TID 211) in 32 ms on localhost (executor driver) (7/200)
09:20:55.322 INFO  [Executor task launch worker for task 214] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=8), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/8] for update
09:20:55.322 INFO  [Executor task launch worker for task 213] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=7),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/7]
09:20:55.322 INFO  [Executor task launch worker for task 215] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=9), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/9] for update
09:20:55.337 INFO  [Executor task launch worker for task 214] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=8), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/8] for update
09:20:55.337 INFO  [Executor task launch worker for task 215] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=9), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/9] for update
09:20:55.337 INFO  [Executor task launch worker for task 214] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.337 INFO  [Executor task launch worker for task 215] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.337 INFO  [Executor task launch worker for task 214] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.337 INFO  [Executor task launch worker for task 215] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.337 INFO  [Executor task launch worker for task 213] org.apache.spark.executor.Executor - Finished task 7.0 in stage 5.0 (TID 213). 3322 bytes result sent to driver
09:20:55.337 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 10.0 in stage 5.0 (TID 216, localhost, executor driver, partition 10, PROCESS_LOCAL, 4726 bytes)
09:20:55.337 INFO  [Executor task launch worker for task 216] org.apache.spark.executor.Executor - Running task 10.0 in stage 5.0 (TID 216)
09:20:55.337 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 7.0 in stage 5.0 (TID 213) in 31 ms on localhost (executor driver) (8/200)
09:20:55.337 INFO  [Executor task launch worker for task 216] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=10), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/10] for update
09:20:55.337 INFO  [Executor task launch worker for task 216] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=10), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/10] for update
09:20:55.337 INFO  [Executor task launch worker for task 216] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.337 INFO  [Executor task launch worker for task 216] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.337 INFO  [Executor task launch worker for task 214] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=8),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/8] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/8/2.delta
09:20:55.337 INFO  [Executor task launch worker for task 215] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=9),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/9] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/9/2.delta
09:20:55.337 INFO  [Executor task launch worker for task 216] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=10),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/10] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/10/2.delta
09:20:55.337 INFO  [Executor task launch worker for task 214] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=8),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/8]
09:20:55.353 INFO  [Executor task launch worker for task 214] org.apache.spark.executor.Executor - Finished task 8.0 in stage 5.0 (TID 214). 3322 bytes result sent to driver
09:20:55.353 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 11.0 in stage 5.0 (TID 217, localhost, executor driver, partition 11, PROCESS_LOCAL, 4726 bytes)
09:20:55.353 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 8.0 in stage 5.0 (TID 214) in 31 ms on localhost (executor driver) (9/200)
09:20:55.353 INFO  [Executor task launch worker for task 217] org.apache.spark.executor.Executor - Running task 11.0 in stage 5.0 (TID 217)
09:20:55.353 INFO  [Executor task launch worker for task 217] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=11), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/11] for update
09:20:55.353 INFO  [Executor task launch worker for task 217] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=11), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/11] for update
09:20:55.353 INFO  [Executor task launch worker for task 215] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=9),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/9]
09:20:55.353 INFO  [Executor task launch worker for task 216] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=10),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/10]
09:20:55.353 INFO  [Executor task launch worker for task 217] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.353 INFO  [Executor task launch worker for task 217] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.353 INFO  [Executor task launch worker for task 215] org.apache.spark.executor.Executor - Finished task 9.0 in stage 5.0 (TID 215). 3322 bytes result sent to driver
09:20:55.353 INFO  [Executor task launch worker for task 216] org.apache.spark.executor.Executor - Finished task 10.0 in stage 5.0 (TID 216). 3322 bytes result sent to driver
09:20:55.353 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 12.0 in stage 5.0 (TID 218, localhost, executor driver, partition 12, PROCESS_LOCAL, 4726 bytes)
09:20:55.353 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 9.0 in stage 5.0 (TID 215) in 31 ms on localhost (executor driver) (10/200)
09:20:55.353 INFO  [Executor task launch worker for task 218] org.apache.spark.executor.Executor - Running task 12.0 in stage 5.0 (TID 218)
09:20:55.353 INFO  [Executor task launch worker for task 217] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=11),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/11] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/11/2.delta
09:20:55.369 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 10.0 in stage 5.0 (TID 216) in 32 ms on localhost (executor driver) (11/200)
09:20:55.369 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 13.0 in stage 5.0 (TID 219, localhost, executor driver, partition 13, PROCESS_LOCAL, 4726 bytes)
09:20:55.369 INFO  [Executor task launch worker for task 219] org.apache.spark.executor.Executor - Running task 13.0 in stage 5.0 (TID 219)
09:20:55.369 INFO  [Executor task launch worker for task 219] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=13), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/13] for update
09:20:55.369 INFO  [Executor task launch worker for task 219] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=13), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/13] for update
09:20:55.369 INFO  [Executor task launch worker for task 219] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.369 INFO  [Executor task launch worker for task 219] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.369 INFO  [Executor task launch worker for task 218] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=12), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/12] for update
09:20:55.369 INFO  [Executor task launch worker for task 218] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=12), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/12] for update
09:20:55.369 INFO  [Executor task launch worker for task 218] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.369 INFO  [Executor task launch worker for task 218] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.369 INFO  [Executor task launch worker for task 217] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=11),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/11]
09:20:55.369 INFO  [Executor task launch worker for task 217] org.apache.spark.executor.Executor - Finished task 11.0 in stage 5.0 (TID 217). 3322 bytes result sent to driver
09:20:55.369 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 14.0 in stage 5.0 (TID 220, localhost, executor driver, partition 14, PROCESS_LOCAL, 4726 bytes)
09:20:55.369 INFO  [Executor task launch worker for task 218] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=12),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/12] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/12/2.delta
09:20:55.369 INFO  [Executor task launch worker for task 219] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=13),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/13] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/13/2.delta
09:20:55.384 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 11.0 in stage 5.0 (TID 217) in 31 ms on localhost (executor driver) (12/200)
09:20:55.384 INFO  [Executor task launch worker for task 220] org.apache.spark.executor.Executor - Running task 14.0 in stage 5.0 (TID 220)
09:20:55.384 INFO  [Executor task launch worker for task 220] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=14), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/14] for update
09:20:55.384 INFO  [Executor task launch worker for task 220] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=14), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/14] for update
09:20:55.384 INFO  [Executor task launch worker for task 220] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.384 INFO  [Executor task launch worker for task 220] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.384 INFO  [Executor task launch worker for task 219] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=13),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/13]
09:20:55.384 INFO  [Executor task launch worker for task 218] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=12),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/12]
09:20:55.384 INFO  [Executor task launch worker for task 218] org.apache.spark.executor.Executor - Finished task 12.0 in stage 5.0 (TID 218). 3365 bytes result sent to driver
09:20:55.384 INFO  [Executor task launch worker for task 219] org.apache.spark.executor.Executor - Finished task 13.0 in stage 5.0 (TID 219). 3322 bytes result sent to driver
09:20:55.384 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 15.0 in stage 5.0 (TID 221, localhost, executor driver, partition 15, PROCESS_LOCAL, 4726 bytes)
09:20:55.384 INFO  [Executor task launch worker for task 221] org.apache.spark.executor.Executor - Running task 15.0 in stage 5.0 (TID 221)
09:20:55.384 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 16.0 in stage 5.0 (TID 222, localhost, executor driver, partition 16, PROCESS_LOCAL, 4726 bytes)
09:20:55.384 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 13.0 in stage 5.0 (TID 219) in 15 ms on localhost (executor driver) (13/200)
09:20:55.384 INFO  [Executor task launch worker for task 222] org.apache.spark.executor.Executor - Running task 16.0 in stage 5.0 (TID 222)
09:20:55.384 INFO  [Executor task launch worker for task 221] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=15), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/15] for update
09:20:55.384 INFO  [Executor task launch worker for task 220] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=14),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/14] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/14/2.delta
09:20:55.400 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 12.0 in stage 5.0 (TID 218) in 47 ms on localhost (executor driver) (14/200)
09:20:55.400 INFO  [Executor task launch worker for task 221] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=15), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/15] for update
09:20:55.400 INFO  [Executor task launch worker for task 221] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.400 INFO  [Executor task launch worker for task 221] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.400 INFO  [Executor task launch worker for task 222] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=16), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/16] for update
09:20:55.400 INFO  [Executor task launch worker for task 222] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=16), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/16] for update
09:20:55.400 INFO  [Executor task launch worker for task 222] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.400 INFO  [Executor task launch worker for task 222] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.400 INFO  [Executor task launch worker for task 220] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=14),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/14]
09:20:55.400 INFO  [Executor task launch worker for task 220] org.apache.spark.executor.Executor - Finished task 14.0 in stage 5.0 (TID 220). 3322 bytes result sent to driver
09:20:55.400 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 17.0 in stage 5.0 (TID 223, localhost, executor driver, partition 17, PROCESS_LOCAL, 4726 bytes)
09:20:55.400 INFO  [Executor task launch worker for task 223] org.apache.spark.executor.Executor - Running task 17.0 in stage 5.0 (TID 223)
09:20:55.400 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 14.0 in stage 5.0 (TID 220) in 31 ms on localhost (executor driver) (15/200)
09:20:55.400 INFO  [Executor task launch worker for task 223] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=17), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/17] for update
09:20:55.400 INFO  [Executor task launch worker for task 221] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=15),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/15] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/15/2.delta
09:20:55.400 INFO  [Executor task launch worker for task 222] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=16),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/16] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/16/2.delta
09:20:55.415 INFO  [Executor task launch worker for task 223] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=17), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/17] for update
09:20:55.415 INFO  [Executor task launch worker for task 223] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.415 INFO  [Executor task launch worker for task 223] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.415 INFO  [Executor task launch worker for task 223] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=17),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/17] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/17/2.delta
09:20:55.415 INFO  [Executor task launch worker for task 222] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=16),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/16]
09:20:55.415 INFO  [Executor task launch worker for task 221] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=15),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/15]
09:20:55.415 INFO  [Executor task launch worker for task 222] org.apache.spark.executor.Executor - Finished task 16.0 in stage 5.0 (TID 222). 3365 bytes result sent to driver
09:20:55.415 INFO  [Executor task launch worker for task 221] org.apache.spark.executor.Executor - Finished task 15.0 in stage 5.0 (TID 221). 3322 bytes result sent to driver
09:20:55.415 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 18.0 in stage 5.0 (TID 224, localhost, executor driver, partition 18, PROCESS_LOCAL, 4726 bytes)
09:20:55.415 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 16.0 in stage 5.0 (TID 222) in 31 ms on localhost (executor driver) (16/200)
09:20:55.415 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 19.0 in stage 5.0 (TID 225, localhost, executor driver, partition 19, PROCESS_LOCAL, 4726 bytes)
09:20:55.415 INFO  [Executor task launch worker for task 225] org.apache.spark.executor.Executor - Running task 19.0 in stage 5.0 (TID 225)
09:20:55.415 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 15.0 in stage 5.0 (TID 221) in 31 ms on localhost (executor driver) (17/200)
09:20:55.415 INFO  [Executor task launch worker for task 223] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=17),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/17]
09:20:55.415 INFO  [Executor task launch worker for task 224] org.apache.spark.executor.Executor - Running task 18.0 in stage 5.0 (TID 224)
09:20:55.415 INFO  [Executor task launch worker for task 223] org.apache.spark.executor.Executor - Finished task 17.0 in stage 5.0 (TID 223). 3322 bytes result sent to driver
09:20:55.415 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 20.0 in stage 5.0 (TID 226, localhost, executor driver, partition 20, PROCESS_LOCAL, 4726 bytes)
09:20:55.415 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 17.0 in stage 5.0 (TID 223) in 15 ms on localhost (executor driver) (18/200)
09:20:55.415 INFO  [Executor task launch worker for task 226] org.apache.spark.executor.Executor - Running task 20.0 in stage 5.0 (TID 226)
09:20:55.431 INFO  [Executor task launch worker for task 225] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=19), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/19] for update
09:20:55.431 INFO  [Executor task launch worker for task 225] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=19), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/19] for update
09:20:55.431 INFO  [Executor task launch worker for task 225] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 2 blocks
09:20:55.431 INFO  [Executor task launch worker for task 225] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.431 INFO  [Executor task launch worker for task 226] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=20), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/20] for update
09:20:55.431 INFO  [Executor task launch worker for task 226] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=20), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/20] for update
09:20:55.431 INFO  [Executor task launch worker for task 226] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.431 INFO  [Executor task launch worker for task 226] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.431 INFO  [Executor task launch worker for task 224] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=18), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/18] for update
09:20:55.431 INFO  [Executor task launch worker for task 224] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=18), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/18] for update
09:20:55.431 INFO  [Executor task launch worker for task 224] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.431 INFO  [Executor task launch worker for task 224] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.431 INFO  [Executor task launch worker for task 224] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=18),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/18] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/18/2.delta
09:20:55.431 INFO  [Executor task launch worker for task 226] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=20),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/20] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/20/2.delta
09:20:55.447 INFO  [Executor task launch worker for task 224] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=18),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/18]
09:20:55.447 INFO  [Executor task launch worker for task 226] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=20),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/20]
09:20:55.447 INFO  [Executor task launch worker for task 224] org.apache.spark.executor.Executor - Finished task 18.0 in stage 5.0 (TID 224). 3408 bytes result sent to driver
09:20:55.447 INFO  [Executor task launch worker for task 226] org.apache.spark.executor.Executor - Finished task 20.0 in stage 5.0 (TID 226). 3408 bytes result sent to driver
09:20:55.447 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 21.0 in stage 5.0 (TID 227, localhost, executor driver, partition 21, PROCESS_LOCAL, 4726 bytes)
09:20:55.447 INFO  [Executor task launch worker for task 227] org.apache.spark.executor.Executor - Running task 21.0 in stage 5.0 (TID 227)
09:20:55.447 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 18.0 in stage 5.0 (TID 224) in 32 ms on localhost (executor driver) (19/200)
09:20:55.447 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 22.0 in stage 5.0 (TID 228, localhost, executor driver, partition 22, PROCESS_LOCAL, 4726 bytes)
09:20:55.447 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 20.0 in stage 5.0 (TID 226) in 32 ms on localhost (executor driver) (20/200)
09:20:55.447 INFO  [Executor task launch worker for task 228] org.apache.spark.executor.Executor - Running task 22.0 in stage 5.0 (TID 228)
09:20:55.447 INFO  [Executor task launch worker for task 227] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=21), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/21] for update
09:20:55.447 INFO  [Executor task launch worker for task 227] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=21), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/21] for update
09:20:55.447 INFO  [Executor task launch worker for task 227] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.447 INFO  [Executor task launch worker for task 227] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.447 INFO  [Executor task launch worker for task 228] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=22), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/22] for update
09:20:55.447 INFO  [Executor task launch worker for task 228] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=22), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/22] for update
09:20:55.447 INFO  [Executor task launch worker for task 228] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.447 INFO  [Executor task launch worker for task 227] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=21),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/21] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/21/2.delta
09:20:55.462 INFO  [Executor task launch worker for task 228] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 15 ms
09:20:55.462 INFO  [Executor task launch worker for task 225] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=19),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/19] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/19/2.delta
09:20:55.462 INFO  [Executor task launch worker for task 225] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=19),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/19]
09:20:55.462 INFO  [Executor task launch worker for task 228] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=22),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/22] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/22/2.delta
09:20:55.462 INFO  [Executor task launch worker for task 225] org.apache.spark.executor.Executor - Finished task 19.0 in stage 5.0 (TID 225). 3394 bytes result sent to driver
09:20:55.462 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 23.0 in stage 5.0 (TID 229, localhost, executor driver, partition 23, PROCESS_LOCAL, 4726 bytes)
09:20:55.462 INFO  [Executor task launch worker for task 229] org.apache.spark.executor.Executor - Running task 23.0 in stage 5.0 (TID 229)
09:20:55.462 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 19.0 in stage 5.0 (TID 225) in 47 ms on localhost (executor driver) (21/200)
09:20:55.462 INFO  [Executor task launch worker for task 229] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=23), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/23] for update
09:20:55.462 INFO  [Executor task launch worker for task 229] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=23), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/23] for update
09:20:55.462 INFO  [Executor task launch worker for task 229] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.462 INFO  [Executor task launch worker for task 229] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.462 INFO  [Executor task launch worker for task 227] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=21),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/21]
09:20:55.462 INFO  [Executor task launch worker for task 227] org.apache.spark.executor.Executor - Finished task 21.0 in stage 5.0 (TID 227). 3322 bytes result sent to driver
09:20:55.478 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 24.0 in stage 5.0 (TID 230, localhost, executor driver, partition 24, PROCESS_LOCAL, 4726 bytes)
09:20:55.478 INFO  [Executor task launch worker for task 230] org.apache.spark.executor.Executor - Running task 24.0 in stage 5.0 (TID 230)
09:20:55.478 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 21.0 in stage 5.0 (TID 227) in 31 ms on localhost (executor driver) (22/200)
09:20:55.478 INFO  [Executor task launch worker for task 228] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=22),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/22]
09:20:55.478 INFO  [Executor task launch worker for task 228] org.apache.spark.executor.Executor - Finished task 22.0 in stage 5.0 (TID 228). 3365 bytes result sent to driver
09:20:55.478 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 25.0 in stage 5.0 (TID 231, localhost, executor driver, partition 25, PROCESS_LOCAL, 4726 bytes)
09:20:55.478 INFO  [Executor task launch worker for task 231] org.apache.spark.executor.Executor - Running task 25.0 in stage 5.0 (TID 231)
09:20:55.478 INFO  [Executor task launch worker for task 229] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=23),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/23] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/23/2.delta
09:20:55.478 INFO  [Executor task launch worker for task 230] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=24), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/24] for update
09:20:55.478 INFO  [Executor task launch worker for task 230] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=24), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/24] for update
09:20:55.478 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 22.0 in stage 5.0 (TID 228) in 31 ms on localhost (executor driver) (23/200)
09:20:55.478 INFO  [Executor task launch worker for task 230] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.478 INFO  [Executor task launch worker for task 230] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.478 INFO  [Executor task launch worker for task 231] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=25), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/25] for update
09:20:55.478 INFO  [Executor task launch worker for task 231] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=25), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/25] for update
09:20:55.478 INFO  [Executor task launch worker for task 231] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.478 INFO  [Executor task launch worker for task 229] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=23),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/23]
09:20:55.478 INFO  [Executor task launch worker for task 230] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=24),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/24] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/24/2.delta
09:20:55.494 INFO  [Executor task launch worker for task 231] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 16 ms
09:20:55.494 INFO  [Executor task launch worker for task 229] org.apache.spark.executor.Executor - Finished task 23.0 in stage 5.0 (TID 229). 3365 bytes result sent to driver
09:20:55.494 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 26.0 in stage 5.0 (TID 232, localhost, executor driver, partition 26, PROCESS_LOCAL, 4726 bytes)
09:20:55.494 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 23.0 in stage 5.0 (TID 229) in 32 ms on localhost (executor driver) (24/200)
09:20:55.494 INFO  [Executor task launch worker for task 232] org.apache.spark.executor.Executor - Running task 26.0 in stage 5.0 (TID 232)
09:20:55.494 INFO  [Executor task launch worker for task 232] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=26), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/26] for update
09:20:55.494 INFO  [Executor task launch worker for task 232] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=26), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/26] for update
09:20:55.494 INFO  [Executor task launch worker for task 232] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.494 INFO  [Executor task launch worker for task 232] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.494 INFO  [Executor task launch worker for task 230] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=24),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/24]
09:20:55.494 INFO  [Executor task launch worker for task 230] org.apache.spark.executor.Executor - Finished task 24.0 in stage 5.0 (TID 230). 3322 bytes result sent to driver
09:20:55.494 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 27.0 in stage 5.0 (TID 233, localhost, executor driver, partition 27, PROCESS_LOCAL, 4726 bytes)
09:20:55.494 INFO  [Executor task launch worker for task 231] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=25),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/25] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/25/2.delta
09:20:55.494 INFO  [Executor task launch worker for task 233] org.apache.spark.executor.Executor - Running task 27.0 in stage 5.0 (TID 233)
09:20:55.494 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 24.0 in stage 5.0 (TID 230) in 16 ms on localhost (executor driver) (25/200)
09:20:55.494 INFO  [Executor task launch worker for task 232] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=26),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/26] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/26/2.delta
09:20:55.494 INFO  [Executor task launch worker for task 233] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=27), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/27] for update
09:20:55.494 INFO  [Executor task launch worker for task 231] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=25),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/25]
09:20:55.509 INFO  [Executor task launch worker for task 233] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=27), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/27] for update
09:20:55.509 INFO  [Executor task launch worker for task 233] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.509 INFO  [Executor task launch worker for task 231] org.apache.spark.executor.Executor - Finished task 25.0 in stage 5.0 (TID 231). 3322 bytes result sent to driver
09:20:55.509 INFO  [Executor task launch worker for task 233] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.509 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 28.0 in stage 5.0 (TID 234, localhost, executor driver, partition 28, PROCESS_LOCAL, 4726 bytes)
09:20:55.509 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 25.0 in stage 5.0 (TID 231) in 31 ms on localhost (executor driver) (26/200)
09:20:55.509 INFO  [Executor task launch worker for task 234] org.apache.spark.executor.Executor - Running task 28.0 in stage 5.0 (TID 234)
09:20:55.509 INFO  [Executor task launch worker for task 232] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=26),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/26]
09:20:55.509 INFO  [Executor task launch worker for task 234] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=28), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/28] for update
09:20:55.509 INFO  [Executor task launch worker for task 232] org.apache.spark.executor.Executor - Finished task 26.0 in stage 5.0 (TID 232). 3322 bytes result sent to driver
09:20:55.509 INFO  [Executor task launch worker for task 234] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=28), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/28] for update
09:20:55.509 INFO  [Executor task launch worker for task 234] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.509 INFO  [Executor task launch worker for task 234] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.509 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 29.0 in stage 5.0 (TID 235, localhost, executor driver, partition 29, PROCESS_LOCAL, 4726 bytes)
09:20:55.509 INFO  [Executor task launch worker for task 235] org.apache.spark.executor.Executor - Running task 29.0 in stage 5.0 (TID 235)
09:20:55.509 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 26.0 in stage 5.0 (TID 232) in 15 ms on localhost (executor driver) (27/200)
09:20:55.509 INFO  [Executor task launch worker for task 235] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=29), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/29] for update
09:20:55.509 INFO  [Executor task launch worker for task 233] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=27),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/27] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/27/2.delta
09:20:55.525 INFO  [Executor task launch worker for task 235] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=29), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/29] for update
09:20:55.525 INFO  [Executor task launch worker for task 235] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.525 INFO  [Executor task launch worker for task 235] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.525 INFO  [Executor task launch worker for task 234] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=28),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/28] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/28/2.delta
09:20:55.525 INFO  [Executor task launch worker for task 233] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=27),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/27]
09:20:55.525 INFO  [Executor task launch worker for task 233] org.apache.spark.executor.Executor - Finished task 27.0 in stage 5.0 (TID 233). 3322 bytes result sent to driver
09:20:55.525 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 30.0 in stage 5.0 (TID 236, localhost, executor driver, partition 30, PROCESS_LOCAL, 4726 bytes)
09:20:55.525 INFO  [Executor task launch worker for task 234] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=28),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/28]
09:20:55.525 INFO  [Executor task launch worker for task 236] org.apache.spark.executor.Executor - Running task 30.0 in stage 5.0 (TID 236)
09:20:55.525 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 27.0 in stage 5.0 (TID 233) in 31 ms on localhost (executor driver) (28/200)
09:20:55.525 INFO  [Executor task launch worker for task 234] org.apache.spark.executor.Executor - Finished task 28.0 in stage 5.0 (TID 234). 3365 bytes result sent to driver
09:20:55.525 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 31.0 in stage 5.0 (TID 237, localhost, executor driver, partition 31, PROCESS_LOCAL, 4726 bytes)
09:20:55.525 INFO  [Executor task launch worker for task 237] org.apache.spark.executor.Executor - Running task 31.0 in stage 5.0 (TID 237)
09:20:55.525 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 28.0 in stage 5.0 (TID 234) in 16 ms on localhost (executor driver) (29/200)
09:20:55.525 INFO  [Executor task launch worker for task 235] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=29),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/29] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/29/2.delta
09:20:55.525 INFO  [Executor task launch worker for task 236] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=30), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/30] for update
09:20:55.525 INFO  [Executor task launch worker for task 237] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=31), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/31] for update
09:20:55.540 INFO  [Executor task launch worker for task 237] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=31), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/31] for update
09:20:55.540 INFO  [Executor task launch worker for task 236] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=30), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/30] for update
09:20:55.540 INFO  [Executor task launch worker for task 237] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.540 INFO  [Executor task launch worker for task 236] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.540 INFO  [Executor task launch worker for task 237] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.540 INFO  [Executor task launch worker for task 236] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.540 INFO  [Executor task launch worker for task 235] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=29),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/29]
09:20:55.540 INFO  [Executor task launch worker for task 235] org.apache.spark.executor.Executor - Finished task 29.0 in stage 5.0 (TID 235). 3322 bytes result sent to driver
09:20:55.540 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 32.0 in stage 5.0 (TID 238, localhost, executor driver, partition 32, PROCESS_LOCAL, 4726 bytes)
09:20:55.540 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 29.0 in stage 5.0 (TID 235) in 31 ms on localhost (executor driver) (30/200)
09:20:55.540 INFO  [Executor task launch worker for task 238] org.apache.spark.executor.Executor - Running task 32.0 in stage 5.0 (TID 238)
09:20:55.540 INFO  [Executor task launch worker for task 238] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=32), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/32] for update
09:20:55.540 INFO  [Executor task launch worker for task 238] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=32), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/32] for update
09:20:55.540 INFO  [Executor task launch worker for task 237] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=31),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/31] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/31/2.delta
09:20:55.540 INFO  [Executor task launch worker for task 238] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.540 INFO  [Executor task launch worker for task 236] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=30),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/30] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/30/2.delta
09:20:55.540 INFO  [Executor task launch worker for task 237] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=31),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/31]
09:20:55.556 INFO  [Executor task launch worker for task 238] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 16 ms
09:20:55.556 INFO  [Executor task launch worker for task 237] org.apache.spark.executor.Executor - Finished task 31.0 in stage 5.0 (TID 237). 3322 bytes result sent to driver
09:20:55.556 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 33.0 in stage 5.0 (TID 239, localhost, executor driver, partition 33, PROCESS_LOCAL, 4726 bytes)
09:20:55.556 INFO  [Executor task launch worker for task 239] org.apache.spark.executor.Executor - Running task 33.0 in stage 5.0 (TID 239)
09:20:55.556 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 31.0 in stage 5.0 (TID 237) in 31 ms on localhost (executor driver) (31/200)
09:20:55.556 INFO  [Executor task launch worker for task 239] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=33), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/33] for update
09:20:55.556 INFO  [Executor task launch worker for task 239] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=33), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/33] for update
09:20:55.556 INFO  [Executor task launch worker for task 239] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.556 INFO  [Executor task launch worker for task 239] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.556 INFO  [Executor task launch worker for task 236] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=30),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/30]
09:20:55.556 INFO  [Executor task launch worker for task 236] org.apache.spark.executor.Executor - Finished task 30.0 in stage 5.0 (TID 236). 3322 bytes result sent to driver
09:20:55.556 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 34.0 in stage 5.0 (TID 240, localhost, executor driver, partition 34, PROCESS_LOCAL, 4726 bytes)
09:20:55.556 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 30.0 in stage 5.0 (TID 236) in 31 ms on localhost (executor driver) (32/200)
09:20:55.556 INFO  [Executor task launch worker for task 238] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=32),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/32] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/32/2.delta
09:20:55.556 INFO  [Executor task launch worker for task 240] org.apache.spark.executor.Executor - Running task 34.0 in stage 5.0 (TID 240)
09:20:55.556 INFO  [Executor task launch worker for task 239] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=33),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/33] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/33/2.delta
09:20:55.572 INFO  [Executor task launch worker for task 240] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=34), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/34] for update
09:20:55.572 INFO  [Executor task launch worker for task 240] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=34), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/34] for update
09:20:55.572 INFO  [Executor task launch worker for task 240] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.572 INFO  [Executor task launch worker for task 240] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.572 INFO  [Executor task launch worker for task 239] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=33),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/33]
09:20:55.572 INFO  [Executor task launch worker for task 239] org.apache.spark.executor.Executor - Finished task 33.0 in stage 5.0 (TID 239). 3322 bytes result sent to driver
09:20:55.572 INFO  [Executor task launch worker for task 238] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=32),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/32]
09:20:55.572 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 35.0 in stage 5.0 (TID 241, localhost, executor driver, partition 35, PROCESS_LOCAL, 4726 bytes)
09:20:55.572 INFO  [Executor task launch worker for task 238] org.apache.spark.executor.Executor - Finished task 32.0 in stage 5.0 (TID 238). 3322 bytes result sent to driver
09:20:55.572 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 33.0 in stage 5.0 (TID 239) in 16 ms on localhost (executor driver) (33/200)
09:20:55.572 INFO  [Executor task launch worker for task 241] org.apache.spark.executor.Executor - Running task 35.0 in stage 5.0 (TID 241)
09:20:55.572 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 36.0 in stage 5.0 (TID 242, localhost, executor driver, partition 36, PROCESS_LOCAL, 4726 bytes)
09:20:55.572 INFO  [Executor task launch worker for task 242] org.apache.spark.executor.Executor - Running task 36.0 in stage 5.0 (TID 242)
09:20:55.572 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 32.0 in stage 5.0 (TID 238) in 32 ms on localhost (executor driver) (34/200)
09:20:55.572 INFO  [Executor task launch worker for task 241] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=35), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/35] for update
09:20:55.572 INFO  [Executor task launch worker for task 242] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=36), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/36] for update
09:20:55.572 INFO  [Executor task launch worker for task 240] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=34),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/34] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/34/2.delta
09:20:55.587 INFO  [Executor task launch worker for task 242] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=36), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/36] for update
09:20:55.587 INFO  [Executor task launch worker for task 241] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=35), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/35] for update
09:20:55.587 INFO  [Executor task launch worker for task 242] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.587 INFO  [Executor task launch worker for task 241] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.587 INFO  [Executor task launch worker for task 242] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.587 INFO  [Executor task launch worker for task 241] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.587 INFO  [Executor task launch worker for task 240] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=34),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/34]
09:20:55.587 INFO  [Executor task launch worker for task 240] org.apache.spark.executor.Executor - Finished task 34.0 in stage 5.0 (TID 240). 3365 bytes result sent to driver
09:20:55.587 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 37.0 in stage 5.0 (TID 243, localhost, executor driver, partition 37, PROCESS_LOCAL, 4726 bytes)
09:20:55.587 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 34.0 in stage 5.0 (TID 240) in 31 ms on localhost (executor driver) (35/200)
09:20:55.587 INFO  [Executor task launch worker for task 243] org.apache.spark.executor.Executor - Running task 37.0 in stage 5.0 (TID 243)
09:20:55.587 INFO  [Executor task launch worker for task 242] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=36),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/36] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/36/2.delta
09:20:55.587 INFO  [Executor task launch worker for task 243] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=37), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/37] for update
09:20:55.587 INFO  [Executor task launch worker for task 243] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=37), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/37] for update
09:20:55.587 INFO  [Executor task launch worker for task 241] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=35),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/35] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/35/2.delta
09:20:55.587 INFO  [Executor task launch worker for task 242] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=36),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/36]
09:20:55.603 INFO  [Executor task launch worker for task 243] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.603 INFO  [Executor task launch worker for task 243] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.603 INFO  [Executor task launch worker for task 242] org.apache.spark.executor.Executor - Finished task 36.0 in stage 5.0 (TID 242). 3322 bytes result sent to driver
09:20:55.603 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 38.0 in stage 5.0 (TID 244, localhost, executor driver, partition 38, PROCESS_LOCAL, 4726 bytes)
09:20:55.603 INFO  [Executor task launch worker for task 244] org.apache.spark.executor.Executor - Running task 38.0 in stage 5.0 (TID 244)
09:20:55.603 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 36.0 in stage 5.0 (TID 242) in 31 ms on localhost (executor driver) (36/200)
09:20:55.603 INFO  [Executor task launch worker for task 244] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=38), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/38] for update
09:20:55.603 INFO  [Executor task launch worker for task 244] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=38), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/38] for update
09:20:55.603 INFO  [Executor task launch worker for task 244] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.603 INFO  [Executor task launch worker for task 244] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.603 INFO  [Executor task launch worker for task 241] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=35),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/35]
09:20:55.603 INFO  [Executor task launch worker for task 241] org.apache.spark.executor.Executor - Finished task 35.0 in stage 5.0 (TID 241). 3322 bytes result sent to driver
09:20:55.603 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 39.0 in stage 5.0 (TID 245, localhost, executor driver, partition 39, PROCESS_LOCAL, 4726 bytes)
09:20:55.603 INFO  [Executor task launch worker for task 243] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=37),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/37] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/37/2.delta
09:20:55.603 INFO  [Executor task launch worker for task 245] org.apache.spark.executor.Executor - Running task 39.0 in stage 5.0 (TID 245)
09:20:55.603 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 35.0 in stage 5.0 (TID 241) in 31 ms on localhost (executor driver) (37/200)
09:20:55.619 INFO  [Executor task launch worker for task 244] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=38),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/38] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/38/2.delta
09:20:55.619 INFO  [Executor task launch worker for task 245] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=39), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/39] for update
09:20:55.619 INFO  [Executor task launch worker for task 245] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=39), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/39] for update
09:20:55.619 INFO  [Executor task launch worker for task 245] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.619 INFO  [Executor task launch worker for task 245] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.619 INFO  [Executor task launch worker for task 243] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=37),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/37]
09:20:55.619 INFO  [Executor task launch worker for task 243] org.apache.spark.executor.Executor - Finished task 37.0 in stage 5.0 (TID 243). 3322 bytes result sent to driver
09:20:55.619 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 40.0 in stage 5.0 (TID 246, localhost, executor driver, partition 40, PROCESS_LOCAL, 4726 bytes)
09:20:55.619 INFO  [Executor task launch worker for task 244] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=38),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/38]
09:20:55.619 INFO  [Executor task launch worker for task 244] org.apache.spark.executor.Executor - Finished task 38.0 in stage 5.0 (TID 244). 3365 bytes result sent to driver
09:20:55.619 INFO  [Executor task launch worker for task 246] org.apache.spark.executor.Executor - Running task 40.0 in stage 5.0 (TID 246)
09:20:55.619 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 37.0 in stage 5.0 (TID 243) in 32 ms on localhost (executor driver) (38/200)
09:20:55.619 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 41.0 in stage 5.0 (TID 247, localhost, executor driver, partition 41, PROCESS_LOCAL, 4726 bytes)
09:20:55.619 INFO  [Executor task launch worker for task 247] org.apache.spark.executor.Executor - Running task 41.0 in stage 5.0 (TID 247)
09:20:55.619 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 38.0 in stage 5.0 (TID 244) in 16 ms on localhost (executor driver) (39/200)
09:20:55.619 INFO  [Executor task launch worker for task 246] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=40), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/40] for update
09:20:55.619 INFO  [Executor task launch worker for task 247] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=41), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/41] for update
09:20:55.619 INFO  [Executor task launch worker for task 245] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=39),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/39] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/39/2.delta
09:20:55.634 INFO  [Executor task launch worker for task 246] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=40), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/40] for update
09:20:55.634 INFO  [Executor task launch worker for task 247] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=41), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/41] for update
09:20:55.634 INFO  [Executor task launch worker for task 246] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.634 INFO  [Executor task launch worker for task 247] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.634 INFO  [Executor task launch worker for task 246] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.634 INFO  [Executor task launch worker for task 247] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.634 INFO  [Executor task launch worker for task 245] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=39),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/39]
09:20:55.634 INFO  [Executor task launch worker for task 245] org.apache.spark.executor.Executor - Finished task 39.0 in stage 5.0 (TID 245). 3365 bytes result sent to driver
09:20:55.634 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 42.0 in stage 5.0 (TID 248, localhost, executor driver, partition 42, PROCESS_LOCAL, 4726 bytes)
09:20:55.634 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 39.0 in stage 5.0 (TID 245) in 31 ms on localhost (executor driver) (40/200)
09:20:55.634 INFO  [Executor task launch worker for task 248] org.apache.spark.executor.Executor - Running task 42.0 in stage 5.0 (TID 248)
09:20:55.634 INFO  [Executor task launch worker for task 248] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=42), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/42] for update
09:20:55.634 INFO  [Executor task launch worker for task 248] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=42), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/42] for update
09:20:55.634 INFO  [Executor task launch worker for task 248] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.634 INFO  [Executor task launch worker for task 247] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=41),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/41] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/41/2.delta
09:20:55.634 INFO  [Executor task launch worker for task 246] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=40),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/40] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/40/2.delta
09:20:55.650 INFO  [Executor task launch worker for task 248] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 16 ms
09:20:55.650 INFO  [Executor task launch worker for task 247] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=41),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/41]
09:20:55.650 INFO  [Executor task launch worker for task 247] org.apache.spark.executor.Executor - Finished task 41.0 in stage 5.0 (TID 247). 3322 bytes result sent to driver
09:20:55.650 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 43.0 in stage 5.0 (TID 249, localhost, executor driver, partition 43, PROCESS_LOCAL, 4726 bytes)
09:20:55.650 INFO  [Executor task launch worker for task 249] org.apache.spark.executor.Executor - Running task 43.0 in stage 5.0 (TID 249)
09:20:55.650 INFO  [Executor task launch worker for task 248] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=42),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/42] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/42/2.delta
09:20:55.650 INFO  [Executor task launch worker for task 249] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=43), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/43] for update
09:20:55.650 INFO  [Executor task launch worker for task 249] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=43), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/43] for update
09:20:55.650 INFO  [Executor task launch worker for task 249] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.650 INFO  [Executor task launch worker for task 249] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.650 INFO  [Executor task launch worker for task 248] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=42),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/42]
09:20:55.650 INFO  [Executor task launch worker for task 248] org.apache.spark.executor.Executor - Finished task 42.0 in stage 5.0 (TID 248). 3322 bytes result sent to driver
09:20:55.665 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 44.0 in stage 5.0 (TID 250, localhost, executor driver, partition 44, PROCESS_LOCAL, 4726 bytes)
09:20:55.665 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 42.0 in stage 5.0 (TID 248) in 31 ms on localhost (executor driver) (41/200)
09:20:55.665 INFO  [Executor task launch worker for task 250] org.apache.spark.executor.Executor - Running task 44.0 in stage 5.0 (TID 250)
09:20:55.665 INFO  [Executor task launch worker for task 249] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=43),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/43] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/43/2.delta
09:20:55.665 INFO  [Executor task launch worker for task 250] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=44), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/44] for update
09:20:55.665 INFO  [Executor task launch worker for task 250] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=44), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/44] for update
09:20:55.665 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 41.0 in stage 5.0 (TID 247) in 46 ms on localhost (executor driver) (42/200)
09:20:55.665 INFO  [Executor task launch worker for task 250] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.665 INFO  [Executor task launch worker for task 250] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.665 INFO  [Executor task launch worker for task 246] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=40),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/40]
09:20:55.665 INFO  [Executor task launch worker for task 246] org.apache.spark.executor.Executor - Finished task 40.0 in stage 5.0 (TID 246). 3322 bytes result sent to driver
09:20:55.665 INFO  [Executor task launch worker for task 249] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=43),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/43]
09:20:55.665 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 45.0 in stage 5.0 (TID 251, localhost, executor driver, partition 45, PROCESS_LOCAL, 4726 bytes)
09:20:55.665 INFO  [Executor task launch worker for task 251] org.apache.spark.executor.Executor - Running task 45.0 in stage 5.0 (TID 251)
09:20:55.665 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 40.0 in stage 5.0 (TID 246) in 46 ms on localhost (executor driver) (43/200)
09:20:55.665 INFO  [Executor task launch worker for task 249] org.apache.spark.executor.Executor - Finished task 43.0 in stage 5.0 (TID 249). 3365 bytes result sent to driver
09:20:55.681 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 46.0 in stage 5.0 (TID 252, localhost, executor driver, partition 46, PROCESS_LOCAL, 4726 bytes)
09:20:55.681 INFO  [Executor task launch worker for task 251] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=45), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/45] for update
09:20:55.681 INFO  [Executor task launch worker for task 251] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=45), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/45] for update
09:20:55.681 INFO  [Executor task launch worker for task 251] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.681 INFO  [Executor task launch worker for task 251] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.681 INFO  [Executor task launch worker for task 250] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=44),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/44] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/44/2.delta
09:20:55.681 INFO  [Executor task launch worker for task 252] org.apache.spark.executor.Executor - Running task 46.0 in stage 5.0 (TID 252)
09:20:55.681 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 43.0 in stage 5.0 (TID 249) in 31 ms on localhost (executor driver) (44/200)
09:20:55.681 INFO  [Executor task launch worker for task 252] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=46), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/46] for update
09:20:55.681 INFO  [Executor task launch worker for task 252] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=46), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/46] for update
09:20:55.681 INFO  [Executor task launch worker for task 252] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.681 INFO  [Executor task launch worker for task 252] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.681 INFO  [Executor task launch worker for task 250] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=44),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/44]
09:20:55.681 INFO  [Executor task launch worker for task 250] org.apache.spark.executor.Executor - Finished task 44.0 in stage 5.0 (TID 250). 3365 bytes result sent to driver
09:20:55.681 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 47.0 in stage 5.0 (TID 253, localhost, executor driver, partition 47, PROCESS_LOCAL, 4726 bytes)
09:20:55.681 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 44.0 in stage 5.0 (TID 250) in 16 ms on localhost (executor driver) (45/200)
09:20:55.681 INFO  [Executor task launch worker for task 253] org.apache.spark.executor.Executor - Running task 47.0 in stage 5.0 (TID 253)
09:20:55.681 INFO  [Executor task launch worker for task 251] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=45),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/45] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/45/2.delta
09:20:55.697 INFO  [Executor task launch worker for task 252] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=46),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/46] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/46/2.delta
09:20:55.697 INFO  [Executor task launch worker for task 253] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=47), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/47] for update
09:20:55.697 INFO  [Executor task launch worker for task 253] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=47), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/47] for update
09:20:55.697 INFO  [Executor task launch worker for task 253] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.697 INFO  [Executor task launch worker for task 253] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.697 INFO  [Executor task launch worker for task 252] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=46),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/46]
09:20:55.697 INFO  [Executor task launch worker for task 252] org.apache.spark.executor.Executor - Finished task 46.0 in stage 5.0 (TID 252). 3365 bytes result sent to driver
09:20:55.697 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 48.0 in stage 5.0 (TID 254, localhost, executor driver, partition 48, PROCESS_LOCAL, 4726 bytes)
09:20:55.697 INFO  [Executor task launch worker for task 254] org.apache.spark.executor.Executor - Running task 48.0 in stage 5.0 (TID 254)
09:20:55.697 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 46.0 in stage 5.0 (TID 252) in 32 ms on localhost (executor driver) (46/200)
09:20:55.697 INFO  [Executor task launch worker for task 254] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=48), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/48] for update
09:20:55.697 INFO  [Executor task launch worker for task 254] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=48), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/48] for update
09:20:55.697 INFO  [Executor task launch worker for task 254] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.697 INFO  [Executor task launch worker for task 251] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=45),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/45]
09:20:55.712 INFO  [Executor task launch worker for task 254] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 15 ms
09:20:55.716 INFO  [Executor task launch worker for task 253] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=47),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/47] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/47/2.delta
09:20:55.720 INFO  [Executor task launch worker for task 251] org.apache.spark.executor.Executor - Finished task 45.0 in stage 5.0 (TID 251). 3408 bytes result sent to driver
09:20:55.721 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 49.0 in stage 5.0 (TID 255, localhost, executor driver, partition 49, PROCESS_LOCAL, 4726 bytes)
09:20:55.721 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 45.0 in stage 5.0 (TID 251) in 56 ms on localhost (executor driver) (47/200)
09:20:55.722 INFO  [Executor task launch worker for task 255] org.apache.spark.executor.Executor - Running task 49.0 in stage 5.0 (TID 255)
09:20:55.731 INFO  [Executor task launch worker for task 255] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=49), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/49] for update
09:20:55.731 INFO  [Executor task launch worker for task 254] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=48),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/48] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/48/2.delta
09:20:55.731 INFO  [Executor task launch worker for task 255] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=49), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/49] for update
09:20:55.731 INFO  [Executor task launch worker for task 255] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.732 INFO  [Executor task launch worker for task 255] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.737 INFO  [Executor task launch worker for task 254] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=48),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/48]
09:20:55.738 INFO  [Executor task launch worker for task 254] org.apache.spark.executor.Executor - Finished task 48.0 in stage 5.0 (TID 254). 3365 bytes result sent to driver
09:20:55.739 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 50.0 in stage 5.0 (TID 256, localhost, executor driver, partition 50, PROCESS_LOCAL, 4726 bytes)
09:20:55.739 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 48.0 in stage 5.0 (TID 254) in 42 ms on localhost (executor driver) (48/200)
09:20:55.739 INFO  [Executor task launch worker for task 256] org.apache.spark.executor.Executor - Running task 50.0 in stage 5.0 (TID 256)
09:20:55.741 INFO  [Executor task launch worker for task 256] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=50), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/50] for update
09:20:55.742 INFO  [Executor task launch worker for task 256] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=50), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/50] for update
09:20:55.742 INFO  [Executor task launch worker for task 256] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.742 INFO  [Executor task launch worker for task 256] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.743 INFO  [Executor task launch worker for task 253] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=47),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/47]
09:20:55.744 INFO  [Executor task launch worker for task 253] org.apache.spark.executor.Executor - Finished task 47.0 in stage 5.0 (TID 253). 3451 bytes result sent to driver
09:20:55.745 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 51.0 in stage 5.0 (TID 257, localhost, executor driver, partition 51, PROCESS_LOCAL, 4726 bytes)
09:20:55.745 INFO  [Executor task launch worker for task 257] org.apache.spark.executor.Executor - Running task 51.0 in stage 5.0 (TID 257)
09:20:55.747 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 47.0 in stage 5.0 (TID 253) in 64 ms on localhost (executor driver) (49/200)
09:20:55.747 INFO  [Executor task launch worker for task 257] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=51), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/51] for update
09:20:55.747 INFO  [Executor task launch worker for task 257] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=51), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/51] for update
09:20:55.747 INFO  [Executor task launch worker for task 257] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.747 INFO  [Executor task launch worker for task 257] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.747 INFO  [Executor task launch worker for task 255] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=49),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/49] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/49/2.delta
09:20:55.747 INFO  [Executor task launch worker for task 256] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=50),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/50] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/50/2.delta
09:20:55.747 INFO  [Executor task launch worker for task 256] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=50),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/50]
09:20:55.747 INFO  [Executor task launch worker for task 255] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=49),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/49]
09:20:55.747 INFO  [Executor task launch worker for task 256] org.apache.spark.executor.Executor - Finished task 50.0 in stage 5.0 (TID 256). 3365 bytes result sent to driver
09:20:55.747 INFO  [Executor task launch worker for task 255] org.apache.spark.executor.Executor - Finished task 49.0 in stage 5.0 (TID 255). 3408 bytes result sent to driver
09:20:55.747 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 52.0 in stage 5.0 (TID 258, localhost, executor driver, partition 52, PROCESS_LOCAL, 4726 bytes)
09:20:55.747 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 53.0 in stage 5.0 (TID 259, localhost, executor driver, partition 53, PROCESS_LOCAL, 4726 bytes)
09:20:55.747 INFO  [Executor task launch worker for task 259] org.apache.spark.executor.Executor - Running task 53.0 in stage 5.0 (TID 259)
09:20:55.747 INFO  [Executor task launch worker for task 258] org.apache.spark.executor.Executor - Running task 52.0 in stage 5.0 (TID 258)
09:20:55.747 INFO  [Executor task launch worker for task 257] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=51),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/51] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/51/2.delta
09:20:55.747 INFO  [Executor task launch worker for task 259] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=53), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/53] for update
09:20:55.747 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 50.0 in stage 5.0 (TID 256) in 9 ms on localhost (executor driver) (50/200)
09:20:55.747 INFO  [Executor task launch worker for task 258] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=52), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/52] for update
09:20:55.763 INFO  [Executor task launch worker for task 259] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=53), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/53] for update
09:20:55.763 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 49.0 in stage 5.0 (TID 255) in 42 ms on localhost (executor driver) (51/200)
09:20:55.763 INFO  [Executor task launch worker for task 259] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.763 INFO  [Executor task launch worker for task 258] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=52), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/52] for update
09:20:55.763 INFO  [Executor task launch worker for task 259] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.763 INFO  [Executor task launch worker for task 258] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.763 INFO  [Executor task launch worker for task 258] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.903 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner - Cleaned accumulator 13
09:20:55.903 INFO  [dispatcher-event-loop-6] org.apache.spark.storage.BlockManagerInfo - Removed broadcast_8_piece0 on 172.16.2.246:51465 in memory (size: 10.7 KB, free: 1954.4 MB)
09:20:55.903 INFO  [Executor task launch worker for task 257] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=51),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/51]
09:20:55.903 INFO  [Executor task launch worker for task 257] org.apache.spark.executor.Executor - Finished task 51.0 in stage 5.0 (TID 257). 3408 bytes result sent to driver
09:20:55.903 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 54.0 in stage 5.0 (TID 260, localhost, executor driver, partition 54, PROCESS_LOCAL, 4726 bytes)
09:20:55.903 INFO  [Executor task launch worker for task 260] org.apache.spark.executor.Executor - Running task 54.0 in stage 5.0 (TID 260)
09:20:55.903 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner - Cleaned accumulator 19
09:20:55.903 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner - Cleaned accumulator 25
09:20:55.903 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner - Cleaned accumulator 23
09:20:55.903 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner - Cleaned accumulator 26
09:20:55.903 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner - Cleaned accumulator 8
09:20:55.903 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 51.0 in stage 5.0 (TID 257) in 158 ms on localhost (executor driver) (52/200)
09:20:55.903 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner - Cleaned accumulator 18
09:20:55.903 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner - Cleaned accumulator 7
09:20:55.903 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner - Cleaned accumulator 1
09:20:55.919 INFO  [dispatcher-event-loop-5] org.apache.spark.storage.BlockManagerInfo - Removed broadcast_3_piece0 on 172.16.2.246:51465 in memory (size: 16.7 KB, free: 1954.4 MB)
09:20:55.919 INFO  [Executor task launch worker for task 260] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=54), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/54] for update
09:20:55.919 INFO  [Executor task launch worker for task 260] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=54), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/54] for update
09:20:55.919 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner - Cleaned accumulator 20
09:20:55.919 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner - Cleaned accumulator 9
09:20:55.919 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner - Cleaned accumulator 10
09:20:55.919 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner - Cleaned accumulator 12
09:20:55.919 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner - Cleaned accumulator 11
09:20:55.919 INFO  [Executor task launch worker for task 259] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=53),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/53] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/53/2.delta
09:20:55.919 INFO  [Executor task launch worker for task 260] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.919 INFO  [Executor task launch worker for task 260] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.919 INFO  [Executor task launch worker for task 259] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=53),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/53]
09:20:55.919 INFO  [Executor task launch worker for task 259] org.apache.spark.executor.Executor - Finished task 53.0 in stage 5.0 (TID 259). 3365 bytes result sent to driver
09:20:55.919 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 55.0 in stage 5.0 (TID 261, localhost, executor driver, partition 55, PROCESS_LOCAL, 4726 bytes)
09:20:55.919 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 53.0 in stage 5.0 (TID 259) in 172 ms on localhost (executor driver) (53/200)
09:20:55.919 INFO  [Executor task launch worker for task 261] org.apache.spark.executor.Executor - Running task 55.0 in stage 5.0 (TID 261)
09:20:55.919 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner - Cleaned shuffle 0
09:20:55.919 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner - Cleaned accumulator 6
09:20:55.919 INFO  [dispatcher-event-loop-0] org.apache.spark.storage.BlockManagerInfo - Removed broadcast_1_piece0 on 172.16.2.246:51465 in memory (size: 21.2 KB, free: 1954.4 MB)
09:20:55.919 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner - Cleaned accumulator 5
09:20:55.919 INFO  [Executor task launch worker for task 261] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=55), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/55] for update
09:20:55.919 INFO  [Executor task launch worker for task 258] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=52),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/52] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/52/2.delta
09:20:55.919 INFO  [Executor task launch worker for task 260] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=54),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/54] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/54/2.delta
09:20:55.935 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner - Cleaned accumulator 4
09:20:55.935 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner - Cleaned accumulator 15
09:20:55.935 INFO  [Executor task launch worker for task 261] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=55), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/55] for update
09:20:55.935 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner - Cleaned accumulator 21
09:20:55.935 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner - Cleaned accumulator 3
09:20:55.935 INFO  [Executor task launch worker for task 261] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.935 INFO  [Executor task launch worker for task 261] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.935 INFO  [dispatcher-event-loop-3] org.apache.spark.storage.BlockManagerInfo - Removed broadcast_0_piece0 on 172.16.2.246:51465 in memory (size: 21.2 KB, free: 1954.4 MB)
09:20:55.935 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner - Cleaned accumulator 16
09:20:55.935 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner - Cleaned accumulator 17
09:20:55.935 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner - Cleaned accumulator 24
09:20:55.935 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner - Cleaned accumulator 22
09:20:55.935 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner - Cleaned accumulator 2
09:20:55.935 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner - Cleaned accumulator 14
09:20:55.935 INFO  [Executor task launch worker for task 261] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=55),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/55] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/55/2.delta
09:20:55.935 INFO  [Executor task launch worker for task 258] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=52),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/52]
09:20:55.935 INFO  [Executor task launch worker for task 260] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=54),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/54]
09:20:55.935 INFO  [Executor task launch worker for task 261] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=55),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/55]
09:20:55.950 INFO  [Executor task launch worker for task 258] org.apache.spark.executor.Executor - Finished task 52.0 in stage 5.0 (TID 258). 3365 bytes result sent to driver
09:20:55.950 INFO  [Executor task launch worker for task 261] org.apache.spark.executor.Executor - Finished task 55.0 in stage 5.0 (TID 261). 3322 bytes result sent to driver
09:20:55.950 INFO  [Executor task launch worker for task 260] org.apache.spark.executor.Executor - Finished task 54.0 in stage 5.0 (TID 260). 3408 bytes result sent to driver
09:20:55.950 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 56.0 in stage 5.0 (TID 262, localhost, executor driver, partition 56, PROCESS_LOCAL, 4726 bytes)
09:20:55.950 INFO  [Executor task launch worker for task 262] org.apache.spark.executor.Executor - Running task 56.0 in stage 5.0 (TID 262)
09:20:55.950 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 57.0 in stage 5.0 (TID 263, localhost, executor driver, partition 57, PROCESS_LOCAL, 4726 bytes)
09:20:55.950 INFO  [Executor task launch worker for task 263] org.apache.spark.executor.Executor - Running task 57.0 in stage 5.0 (TID 263)
09:20:55.950 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 58.0 in stage 5.0 (TID 264, localhost, executor driver, partition 58, PROCESS_LOCAL, 4726 bytes)
09:20:55.950 INFO  [Executor task launch worker for task 264] org.apache.spark.executor.Executor - Running task 58.0 in stage 5.0 (TID 264)
09:20:55.950 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 54.0 in stage 5.0 (TID 260) in 47 ms on localhost (executor driver) (54/200)
09:20:55.950 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 52.0 in stage 5.0 (TID 258) in 203 ms on localhost (executor driver) (55/200)
09:20:55.950 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 55.0 in stage 5.0 (TID 261) in 31 ms on localhost (executor driver) (56/200)
09:20:55.950 INFO  [Executor task launch worker for task 263] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=57), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/57] for update
09:20:55.950 INFO  [Executor task launch worker for task 264] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=58), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/58] for update
09:20:55.950 INFO  [Executor task launch worker for task 263] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=57), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/57] for update
09:20:55.950 INFO  [Executor task launch worker for task 264] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=58), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/58] for update
09:20:55.950 INFO  [Executor task launch worker for task 262] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=56), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/56] for update
09:20:55.966 INFO  [Executor task launch worker for task 264] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.966 INFO  [Executor task launch worker for task 263] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.966 INFO  [Executor task launch worker for task 262] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=56), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/56] for update
09:20:55.966 INFO  [Executor task launch worker for task 264] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.966 INFO  [Executor task launch worker for task 263] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.966 INFO  [Executor task launch worker for task 262] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.966 INFO  [Executor task launch worker for task 262] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.966 INFO  [Executor task launch worker for task 264] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=58),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/58] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/58/2.delta
09:20:55.966 INFO  [Executor task launch worker for task 264] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=58),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/58]
09:20:55.966 INFO  [Executor task launch worker for task 263] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=57),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/57] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/57/2.delta
09:20:55.982 INFO  [Executor task launch worker for task 264] org.apache.spark.executor.Executor - Finished task 58.0 in stage 5.0 (TID 264). 3322 bytes result sent to driver
09:20:55.982 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 59.0 in stage 5.0 (TID 265, localhost, executor driver, partition 59, PROCESS_LOCAL, 4726 bytes)
09:20:55.982 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 58.0 in stage 5.0 (TID 264) in 32 ms on localhost (executor driver) (57/200)
09:20:55.982 INFO  [Executor task launch worker for task 265] org.apache.spark.executor.Executor - Running task 59.0 in stage 5.0 (TID 265)
09:20:55.982 INFO  [Executor task launch worker for task 263] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=57),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/57]
09:20:55.982 INFO  [Executor task launch worker for task 263] org.apache.spark.executor.Executor - Finished task 57.0 in stage 5.0 (TID 263). 3322 bytes result sent to driver
09:20:55.982 INFO  [Executor task launch worker for task 265] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=59), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/59] for update
09:20:55.982 INFO  [Executor task launch worker for task 265] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=59), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/59] for update
09:20:55.982 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 60.0 in stage 5.0 (TID 266, localhost, executor driver, partition 60, PROCESS_LOCAL, 4726 bytes)
09:20:55.982 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 57.0 in stage 5.0 (TID 263) in 32 ms on localhost (executor driver) (58/200)
09:20:55.982 INFO  [Executor task launch worker for task 265] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.982 INFO  [Executor task launch worker for task 265] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.982 INFO  [Executor task launch worker for task 262] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=56),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/56] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/56/2.delta
09:20:55.982 INFO  [Executor task launch worker for task 266] org.apache.spark.executor.Executor - Running task 60.0 in stage 5.0 (TID 266)
09:20:55.982 INFO  [Executor task launch worker for task 266] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=60), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/60] for update
09:20:55.982 INFO  [Executor task launch worker for task 266] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=60), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/60] for update
09:20:55.997 INFO  [Executor task launch worker for task 266] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.997 INFO  [Executor task launch worker for task 266] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.997 INFO  [Executor task launch worker for task 262] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=56),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/56]
09:20:55.997 INFO  [Executor task launch worker for task 262] org.apache.spark.executor.Executor - Finished task 56.0 in stage 5.0 (TID 262). 3365 bytes result sent to driver
09:20:55.997 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 61.0 in stage 5.0 (TID 267, localhost, executor driver, partition 61, PROCESS_LOCAL, 4726 bytes)
09:20:55.997 INFO  [Executor task launch worker for task 265] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=59),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/59] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/59/2.delta
09:20:55.997 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 56.0 in stage 5.0 (TID 262) in 47 ms on localhost (executor driver) (59/200)
09:20:55.997 INFO  [Executor task launch worker for task 267] org.apache.spark.executor.Executor - Running task 61.0 in stage 5.0 (TID 267)
09:20:55.997 INFO  [Executor task launch worker for task 266] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=60),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/60] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/60/2.delta
09:20:55.997 INFO  [Executor task launch worker for task 267] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=61), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/61] for update
09:20:55.997 INFO  [Executor task launch worker for task 267] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=61), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/61] for update
09:20:55.997 INFO  [Executor task launch worker for task 267] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:55.997 INFO  [Executor task launch worker for task 267] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:55.997 INFO  [Executor task launch worker for task 265] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=59),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/59]
09:20:55.997 INFO  [Executor task launch worker for task 265] org.apache.spark.executor.Executor - Finished task 59.0 in stage 5.0 (TID 265). 3365 bytes result sent to driver
09:20:55.997 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 62.0 in stage 5.0 (TID 268, localhost, executor driver, partition 62, PROCESS_LOCAL, 4726 bytes)
09:20:55.997 INFO  [Executor task launch worker for task 266] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=60),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/60]
09:20:55.997 INFO  [Executor task launch worker for task 267] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=61),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/61] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/61/2.delta
09:20:56.013 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 59.0 in stage 5.0 (TID 265) in 31 ms on localhost (executor driver) (60/200)
09:20:56.013 INFO  [Executor task launch worker for task 268] org.apache.spark.executor.Executor - Running task 62.0 in stage 5.0 (TID 268)
09:20:56.013 INFO  [Executor task launch worker for task 266] org.apache.spark.executor.Executor - Finished task 60.0 in stage 5.0 (TID 266). 3322 bytes result sent to driver
09:20:56.013 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 63.0 in stage 5.0 (TID 269, localhost, executor driver, partition 63, PROCESS_LOCAL, 4726 bytes)
09:20:56.013 INFO  [Executor task launch worker for task 269] org.apache.spark.executor.Executor - Running task 63.0 in stage 5.0 (TID 269)
09:20:56.013 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 60.0 in stage 5.0 (TID 266) in 31 ms on localhost (executor driver) (61/200)
09:20:56.013 INFO  [Executor task launch worker for task 268] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=62), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/62] for update
09:20:56.013 INFO  [Executor task launch worker for task 268] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=62), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/62] for update
09:20:56.013 INFO  [Executor task launch worker for task 268] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.013 INFO  [Executor task launch worker for task 268] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.013 INFO  [Executor task launch worker for task 269] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=63), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/63] for update
09:20:56.013 INFO  [Executor task launch worker for task 269] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=63), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/63] for update
09:20:56.013 INFO  [Executor task launch worker for task 269] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.013 INFO  [Executor task launch worker for task 269] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.013 INFO  [Executor task launch worker for task 267] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=61),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/61]
09:20:56.013 INFO  [Executor task launch worker for task 267] org.apache.spark.executor.Executor - Finished task 61.0 in stage 5.0 (TID 267). 3322 bytes result sent to driver
09:20:56.013 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 64.0 in stage 5.0 (TID 270, localhost, executor driver, partition 64, PROCESS_LOCAL, 4726 bytes)
09:20:56.013 INFO  [Executor task launch worker for task 270] org.apache.spark.executor.Executor - Running task 64.0 in stage 5.0 (TID 270)
09:20:56.013 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 61.0 in stage 5.0 (TID 267) in 16 ms on localhost (executor driver) (62/200)
09:20:56.013 INFO  [Executor task launch worker for task 268] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=62),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/62] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/62/2.delta
09:20:56.013 INFO  [Executor task launch worker for task 269] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=63),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/63] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/63/2.delta
09:20:56.028 INFO  [Executor task launch worker for task 270] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=64), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/64] for update
09:20:56.028 INFO  [Executor task launch worker for task 270] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=64), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/64] for update
09:20:56.028 INFO  [Executor task launch worker for task 270] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.028 INFO  [Executor task launch worker for task 270] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.028 INFO  [Executor task launch worker for task 269] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=63),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/63]
09:20:56.028 INFO  [Executor task launch worker for task 269] org.apache.spark.executor.Executor - Finished task 63.0 in stage 5.0 (TID 269). 3322 bytes result sent to driver
09:20:56.028 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 65.0 in stage 5.0 (TID 271, localhost, executor driver, partition 65, PROCESS_LOCAL, 4726 bytes)
09:20:56.028 INFO  [Executor task launch worker for task 271] org.apache.spark.executor.Executor - Running task 65.0 in stage 5.0 (TID 271)
09:20:56.028 INFO  [Executor task launch worker for task 268] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=62),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/62]
09:20:56.028 INFO  [Executor task launch worker for task 268] org.apache.spark.executor.Executor - Finished task 62.0 in stage 5.0 (TID 268). 3322 bytes result sent to driver
09:20:56.028 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 66.0 in stage 5.0 (TID 272, localhost, executor driver, partition 66, PROCESS_LOCAL, 4726 bytes)
09:20:56.028 INFO  [Executor task launch worker for task 271] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=65), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/65] for update
09:20:56.028 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 63.0 in stage 5.0 (TID 269) in 15 ms on localhost (executor driver) (63/200)
09:20:56.028 INFO  [Executor task launch worker for task 272] org.apache.spark.executor.Executor - Running task 66.0 in stage 5.0 (TID 272)
09:20:56.028 INFO  [Executor task launch worker for task 270] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=64),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/64] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/64/2.delta
09:20:56.044 INFO  [Executor task launch worker for task 271] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=65), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/65] for update
09:20:56.044 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 62.0 in stage 5.0 (TID 268) in 47 ms on localhost (executor driver) (64/200)
09:20:56.044 INFO  [Executor task launch worker for task 271] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.044 INFO  [Executor task launch worker for task 271] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.044 INFO  [Executor task launch worker for task 272] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=66), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/66] for update
09:20:56.044 INFO  [Executor task launch worker for task 272] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=66), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/66] for update
09:20:56.044 INFO  [Executor task launch worker for task 272] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.044 INFO  [Executor task launch worker for task 272] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.044 INFO  [Executor task launch worker for task 270] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=64),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/64]
09:20:56.044 INFO  [Executor task launch worker for task 270] org.apache.spark.executor.Executor - Finished task 64.0 in stage 5.0 (TID 270). 3365 bytes result sent to driver
09:20:56.044 INFO  [Executor task launch worker for task 271] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=65),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/65] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/65/2.delta
09:20:56.044 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 67.0 in stage 5.0 (TID 273, localhost, executor driver, partition 67, PROCESS_LOCAL, 4726 bytes)
09:20:56.044 INFO  [Executor task launch worker for task 273] org.apache.spark.executor.Executor - Running task 67.0 in stage 5.0 (TID 273)
09:20:56.044 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 64.0 in stage 5.0 (TID 270) in 31 ms on localhost (executor driver) (65/200)
09:20:56.044 INFO  [Executor task launch worker for task 272] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=66),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/66] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/66/2.delta
09:20:56.044 INFO  [Executor task launch worker for task 271] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=65),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/65]
09:20:56.060 INFO  [Executor task launch worker for task 271] org.apache.spark.executor.Executor - Finished task 65.0 in stage 5.0 (TID 271). 3322 bytes result sent to driver
09:20:56.060 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 68.0 in stage 5.0 (TID 274, localhost, executor driver, partition 68, PROCESS_LOCAL, 4726 bytes)
09:20:56.060 INFO  [Executor task launch worker for task 274] org.apache.spark.executor.Executor - Running task 68.0 in stage 5.0 (TID 274)
09:20:56.060 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 65.0 in stage 5.0 (TID 271) in 32 ms on localhost (executor driver) (66/200)
09:20:56.060 INFO  [Executor task launch worker for task 273] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=67), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/67] for update
09:20:56.060 INFO  [Executor task launch worker for task 273] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=67), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/67] for update
09:20:56.060 INFO  [Executor task launch worker for task 273] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.060 INFO  [Executor task launch worker for task 273] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.060 INFO  [Executor task launch worker for task 274] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=68), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/68] for update
09:20:56.060 INFO  [Executor task launch worker for task 274] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=68), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/68] for update
09:20:56.060 INFO  [Executor task launch worker for task 274] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.060 INFO  [Executor task launch worker for task 274] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.060 INFO  [Executor task launch worker for task 272] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=66),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/66]
09:20:56.060 INFO  [Executor task launch worker for task 272] org.apache.spark.executor.Executor - Finished task 66.0 in stage 5.0 (TID 272). 3365 bytes result sent to driver
09:20:56.060 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 69.0 in stage 5.0 (TID 275, localhost, executor driver, partition 69, PROCESS_LOCAL, 4726 bytes)
09:20:56.060 INFO  [Executor task launch worker for task 275] org.apache.spark.executor.Executor - Running task 69.0 in stage 5.0 (TID 275)
09:20:56.060 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 66.0 in stage 5.0 (TID 272) in 32 ms on localhost (executor driver) (67/200)
09:20:56.075 INFO  [Executor task launch worker for task 275] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=69), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/69] for update
09:20:56.075 INFO  [Executor task launch worker for task 275] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=69), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/69] for update
09:20:56.075 INFO  [Executor task launch worker for task 275] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.075 INFO  [Executor task launch worker for task 275] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.075 INFO  [Executor task launch worker for task 274] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=68),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/68] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/68/2.delta
09:20:56.075 INFO  [Executor task launch worker for task 273] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=67),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/67] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/67/2.delta
09:20:56.075 INFO  [Executor task launch worker for task 274] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=68),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/68]
09:20:56.075 INFO  [Executor task launch worker for task 273] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=67),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/67]
09:20:56.075 INFO  [Executor task launch worker for task 274] org.apache.spark.executor.Executor - Finished task 68.0 in stage 5.0 (TID 274). 3365 bytes result sent to driver
09:20:56.075 INFO  [Executor task launch worker for task 273] org.apache.spark.executor.Executor - Finished task 67.0 in stage 5.0 (TID 273). 3408 bytes result sent to driver
09:20:56.075 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 70.0 in stage 5.0 (TID 276, localhost, executor driver, partition 70, PROCESS_LOCAL, 4726 bytes)
09:20:56.075 INFO  [Executor task launch worker for task 276] org.apache.spark.executor.Executor - Running task 70.0 in stage 5.0 (TID 276)
09:20:56.075 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 71.0 in stage 5.0 (TID 277, localhost, executor driver, partition 71, PROCESS_LOCAL, 4726 bytes)
09:20:56.075 INFO  [Executor task launch worker for task 277] org.apache.spark.executor.Executor - Running task 71.0 in stage 5.0 (TID 277)
09:20:56.091 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 68.0 in stage 5.0 (TID 274) in 31 ms on localhost (executor driver) (68/200)
09:20:56.091 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 67.0 in stage 5.0 (TID 273) in 47 ms on localhost (executor driver) (69/200)
09:20:56.091 INFO  [Executor task launch worker for task 276] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=70), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/70] for update
09:20:56.091 INFO  [Executor task launch worker for task 276] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=70), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/70] for update
09:20:56.091 INFO  [Executor task launch worker for task 275] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=69),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/69] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/69/2.delta
09:20:56.091 INFO  [Executor task launch worker for task 276] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.091 INFO  [Executor task launch worker for task 276] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.091 INFO  [Executor task launch worker for task 277] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=71), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/71] for update
09:20:56.091 INFO  [Executor task launch worker for task 277] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=71), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/71] for update
09:20:56.091 INFO  [Executor task launch worker for task 277] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.091 INFO  [Executor task launch worker for task 277] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.091 INFO  [Executor task launch worker for task 275] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=69),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/69]
09:20:56.091 INFO  [Executor task launch worker for task 275] org.apache.spark.executor.Executor - Finished task 69.0 in stage 5.0 (TID 275). 3451 bytes result sent to driver
09:20:56.091 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 72.0 in stage 5.0 (TID 278, localhost, executor driver, partition 72, PROCESS_LOCAL, 4726 bytes)
09:20:56.091 INFO  [Executor task launch worker for task 278] org.apache.spark.executor.Executor - Running task 72.0 in stage 5.0 (TID 278)
09:20:56.091 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 69.0 in stage 5.0 (TID 275) in 31 ms on localhost (executor driver) (70/200)
09:20:56.091 INFO  [Executor task launch worker for task 276] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=70),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/70] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/70/2.delta
09:20:56.091 INFO  [Executor task launch worker for task 277] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=71),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/71] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/71/2.delta
09:20:56.091 INFO  [Executor task launch worker for task 278] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=72), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/72] for update
09:20:56.106 INFO  [Executor task launch worker for task 278] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=72), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/72] for update
09:20:56.106 INFO  [Executor task launch worker for task 278] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.106 INFO  [Executor task launch worker for task 278] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.106 INFO  [Executor task launch worker for task 277] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=71),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/71]
09:20:56.106 INFO  [Executor task launch worker for task 276] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=70),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/70]
09:20:56.106 INFO  [Executor task launch worker for task 277] org.apache.spark.executor.Executor - Finished task 71.0 in stage 5.0 (TID 277). 3365 bytes result sent to driver
09:20:56.106 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 73.0 in stage 5.0 (TID 279, localhost, executor driver, partition 73, PROCESS_LOCAL, 4726 bytes)
09:20:56.106 INFO  [Executor task launch worker for task 276] org.apache.spark.executor.Executor - Finished task 70.0 in stage 5.0 (TID 276). 3408 bytes result sent to driver
09:20:56.106 INFO  [Executor task launch worker for task 279] org.apache.spark.executor.Executor - Running task 73.0 in stage 5.0 (TID 279)
09:20:56.106 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 71.0 in stage 5.0 (TID 277) in 31 ms on localhost (executor driver) (71/200)
09:20:56.106 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 74.0 in stage 5.0 (TID 280, localhost, executor driver, partition 74, PROCESS_LOCAL, 4726 bytes)
09:20:56.106 INFO  [Executor task launch worker for task 280] org.apache.spark.executor.Executor - Running task 74.0 in stage 5.0 (TID 280)
09:20:56.106 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 70.0 in stage 5.0 (TID 276) in 31 ms on localhost (executor driver) (72/200)
09:20:56.106 INFO  [Executor task launch worker for task 278] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=72),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/72] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/72/2.delta
09:20:56.106 INFO  [Executor task launch worker for task 280] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=74), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/74] for update
09:20:56.106 INFO  [Executor task launch worker for task 280] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=74), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/74] for update
09:20:56.106 INFO  [Executor task launch worker for task 279] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=73), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/73] for update
09:20:56.106 INFO  [Executor task launch worker for task 278] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=72),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/72]
09:20:56.122 INFO  [Executor task launch worker for task 280] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.122 INFO  [Executor task launch worker for task 279] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=73), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/73] for update
09:20:56.122 INFO  [Executor task launch worker for task 280] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.122 INFO  [Executor task launch worker for task 279] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.122 INFO  [Executor task launch worker for task 279] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.122 INFO  [Executor task launch worker for task 278] org.apache.spark.executor.Executor - Finished task 72.0 in stage 5.0 (TID 278). 3322 bytes result sent to driver
09:20:56.122 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 75.0 in stage 5.0 (TID 281, localhost, executor driver, partition 75, PROCESS_LOCAL, 4726 bytes)
09:20:56.122 INFO  [Executor task launch worker for task 281] org.apache.spark.executor.Executor - Running task 75.0 in stage 5.0 (TID 281)
09:20:56.122 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 72.0 in stage 5.0 (TID 278) in 31 ms on localhost (executor driver) (73/200)
09:20:56.122 INFO  [Executor task launch worker for task 281] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=75), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/75] for update
09:20:56.122 INFO  [Executor task launch worker for task 281] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=75), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/75] for update
09:20:56.122 INFO  [Executor task launch worker for task 281] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.122 INFO  [Executor task launch worker for task 281] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.138 INFO  [Executor task launch worker for task 280] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=74),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/74] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/74/2.delta
09:20:56.138 INFO  [Executor task launch worker for task 279] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=73),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/73] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/73/2.delta
09:20:56.138 INFO  [Executor task launch worker for task 281] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=75),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/75] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/75/2.delta
09:20:56.138 INFO  [Executor task launch worker for task 280] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=74),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/74]
09:20:56.138 INFO  [Executor task launch worker for task 279] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=73),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/73]
09:20:56.138 INFO  [Executor task launch worker for task 279] org.apache.spark.executor.Executor - Finished task 73.0 in stage 5.0 (TID 279). 3365 bytes result sent to driver
09:20:56.138 INFO  [Executor task launch worker for task 280] org.apache.spark.executor.Executor - Finished task 74.0 in stage 5.0 (TID 280). 3365 bytes result sent to driver
09:20:56.138 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 76.0 in stage 5.0 (TID 282, localhost, executor driver, partition 76, PROCESS_LOCAL, 4726 bytes)
09:20:56.138 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 77.0 in stage 5.0 (TID 283, localhost, executor driver, partition 77, PROCESS_LOCAL, 4726 bytes)
09:20:56.138 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 73.0 in stage 5.0 (TID 279) in 32 ms on localhost (executor driver) (74/200)
09:20:56.138 INFO  [Executor task launch worker for task 283] org.apache.spark.executor.Executor - Running task 77.0 in stage 5.0 (TID 283)
09:20:56.138 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 74.0 in stage 5.0 (TID 280) in 32 ms on localhost (executor driver) (75/200)
09:20:56.138 INFO  [Executor task launch worker for task 282] org.apache.spark.executor.Executor - Running task 76.0 in stage 5.0 (TID 282)
09:20:56.153 INFO  [Executor task launch worker for task 282] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=76), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/76] for update
09:20:56.153 INFO  [Executor task launch worker for task 282] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=76), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/76] for update
09:20:56.153 INFO  [Executor task launch worker for task 283] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=77), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/77] for update
09:20:56.153 INFO  [Executor task launch worker for task 283] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=77), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/77] for update
09:20:56.153 INFO  [Executor task launch worker for task 282] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.153 INFO  [Executor task launch worker for task 282] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.153 INFO  [Executor task launch worker for task 283] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.153 INFO  [Executor task launch worker for task 283] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.153 INFO  [Executor task launch worker for task 281] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=75),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/75]
09:20:56.153 INFO  [Executor task launch worker for task 281] org.apache.spark.executor.Executor - Finished task 75.0 in stage 5.0 (TID 281). 3365 bytes result sent to driver
09:20:56.153 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 78.0 in stage 5.0 (TID 284, localhost, executor driver, partition 78, PROCESS_LOCAL, 4726 bytes)
09:20:56.153 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 75.0 in stage 5.0 (TID 281) in 31 ms on localhost (executor driver) (76/200)
09:20:56.153 INFO  [Executor task launch worker for task 284] org.apache.spark.executor.Executor - Running task 78.0 in stage 5.0 (TID 284)
09:20:56.153 INFO  [Executor task launch worker for task 283] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=77),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/77] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/77/2.delta
09:20:56.153 INFO  [Executor task launch worker for task 284] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=78), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/78] for update
09:20:56.153 INFO  [Executor task launch worker for task 284] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=78), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/78] for update
09:20:56.153 INFO  [Executor task launch worker for task 282] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=76),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/76] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/76/2.delta
09:20:56.153 INFO  [Executor task launch worker for task 283] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=77),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/77]
09:20:56.169 INFO  [Executor task launch worker for task 284] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.169 INFO  [Executor task launch worker for task 284] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.169 INFO  [Executor task launch worker for task 283] org.apache.spark.executor.Executor - Finished task 77.0 in stage 5.0 (TID 283). 3408 bytes result sent to driver
09:20:56.169 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 79.0 in stage 5.0 (TID 285, localhost, executor driver, partition 79, PROCESS_LOCAL, 4726 bytes)
09:20:56.169 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 77.0 in stage 5.0 (TID 283) in 31 ms on localhost (executor driver) (77/200)
09:20:56.169 INFO  [Executor task launch worker for task 285] org.apache.spark.executor.Executor - Running task 79.0 in stage 5.0 (TID 285)
09:20:56.169 INFO  [Executor task launch worker for task 285] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=79), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/79] for update
09:20:56.169 INFO  [Executor task launch worker for task 285] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=79), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/79] for update
09:20:56.169 INFO  [Executor task launch worker for task 285] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.169 INFO  [Executor task launch worker for task 285] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.169 INFO  [Executor task launch worker for task 282] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=76),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/76]
09:20:56.169 INFO  [Executor task launch worker for task 282] org.apache.spark.executor.Executor - Finished task 76.0 in stage 5.0 (TID 282). 3408 bytes result sent to driver
09:20:56.169 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 80.0 in stage 5.0 (TID 286, localhost, executor driver, partition 80, PROCESS_LOCAL, 4726 bytes)
09:20:56.169 INFO  [Executor task launch worker for task 286] org.apache.spark.executor.Executor - Running task 80.0 in stage 5.0 (TID 286)
09:20:56.169 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 76.0 in stage 5.0 (TID 282) in 31 ms on localhost (executor driver) (78/200)
09:20:56.169 INFO  [Executor task launch worker for task 286] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=80), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/80] for update
09:20:56.169 INFO  [Executor task launch worker for task 284] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=78),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/78] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/78/2.delta
09:20:56.169 INFO  [Executor task launch worker for task 285] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=79),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/79] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/79/2.delta
09:20:56.185 INFO  [Executor task launch worker for task 286] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=80), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/80] for update
09:20:56.185 INFO  [Executor task launch worker for task 286] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.185 INFO  [Executor task launch worker for task 286] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.185 INFO  [Executor task launch worker for task 284] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=78),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/78]
09:20:56.185 INFO  [Executor task launch worker for task 285] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=79),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/79]
09:20:56.185 INFO  [Executor task launch worker for task 284] org.apache.spark.executor.Executor - Finished task 78.0 in stage 5.0 (TID 284). 3322 bytes result sent to driver
09:20:56.185 INFO  [Executor task launch worker for task 285] org.apache.spark.executor.Executor - Finished task 79.0 in stage 5.0 (TID 285). 3322 bytes result sent to driver
09:20:56.185 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 81.0 in stage 5.0 (TID 287, localhost, executor driver, partition 81, PROCESS_LOCAL, 4726 bytes)
09:20:56.185 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 78.0 in stage 5.0 (TID 284) in 32 ms on localhost (executor driver) (79/200)
09:20:56.185 INFO  [Executor task launch worker for task 287] org.apache.spark.executor.Executor - Running task 81.0 in stage 5.0 (TID 287)
09:20:56.185 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 82.0 in stage 5.0 (TID 288, localhost, executor driver, partition 82, PROCESS_LOCAL, 4726 bytes)
09:20:56.185 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 79.0 in stage 5.0 (TID 285) in 16 ms on localhost (executor driver) (80/200)
09:20:56.185 INFO  [Executor task launch worker for task 288] org.apache.spark.executor.Executor - Running task 82.0 in stage 5.0 (TID 288)
09:20:56.185 INFO  [Executor task launch worker for task 286] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=80),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/80] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/80/2.delta
09:20:56.185 INFO  [Executor task launch worker for task 287] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=81), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/81] for update
09:20:56.185 INFO  [Executor task launch worker for task 288] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=82), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/82] for update
09:20:56.185 INFO  [Executor task launch worker for task 286] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=80),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/80]
09:20:56.200 INFO  [Executor task launch worker for task 287] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=81), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/81] for update
09:20:56.200 INFO  [Executor task launch worker for task 288] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=82), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/82] for update
09:20:56.200 INFO  [Executor task launch worker for task 288] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.200 INFO  [Executor task launch worker for task 287] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.200 INFO  [Executor task launch worker for task 286] org.apache.spark.executor.Executor - Finished task 80.0 in stage 5.0 (TID 286). 3322 bytes result sent to driver
09:20:56.200 INFO  [Executor task launch worker for task 288] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.200 INFO  [Executor task launch worker for task 287] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.200 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 83.0 in stage 5.0 (TID 289, localhost, executor driver, partition 83, PROCESS_LOCAL, 4726 bytes)
09:20:56.200 INFO  [Executor task launch worker for task 289] org.apache.spark.executor.Executor - Running task 83.0 in stage 5.0 (TID 289)
09:20:56.200 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 80.0 in stage 5.0 (TID 286) in 31 ms on localhost (executor driver) (81/200)
09:20:56.200 INFO  [Executor task launch worker for task 289] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=83), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/83] for update
09:20:56.200 INFO  [Executor task launch worker for task 289] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=83), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/83] for update
09:20:56.200 INFO  [Executor task launch worker for task 289] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.200 INFO  [Executor task launch worker for task 289] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.200 INFO  [Executor task launch worker for task 287] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=81),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/81] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/81/2.delta
09:20:56.200 INFO  [Executor task launch worker for task 288] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=82),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/82] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/82/2.delta
09:20:56.200 INFO  [Executor task launch worker for task 289] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=83),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/83] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/83/2.delta
09:20:56.200 INFO  [Executor task launch worker for task 287] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=81),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/81]
09:20:56.216 INFO  [Executor task launch worker for task 287] org.apache.spark.executor.Executor - Finished task 81.0 in stage 5.0 (TID 287). 3322 bytes result sent to driver
09:20:56.216 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 84.0 in stage 5.0 (TID 290, localhost, executor driver, partition 84, PROCESS_LOCAL, 4726 bytes)
09:20:56.216 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 81.0 in stage 5.0 (TID 287) in 31 ms on localhost (executor driver) (82/200)
09:20:56.216 INFO  [Executor task launch worker for task 290] org.apache.spark.executor.Executor - Running task 84.0 in stage 5.0 (TID 290)
09:20:56.216 INFO  [Executor task launch worker for task 290] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=84), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/84] for update
09:20:56.216 INFO  [Executor task launch worker for task 290] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=84), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/84] for update
09:20:56.216 INFO  [Executor task launch worker for task 290] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.216 INFO  [Executor task launch worker for task 290] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.216 INFO  [Executor task launch worker for task 288] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=82),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/82]
09:20:56.216 INFO  [Executor task launch worker for task 289] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=83),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/83]
09:20:56.216 INFO  [Executor task launch worker for task 288] org.apache.spark.executor.Executor - Finished task 82.0 in stage 5.0 (TID 288). 3322 bytes result sent to driver
09:20:56.216 INFO  [Executor task launch worker for task 289] org.apache.spark.executor.Executor - Finished task 83.0 in stage 5.0 (TID 289). 3322 bytes result sent to driver
09:20:56.216 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 85.0 in stage 5.0 (TID 291, localhost, executor driver, partition 85, PROCESS_LOCAL, 4726 bytes)
09:20:56.216 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 82.0 in stage 5.0 (TID 288) in 31 ms on localhost (executor driver) (83/200)
09:20:56.216 INFO  [Executor task launch worker for task 291] org.apache.spark.executor.Executor - Running task 85.0 in stage 5.0 (TID 291)
09:20:56.216 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 86.0 in stage 5.0 (TID 292, localhost, executor driver, partition 86, PROCESS_LOCAL, 4726 bytes)
09:20:56.216 INFO  [Executor task launch worker for task 292] org.apache.spark.executor.Executor - Running task 86.0 in stage 5.0 (TID 292)
09:20:56.216 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 83.0 in stage 5.0 (TID 289) in 16 ms on localhost (executor driver) (84/200)
09:20:56.216 INFO  [Executor task launch worker for task 292] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=86), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/86] for update
09:20:56.216 INFO  [Executor task launch worker for task 291] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=85), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/85] for update
09:20:56.216 INFO  [Executor task launch worker for task 290] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=84),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/84] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/84/2.delta
09:20:56.231 INFO  [Executor task launch worker for task 292] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=86), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/86] for update
09:20:56.231 INFO  [Executor task launch worker for task 291] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=85), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/85] for update
09:20:56.231 INFO  [Executor task launch worker for task 292] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.231 INFO  [Executor task launch worker for task 291] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.231 INFO  [Executor task launch worker for task 292] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.231 INFO  [Executor task launch worker for task 291] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.231 INFO  [Executor task launch worker for task 290] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=84),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/84]
09:20:56.231 INFO  [Executor task launch worker for task 290] org.apache.spark.executor.Executor - Finished task 84.0 in stage 5.0 (TID 290). 3322 bytes result sent to driver
09:20:56.231 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 87.0 in stage 5.0 (TID 293, localhost, executor driver, partition 87, PROCESS_LOCAL, 4726 bytes)
09:20:56.231 INFO  [Executor task launch worker for task 293] org.apache.spark.executor.Executor - Running task 87.0 in stage 5.0 (TID 293)
09:20:56.231 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 84.0 in stage 5.0 (TID 290) in 15 ms on localhost (executor driver) (85/200)
09:20:56.247 INFO  [Executor task launch worker for task 292] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=86),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/86] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/86/2.delta
09:20:56.247 INFO  [Executor task launch worker for task 291] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=85),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/85] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/85/2.delta
09:20:56.247 INFO  [Executor task launch worker for task 293] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=87), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/87] for update
09:20:56.247 INFO  [Executor task launch worker for task 293] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=87), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/87] for update
09:20:56.247 INFO  [Executor task launch worker for task 293] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.247 INFO  [Executor task launch worker for task 293] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.247 INFO  [Executor task launch worker for task 292] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=86),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/86]
09:20:56.247 INFO  [Executor task launch worker for task 292] org.apache.spark.executor.Executor - Finished task 86.0 in stage 5.0 (TID 292). 3365 bytes result sent to driver
09:20:56.247 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 88.0 in stage 5.0 (TID 294, localhost, executor driver, partition 88, PROCESS_LOCAL, 4726 bytes)
09:20:56.247 INFO  [Executor task launch worker for task 294] org.apache.spark.executor.Executor - Running task 88.0 in stage 5.0 (TID 294)
09:20:56.247 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 86.0 in stage 5.0 (TID 292) in 31 ms on localhost (executor driver) (86/200)
09:20:56.247 INFO  [Executor task launch worker for task 291] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=85),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/85]
09:20:56.247 INFO  [Executor task launch worker for task 291] org.apache.spark.executor.Executor - Finished task 85.0 in stage 5.0 (TID 291). 3365 bytes result sent to driver
09:20:56.247 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 89.0 in stage 5.0 (TID 295, localhost, executor driver, partition 89, PROCESS_LOCAL, 4726 bytes)
09:20:56.247 INFO  [Executor task launch worker for task 295] org.apache.spark.executor.Executor - Running task 89.0 in stage 5.0 (TID 295)
09:20:56.247 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 85.0 in stage 5.0 (TID 291) in 31 ms on localhost (executor driver) (87/200)
09:20:56.247 INFO  [Executor task launch worker for task 293] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=87),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/87] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/87/2.delta
09:20:56.247 INFO  [Executor task launch worker for task 294] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=88), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/88] for update
09:20:56.247 INFO  [Executor task launch worker for task 295] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=89), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/89] for update
09:20:56.263 INFO  [Executor task launch worker for task 294] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=88), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/88] for update
09:20:56.263 INFO  [Executor task launch worker for task 295] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=89), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/89] for update
09:20:56.263 INFO  [Executor task launch worker for task 295] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.263 INFO  [Executor task launch worker for task 294] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.263 INFO  [Executor task launch worker for task 295] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.263 INFO  [Executor task launch worker for task 294] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.263 INFO  [Executor task launch worker for task 293] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=87),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/87]
09:20:56.263 INFO  [Executor task launch worker for task 293] org.apache.spark.executor.Executor - Finished task 87.0 in stage 5.0 (TID 293). 3408 bytes result sent to driver
09:20:56.263 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 90.0 in stage 5.0 (TID 296, localhost, executor driver, partition 90, PROCESS_LOCAL, 4726 bytes)
09:20:56.263 INFO  [Executor task launch worker for task 296] org.apache.spark.executor.Executor - Running task 90.0 in stage 5.0 (TID 296)
09:20:56.263 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 87.0 in stage 5.0 (TID 293) in 32 ms on localhost (executor driver) (88/200)
09:20:56.263 INFO  [Executor task launch worker for task 295] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=89),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/89] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/89/2.delta
09:20:56.263 INFO  [Executor task launch worker for task 296] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=90), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/90] for update
09:20:56.263 INFO  [Executor task launch worker for task 296] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=90), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/90] for update
09:20:56.263 INFO  [Executor task launch worker for task 294] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=88),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/88] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/88/2.delta
09:20:56.263 INFO  [Executor task launch worker for task 295] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=89),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/89]
09:20:56.278 INFO  [Executor task launch worker for task 296] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.278 INFO  [Executor task launch worker for task 296] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.278 INFO  [Executor task launch worker for task 295] org.apache.spark.executor.Executor - Finished task 89.0 in stage 5.0 (TID 295). 3322 bytes result sent to driver
09:20:56.278 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 91.0 in stage 5.0 (TID 297, localhost, executor driver, partition 91, PROCESS_LOCAL, 4726 bytes)
09:20:56.278 INFO  [Executor task launch worker for task 297] org.apache.spark.executor.Executor - Running task 91.0 in stage 5.0 (TID 297)
09:20:56.278 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 89.0 in stage 5.0 (TID 295) in 31 ms on localhost (executor driver) (89/200)
09:20:56.278 INFO  [Executor task launch worker for task 297] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=91), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/91] for update
09:20:56.278 INFO  [Executor task launch worker for task 297] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=91), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/91] for update
09:20:56.278 INFO  [Executor task launch worker for task 297] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.278 INFO  [Executor task launch worker for task 297] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.278 INFO  [Executor task launch worker for task 294] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=88),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/88]
09:20:56.278 INFO  [Executor task launch worker for task 294] org.apache.spark.executor.Executor - Finished task 88.0 in stage 5.0 (TID 294). 3322 bytes result sent to driver
09:20:56.278 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 92.0 in stage 5.0 (TID 298, localhost, executor driver, partition 92, PROCESS_LOCAL, 4726 bytes)
09:20:56.278 INFO  [Executor task launch worker for task 298] org.apache.spark.executor.Executor - Running task 92.0 in stage 5.0 (TID 298)
09:20:56.278 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 88.0 in stage 5.0 (TID 294) in 31 ms on localhost (executor driver) (90/200)
09:20:56.278 INFO  [Executor task launch worker for task 296] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=90),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/90] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/90/2.delta
09:20:56.278 INFO  [Executor task launch worker for task 298] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=92), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/92] for update
09:20:56.278 INFO  [Executor task launch worker for task 296] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=90),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/90]
09:20:56.278 INFO  [Executor task launch worker for task 297] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=91),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/91] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/91/2.delta
09:20:56.294 INFO  [Executor task launch worker for task 298] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=92), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/92] for update
09:20:56.294 INFO  [Executor task launch worker for task 296] org.apache.spark.executor.Executor - Finished task 90.0 in stage 5.0 (TID 296). 3322 bytes result sent to driver
09:20:56.294 INFO  [Executor task launch worker for task 298] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.294 INFO  [Executor task launch worker for task 298] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.294 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 93.0 in stage 5.0 (TID 299, localhost, executor driver, partition 93, PROCESS_LOCAL, 4726 bytes)
09:20:56.294 INFO  [Executor task launch worker for task 299] org.apache.spark.executor.Executor - Running task 93.0 in stage 5.0 (TID 299)
09:20:56.294 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 90.0 in stage 5.0 (TID 296) in 31 ms on localhost (executor driver) (91/200)
09:20:56.294 INFO  [Executor task launch worker for task 299] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=93), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/93] for update
09:20:56.294 INFO  [Executor task launch worker for task 299] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=93), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/93] for update
09:20:56.294 INFO  [Executor task launch worker for task 299] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.294 INFO  [Executor task launch worker for task 299] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.294 INFO  [Executor task launch worker for task 297] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=91),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/91]
09:20:56.294 INFO  [Executor task launch worker for task 297] org.apache.spark.executor.Executor - Finished task 91.0 in stage 5.0 (TID 297). 3322 bytes result sent to driver
09:20:56.294 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 94.0 in stage 5.0 (TID 300, localhost, executor driver, partition 94, PROCESS_LOCAL, 4726 bytes)
09:20:56.294 INFO  [Executor task launch worker for task 300] org.apache.spark.executor.Executor - Running task 94.0 in stage 5.0 (TID 300)
09:20:56.294 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 91.0 in stage 5.0 (TID 297) in 16 ms on localhost (executor driver) (92/200)
09:20:56.294 INFO  [Executor task launch worker for task 298] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=92),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/92] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/92/2.delta
09:20:56.294 INFO  [Executor task launch worker for task 300] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=94), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/94] for update
09:20:56.294 INFO  [Executor task launch worker for task 299] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=93),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/93] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/93/2.delta
09:20:56.310 INFO  [Executor task launch worker for task 300] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=94), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/94] for update
09:20:56.310 INFO  [Executor task launch worker for task 300] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.310 INFO  [Executor task launch worker for task 300] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.310 INFO  [Executor task launch worker for task 298] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=92),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/92]
09:20:56.310 INFO  [Executor task launch worker for task 298] org.apache.spark.executor.Executor - Finished task 92.0 in stage 5.0 (TID 298). 3322 bytes result sent to driver
09:20:56.310 INFO  [Executor task launch worker for task 299] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=93),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/93]
09:20:56.310 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 95.0 in stage 5.0 (TID 301, localhost, executor driver, partition 95, PROCESS_LOCAL, 4726 bytes)
09:20:56.310 INFO  [Executor task launch worker for task 301] org.apache.spark.executor.Executor - Running task 95.0 in stage 5.0 (TID 301)
09:20:56.310 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 92.0 in stage 5.0 (TID 298) in 32 ms on localhost (executor driver) (93/200)
09:20:56.310 INFO  [Executor task launch worker for task 299] org.apache.spark.executor.Executor - Finished task 93.0 in stage 5.0 (TID 299). 3322 bytes result sent to driver
09:20:56.325 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 96.0 in stage 5.0 (TID 302, localhost, executor driver, partition 96, PROCESS_LOCAL, 4726 bytes)
09:20:56.325 INFO  [Executor task launch worker for task 302] org.apache.spark.executor.Executor - Running task 96.0 in stage 5.0 (TID 302)
09:20:56.325 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 93.0 in stage 5.0 (TID 299) in 31 ms on localhost (executor driver) (94/200)
09:20:56.325 INFO  [Executor task launch worker for task 300] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=94),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/94] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/94/2.delta
09:20:56.325 INFO  [Executor task launch worker for task 301] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=95), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/95] for update
09:20:56.325 INFO  [Executor task launch worker for task 301] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=95), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/95] for update
09:20:56.325 INFO  [Executor task launch worker for task 301] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.325 INFO  [Executor task launch worker for task 301] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.325 INFO  [Executor task launch worker for task 302] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=96), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/96] for update
09:20:56.325 INFO  [Executor task launch worker for task 302] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=96), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/96] for update
09:20:56.325 INFO  [Executor task launch worker for task 302] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.325 INFO  [Executor task launch worker for task 302] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.341 INFO  [Executor task launch worker for task 302] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=96),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/96] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/96/2.delta
09:20:56.341 INFO  [Executor task launch worker for task 301] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=95),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/95] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/95/2.delta
09:20:56.341 INFO  [Executor task launch worker for task 300] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=94),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/94]
09:20:56.341 INFO  [Executor task launch worker for task 300] org.apache.spark.executor.Executor - Finished task 94.0 in stage 5.0 (TID 300). 3365 bytes result sent to driver
09:20:56.341 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 97.0 in stage 5.0 (TID 303, localhost, executor driver, partition 97, PROCESS_LOCAL, 4726 bytes)
09:20:56.341 INFO  [Executor task launch worker for task 303] org.apache.spark.executor.Executor - Running task 97.0 in stage 5.0 (TID 303)
09:20:56.341 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 94.0 in stage 5.0 (TID 300) in 47 ms on localhost (executor driver) (95/200)
09:20:56.341 INFO  [Executor task launch worker for task 302] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=96),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/96]
09:20:56.341 INFO  [Executor task launch worker for task 303] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=97), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/97] for update
09:20:56.341 INFO  [Executor task launch worker for task 303] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=97), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/97] for update
09:20:56.341 INFO  [Executor task launch worker for task 302] org.apache.spark.executor.Executor - Finished task 96.0 in stage 5.0 (TID 302). 3365 bytes result sent to driver
09:20:56.341 INFO  [Executor task launch worker for task 303] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.341 INFO  [Executor task launch worker for task 303] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.341 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 98.0 in stage 5.0 (TID 304, localhost, executor driver, partition 98, PROCESS_LOCAL, 4726 bytes)
09:20:56.341 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 96.0 in stage 5.0 (TID 302) in 31 ms on localhost (executor driver) (96/200)
09:20:56.341 INFO  [Executor task launch worker for task 304] org.apache.spark.executor.Executor - Running task 98.0 in stage 5.0 (TID 304)
09:20:56.356 INFO  [Executor task launch worker for task 304] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=98), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/98] for update
09:20:56.356 INFO  [Executor task launch worker for task 304] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=98), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/98] for update
09:20:56.356 INFO  [Executor task launch worker for task 304] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.356 INFO  [Executor task launch worker for task 304] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.356 INFO  [Executor task launch worker for task 303] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=97),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/97] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/97/2.delta
09:20:56.356 INFO  [Executor task launch worker for task 304] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=98),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/98] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/98/2.delta
09:20:56.356 INFO  [Executor task launch worker for task 301] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=95),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/95]
09:20:56.356 INFO  [Executor task launch worker for task 301] org.apache.spark.executor.Executor - Finished task 95.0 in stage 5.0 (TID 301). 3365 bytes result sent to driver
09:20:56.372 INFO  [Executor task launch worker for task 304] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=98),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/98]
09:20:56.372 INFO  [Executor task launch worker for task 304] org.apache.spark.executor.Executor - Finished task 98.0 in stage 5.0 (TID 304). 3408 bytes result sent to driver
09:20:56.372 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 99.0 in stage 5.0 (TID 305, localhost, executor driver, partition 99, PROCESS_LOCAL, 4726 bytes)
09:20:56.372 INFO  [Executor task launch worker for task 305] org.apache.spark.executor.Executor - Running task 99.0 in stage 5.0 (TID 305)
09:20:56.372 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 95.0 in stage 5.0 (TID 301) in 62 ms on localhost (executor driver) (97/200)
09:20:56.372 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 100.0 in stage 5.0 (TID 306, localhost, executor driver, partition 100, PROCESS_LOCAL, 4726 bytes)
09:20:56.372 INFO  [Executor task launch worker for task 306] org.apache.spark.executor.Executor - Running task 100.0 in stage 5.0 (TID 306)
09:20:56.372 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 98.0 in stage 5.0 (TID 304) in 31 ms on localhost (executor driver) (98/200)
09:20:56.372 INFO  [Executor task launch worker for task 305] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=99), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/99] for update
09:20:56.372 INFO  [Executor task launch worker for task 305] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=99), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/99] for update
09:20:56.372 INFO  [Executor task launch worker for task 305] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.372 INFO  [Executor task launch worker for task 305] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.372 INFO  [Executor task launch worker for task 306] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=100), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/100] for update
09:20:56.372 INFO  [Executor task launch worker for task 306] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=100), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/100] for update
09:20:56.372 INFO  [Executor task launch worker for task 306] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.372 INFO  [Executor task launch worker for task 306] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.372 INFO  [Executor task launch worker for task 303] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=97),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/97]
09:20:56.372 INFO  [Executor task launch worker for task 303] org.apache.spark.executor.Executor - Finished task 97.0 in stage 5.0 (TID 303). 3365 bytes result sent to driver
09:20:56.372 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 101.0 in stage 5.0 (TID 307, localhost, executor driver, partition 101, PROCESS_LOCAL, 4726 bytes)
09:20:56.372 INFO  [Executor task launch worker for task 307] org.apache.spark.executor.Executor - Running task 101.0 in stage 5.0 (TID 307)
09:20:56.372 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 97.0 in stage 5.0 (TID 303) in 31 ms on localhost (executor driver) (99/200)
09:20:56.372 INFO  [Executor task launch worker for task 305] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=99),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/99] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/99/2.delta
09:20:56.372 INFO  [Executor task launch worker for task 307] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=101), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/101] for update
09:20:56.372 INFO  [Executor task launch worker for task 306] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=100),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/100] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/100/2.delta
09:20:56.388 INFO  [Executor task launch worker for task 307] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=101), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/101] for update
09:20:56.388 INFO  [Executor task launch worker for task 307] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.388 INFO  [Executor task launch worker for task 307] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.388 INFO  [Executor task launch worker for task 305] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=99),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/99]
09:20:56.388 INFO  [Executor task launch worker for task 305] org.apache.spark.executor.Executor - Finished task 99.0 in stage 5.0 (TID 305). 3322 bytes result sent to driver
09:20:56.388 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 102.0 in stage 5.0 (TID 308, localhost, executor driver, partition 102, PROCESS_LOCAL, 4726 bytes)
09:20:56.388 INFO  [Executor task launch worker for task 308] org.apache.spark.executor.Executor - Running task 102.0 in stage 5.0 (TID 308)
09:20:56.388 INFO  [Executor task launch worker for task 307] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=101),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/101] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/101/2.delta
09:20:56.388 INFO  [Executor task launch worker for task 308] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=102), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/102] for update
09:20:56.388 INFO  [Executor task launch worker for task 308] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=102), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/102] for update
09:20:56.388 INFO  [Executor task launch worker for task 308] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.388 INFO  [Executor task launch worker for task 308] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.388 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 99.0 in stage 5.0 (TID 305) in 16 ms on localhost (executor driver) (100/200)
09:20:56.388 INFO  [Executor task launch worker for task 306] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=100),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/100]
09:20:56.388 INFO  [Executor task launch worker for task 307] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=101),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/101]
09:20:56.388 INFO  [Executor task launch worker for task 306] org.apache.spark.executor.Executor - Finished task 100.0 in stage 5.0 (TID 306). 3322 bytes result sent to driver
09:20:56.388 INFO  [Executor task launch worker for task 307] org.apache.spark.executor.Executor - Finished task 101.0 in stage 5.0 (TID 307). 3322 bytes result sent to driver
09:20:56.388 INFO  [Executor task launch worker for task 308] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=102),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/102] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/102/2.delta
09:20:56.403 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 103.0 in stage 5.0 (TID 309, localhost, executor driver, partition 103, PROCESS_LOCAL, 4726 bytes)
09:20:56.403 INFO  [Executor task launch worker for task 309] org.apache.spark.executor.Executor - Running task 103.0 in stage 5.0 (TID 309)
09:20:56.403 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 104.0 in stage 5.0 (TID 310, localhost, executor driver, partition 104, PROCESS_LOCAL, 4726 bytes)
09:20:56.403 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 100.0 in stage 5.0 (TID 306) in 31 ms on localhost (executor driver) (101/200)
09:20:56.403 INFO  [Executor task launch worker for task 310] org.apache.spark.executor.Executor - Running task 104.0 in stage 5.0 (TID 310)
09:20:56.403 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 101.0 in stage 5.0 (TID 307) in 31 ms on localhost (executor driver) (102/200)
09:20:56.403 INFO  [Executor task launch worker for task 309] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=103), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/103] for update
09:20:56.403 INFO  [Executor task launch worker for task 309] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=103), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/103] for update
09:20:56.403 INFO  [Executor task launch worker for task 310] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=104), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/104] for update
09:20:56.403 INFO  [Executor task launch worker for task 309] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.403 INFO  [Executor task launch worker for task 310] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=104), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/104] for update
09:20:56.403 INFO  [Executor task launch worker for task 309] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.403 INFO  [Executor task launch worker for task 310] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 2 blocks
09:20:56.403 INFO  [Executor task launch worker for task 310] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.403 INFO  [Executor task launch worker for task 308] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=102),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/102]
09:20:56.403 INFO  [Executor task launch worker for task 308] org.apache.spark.executor.Executor - Finished task 102.0 in stage 5.0 (TID 308). 3322 bytes result sent to driver
09:20:56.403 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 105.0 in stage 5.0 (TID 311, localhost, executor driver, partition 105, PROCESS_LOCAL, 4726 bytes)
09:20:56.403 INFO  [Executor task launch worker for task 309] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=103),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/103] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/103/2.delta
09:20:56.419 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 102.0 in stage 5.0 (TID 308) in 31 ms on localhost (executor driver) (103/200)
09:20:56.419 INFO  [Executor task launch worker for task 311] org.apache.spark.executor.Executor - Running task 105.0 in stage 5.0 (TID 311)
09:20:56.419 INFO  [Executor task launch worker for task 311] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=105), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/105] for update
09:20:56.419 INFO  [Executor task launch worker for task 311] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=105), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/105] for update
09:20:56.419 INFO  [Executor task launch worker for task 311] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.419 INFO  [Executor task launch worker for task 311] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.419 INFO  [Executor task launch worker for task 309] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=103),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/103]
09:20:56.419 INFO  [Executor task launch worker for task 309] org.apache.spark.executor.Executor - Finished task 103.0 in stage 5.0 (TID 309). 3322 bytes result sent to driver
09:20:56.419 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 106.0 in stage 5.0 (TID 312, localhost, executor driver, partition 106, PROCESS_LOCAL, 4726 bytes)
09:20:56.419 INFO  [Executor task launch worker for task 312] org.apache.spark.executor.Executor - Running task 106.0 in stage 5.0 (TID 312)
09:20:56.419 INFO  [Executor task launch worker for task 310] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=104),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/104] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/104/2.delta
09:20:56.419 INFO  [Executor task launch worker for task 312] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=106), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/106] for update
09:20:56.419 INFO  [Executor task launch worker for task 312] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=106), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/106] for update
09:20:56.419 INFO  [Executor task launch worker for task 312] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.419 INFO  [Executor task launch worker for task 311] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=105),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/105] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/105/2.delta
09:20:56.419 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 103.0 in stage 5.0 (TID 309) in 16 ms on localhost (executor driver) (104/200)
09:20:56.419 INFO  [Executor task launch worker for task 310] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=104),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/104]
09:20:56.435 INFO  [Executor task launch worker for task 312] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 16 ms
09:20:56.435 INFO  [Executor task launch worker for task 310] org.apache.spark.executor.Executor - Finished task 104.0 in stage 5.0 (TID 310). 3351 bytes result sent to driver
09:20:56.435 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 107.0 in stage 5.0 (TID 313, localhost, executor driver, partition 107, PROCESS_LOCAL, 4726 bytes)
09:20:56.435 INFO  [Executor task launch worker for task 313] org.apache.spark.executor.Executor - Running task 107.0 in stage 5.0 (TID 313)
09:20:56.435 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 104.0 in stage 5.0 (TID 310) in 32 ms on localhost (executor driver) (105/200)
09:20:56.435 INFO  [Executor task launch worker for task 313] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=107), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/107] for update
09:20:56.435 INFO  [Executor task launch worker for task 313] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=107), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/107] for update
09:20:56.435 INFO  [Executor task launch worker for task 313] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.435 INFO  [Executor task launch worker for task 311] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=105),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/105]
09:20:56.435 INFO  [Executor task launch worker for task 313] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.435 INFO  [Executor task launch worker for task 312] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=106),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/106] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/106/2.delta
09:20:56.435 INFO  [Executor task launch worker for task 311] org.apache.spark.executor.Executor - Finished task 105.0 in stage 5.0 (TID 311). 3322 bytes result sent to driver
09:20:56.435 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 108.0 in stage 5.0 (TID 314, localhost, executor driver, partition 108, PROCESS_LOCAL, 4726 bytes)
09:20:56.435 INFO  [Executor task launch worker for task 312] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=106),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/106]
09:20:56.435 INFO  [Executor task launch worker for task 313] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=107),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/107] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/107/2.delta
09:20:56.450 INFO  [Executor task launch worker for task 312] org.apache.spark.executor.Executor - Finished task 106.0 in stage 5.0 (TID 312). 3322 bytes result sent to driver
09:20:56.450 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 105.0 in stage 5.0 (TID 311) in 47 ms on localhost (executor driver) (106/200)
09:20:56.450 INFO  [Executor task launch worker for task 314] org.apache.spark.executor.Executor - Running task 108.0 in stage 5.0 (TID 314)
09:20:56.450 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 109.0 in stage 5.0 (TID 315, localhost, executor driver, partition 109, PROCESS_LOCAL, 4726 bytes)
09:20:56.450 INFO  [Executor task launch worker for task 315] org.apache.spark.executor.Executor - Running task 109.0 in stage 5.0 (TID 315)
09:20:56.450 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 106.0 in stage 5.0 (TID 312) in 31 ms on localhost (executor driver) (107/200)
09:20:56.450 INFO  [Executor task launch worker for task 314] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=108), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/108] for update
09:20:56.450 INFO  [Executor task launch worker for task 315] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=109), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/109] for update
09:20:56.450 INFO  [Executor task launch worker for task 315] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=109), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/109] for update
09:20:56.450 INFO  [Executor task launch worker for task 314] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=108), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/108] for update
09:20:56.450 INFO  [Executor task launch worker for task 315] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.450 INFO  [Executor task launch worker for task 315] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.450 INFO  [Executor task launch worker for task 314] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.450 INFO  [Executor task launch worker for task 314] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.450 INFO  [Executor task launch worker for task 313] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=107),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/107]
09:20:56.450 INFO  [Executor task launch worker for task 313] org.apache.spark.executor.Executor - Finished task 107.0 in stage 5.0 (TID 313). 3322 bytes result sent to driver
09:20:56.450 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 110.0 in stage 5.0 (TID 316, localhost, executor driver, partition 110, PROCESS_LOCAL, 4726 bytes)
09:20:56.450 INFO  [Executor task launch worker for task 315] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=109),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/109] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/109/2.delta
09:20:56.466 INFO  [Executor task launch worker for task 316] org.apache.spark.executor.Executor - Running task 110.0 in stage 5.0 (TID 316)
09:20:56.466 INFO  [Executor task launch worker for task 316] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=110), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/110] for update
09:20:56.466 INFO  [Executor task launch worker for task 316] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=110), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/110] for update
09:20:56.466 INFO  [Executor task launch worker for task 316] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.466 INFO  [Executor task launch worker for task 316] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.466 INFO  [Executor task launch worker for task 315] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=109),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/109]
09:20:56.466 INFO  [Executor task launch worker for task 315] org.apache.spark.executor.Executor - Finished task 109.0 in stage 5.0 (TID 315). 3322 bytes result sent to driver
09:20:56.466 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 107.0 in stage 5.0 (TID 313) in 31 ms on localhost (executor driver) (108/200)
09:20:56.466 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 111.0 in stage 5.0 (TID 317, localhost, executor driver, partition 111, PROCESS_LOCAL, 4726 bytes)
09:20:56.466 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 109.0 in stage 5.0 (TID 315) in 16 ms on localhost (executor driver) (109/200)
09:20:56.466 INFO  [Executor task launch worker for task 317] org.apache.spark.executor.Executor - Running task 111.0 in stage 5.0 (TID 317)
09:20:56.466 INFO  [Executor task launch worker for task 317] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=111), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/111] for update
09:20:56.466 INFO  [Executor task launch worker for task 317] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=111), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/111] for update
09:20:56.466 INFO  [Executor task launch worker for task 317] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.466 INFO  [Executor task launch worker for task 317] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.466 INFO  [Executor task launch worker for task 314] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=108),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/108] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/108/2.delta
09:20:56.466 INFO  [Executor task launch worker for task 316] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=110),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/110] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/110/2.delta
09:20:56.481 INFO  [Executor task launch worker for task 314] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=108),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/108]
09:20:56.481 INFO  [Executor task launch worker for task 316] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=110),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/110]
09:20:56.481 INFO  [Executor task launch worker for task 314] org.apache.spark.executor.Executor - Finished task 108.0 in stage 5.0 (TID 314). 3322 bytes result sent to driver
09:20:56.481 INFO  [Executor task launch worker for task 316] org.apache.spark.executor.Executor - Finished task 110.0 in stage 5.0 (TID 316). 3322 bytes result sent to driver
09:20:56.481 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 112.0 in stage 5.0 (TID 318, localhost, executor driver, partition 112, PROCESS_LOCAL, 4726 bytes)
09:20:56.481 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 113.0 in stage 5.0 (TID 319, localhost, executor driver, partition 113, PROCESS_LOCAL, 4726 bytes)
09:20:56.481 INFO  [Executor task launch worker for task 318] org.apache.spark.executor.Executor - Running task 112.0 in stage 5.0 (TID 318)
09:20:56.481 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 108.0 in stage 5.0 (TID 314) in 46 ms on localhost (executor driver) (110/200)
09:20:56.481 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 110.0 in stage 5.0 (TID 316) in 31 ms on localhost (executor driver) (111/200)
09:20:56.481 INFO  [Executor task launch worker for task 317] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=111),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/111] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/111/2.delta
09:20:56.481 INFO  [Executor task launch worker for task 319] org.apache.spark.executor.Executor - Running task 113.0 in stage 5.0 (TID 319)
09:20:56.481 INFO  [Executor task launch worker for task 318] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=112), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/112] for update
09:20:56.481 INFO  [Executor task launch worker for task 318] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=112), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/112] for update
09:20:56.481 INFO  [Executor task launch worker for task 319] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=113), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/113] for update
09:20:56.481 INFO  [Executor task launch worker for task 317] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=111),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/111]
09:20:56.497 INFO  [Executor task launch worker for task 318] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.497 INFO  [Executor task launch worker for task 319] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=113), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/113] for update
09:20:56.497 INFO  [Executor task launch worker for task 318] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.497 INFO  [Executor task launch worker for task 319] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.497 INFO  [Executor task launch worker for task 319] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.497 INFO  [Executor task launch worker for task 317] org.apache.spark.executor.Executor - Finished task 111.0 in stage 5.0 (TID 317). 3322 bytes result sent to driver
09:20:56.497 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 114.0 in stage 5.0 (TID 320, localhost, executor driver, partition 114, PROCESS_LOCAL, 4726 bytes)
09:20:56.497 INFO  [Executor task launch worker for task 320] org.apache.spark.executor.Executor - Running task 114.0 in stage 5.0 (TID 320)
09:20:56.497 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 111.0 in stage 5.0 (TID 317) in 31 ms on localhost (executor driver) (112/200)
09:20:56.497 INFO  [Executor task launch worker for task 320] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=114), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/114] for update
09:20:56.497 INFO  [Executor task launch worker for task 320] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=114), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/114] for update
09:20:56.497 INFO  [Executor task launch worker for task 320] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.497 INFO  [Executor task launch worker for task 320] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.497 INFO  [Executor task launch worker for task 319] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=113),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/113] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/113/2.delta
09:20:56.497 INFO  [Executor task launch worker for task 320] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=114),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/114] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/114/2.delta
09:20:56.497 INFO  [Executor task launch worker for task 319] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=113),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/113]
09:20:56.497 INFO  [Executor task launch worker for task 318] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=112),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/112] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/112/2.delta
09:20:56.513 INFO  [Executor task launch worker for task 319] org.apache.spark.executor.Executor - Finished task 113.0 in stage 5.0 (TID 319). 3322 bytes result sent to driver
09:20:56.513 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 115.0 in stage 5.0 (TID 321, localhost, executor driver, partition 115, PROCESS_LOCAL, 4726 bytes)
09:20:56.513 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 113.0 in stage 5.0 (TID 319) in 32 ms on localhost (executor driver) (113/200)
09:20:56.513 INFO  [Executor task launch worker for task 321] org.apache.spark.executor.Executor - Running task 115.0 in stage 5.0 (TID 321)
09:20:56.513 INFO  [Executor task launch worker for task 320] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=114),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/114]
09:20:56.513 INFO  [Executor task launch worker for task 321] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=115), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/115] for update
09:20:56.513 INFO  [Executor task launch worker for task 321] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=115), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/115] for update
09:20:56.513 INFO  [Executor task launch worker for task 321] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.513 INFO  [Executor task launch worker for task 321] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.513 INFO  [Executor task launch worker for task 320] org.apache.spark.executor.Executor - Finished task 114.0 in stage 5.0 (TID 320). 3322 bytes result sent to driver
09:20:56.513 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 116.0 in stage 5.0 (TID 322, localhost, executor driver, partition 116, PROCESS_LOCAL, 4726 bytes)
09:20:56.513 INFO  [Executor task launch worker for task 322] org.apache.spark.executor.Executor - Running task 116.0 in stage 5.0 (TID 322)
09:20:56.513 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 114.0 in stage 5.0 (TID 320) in 16 ms on localhost (executor driver) (114/200)
09:20:56.513 INFO  [Executor task launch worker for task 318] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=112),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/112]
09:20:56.513 INFO  [Executor task launch worker for task 322] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=116), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/116] for update
09:20:56.513 INFO  [Executor task launch worker for task 321] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=115),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/115] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/115/2.delta
09:20:56.528 INFO  [Executor task launch worker for task 322] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=116), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/116] for update
09:20:56.528 INFO  [Executor task launch worker for task 318] org.apache.spark.executor.Executor - Finished task 112.0 in stage 5.0 (TID 318). 3322 bytes result sent to driver
09:20:56.528 INFO  [Executor task launch worker for task 322] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.528 INFO  [Executor task launch worker for task 322] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.528 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 117.0 in stage 5.0 (TID 323, localhost, executor driver, partition 117, PROCESS_LOCAL, 4726 bytes)
09:20:56.528 INFO  [Executor task launch worker for task 323] org.apache.spark.executor.Executor - Running task 117.0 in stage 5.0 (TID 323)
09:20:56.528 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 112.0 in stage 5.0 (TID 318) in 47 ms on localhost (executor driver) (115/200)
09:20:56.528 INFO  [Executor task launch worker for task 323] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=117), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/117] for update
09:20:56.528 INFO  [Executor task launch worker for task 323] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=117), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/117] for update
09:20:56.528 INFO  [Executor task launch worker for task 323] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.528 INFO  [Executor task launch worker for task 323] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.528 INFO  [Executor task launch worker for task 321] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=115),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/115]
09:20:56.528 INFO  [Executor task launch worker for task 321] org.apache.spark.executor.Executor - Finished task 115.0 in stage 5.0 (TID 321). 3322 bytes result sent to driver
09:20:56.528 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 118.0 in stage 5.0 (TID 324, localhost, executor driver, partition 118, PROCESS_LOCAL, 4726 bytes)
09:20:56.528 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 115.0 in stage 5.0 (TID 321) in 15 ms on localhost (executor driver) (116/200)
09:20:56.528 INFO  [Executor task launch worker for task 324] org.apache.spark.executor.Executor - Running task 118.0 in stage 5.0 (TID 324)
09:20:56.528 INFO  [Executor task launch worker for task 322] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=116),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/116] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/116/2.delta
09:20:56.528 INFO  [Executor task launch worker for task 323] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=117),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/117] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/117/2.delta
09:20:56.544 INFO  [Executor task launch worker for task 324] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=118), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/118] for update
09:20:56.544 INFO  [Executor task launch worker for task 324] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=118), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/118] for update
09:20:56.544 INFO  [Executor task launch worker for task 324] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.544 INFO  [Executor task launch worker for task 324] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.544 INFO  [Executor task launch worker for task 323] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=117),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/117]
09:20:56.544 INFO  [Executor task launch worker for task 323] org.apache.spark.executor.Executor - Finished task 117.0 in stage 5.0 (TID 323). 3322 bytes result sent to driver
09:20:56.544 INFO  [Executor task launch worker for task 322] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=116),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/116]
09:20:56.544 INFO  [Executor task launch worker for task 322] org.apache.spark.executor.Executor - Finished task 116.0 in stage 5.0 (TID 322). 3322 bytes result sent to driver
09:20:56.544 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 119.0 in stage 5.0 (TID 325, localhost, executor driver, partition 119, PROCESS_LOCAL, 4726 bytes)
09:20:56.544 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 120.0 in stage 5.0 (TID 326, localhost, executor driver, partition 120, PROCESS_LOCAL, 4726 bytes)
09:20:56.544 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 117.0 in stage 5.0 (TID 323) in 16 ms on localhost (executor driver) (117/200)
09:20:56.544 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 116.0 in stage 5.0 (TID 322) in 31 ms on localhost (executor driver) (118/200)
09:20:56.544 INFO  [Executor task launch worker for task 325] org.apache.spark.executor.Executor - Running task 119.0 in stage 5.0 (TID 325)
09:20:56.544 INFO  [Executor task launch worker for task 324] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=118),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/118] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/118/2.delta
09:20:56.544 INFO  [Executor task launch worker for task 326] org.apache.spark.executor.Executor - Running task 120.0 in stage 5.0 (TID 326)
09:20:56.544 INFO  [Executor task launch worker for task 324] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=118),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/118]
09:20:56.560 INFO  [Executor task launch worker for task 325] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=119), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/119] for update
09:20:56.560 INFO  [Executor task launch worker for task 324] org.apache.spark.executor.Executor - Finished task 118.0 in stage 5.0 (TID 324). 3365 bytes result sent to driver
09:20:56.560 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 121.0 in stage 5.0 (TID 327, localhost, executor driver, partition 121, PROCESS_LOCAL, 4726 bytes)
09:20:56.560 INFO  [Executor task launch worker for task 327] org.apache.spark.executor.Executor - Running task 121.0 in stage 5.0 (TID 327)
09:20:56.560 INFO  [Executor task launch worker for task 326] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=120), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/120] for update
09:20:56.560 INFO  [Executor task launch worker for task 326] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=120), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/120] for update
09:20:56.560 INFO  [Executor task launch worker for task 326] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.560 INFO  [Executor task launch worker for task 326] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.560 INFO  [Executor task launch worker for task 325] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=119), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/119] for update
09:20:56.560 INFO  [Executor task launch worker for task 325] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.560 INFO  [Executor task launch worker for task 325] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.560 INFO  [Executor task launch worker for task 327] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=121), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/121] for update
09:20:56.560 INFO  [Executor task launch worker for task 327] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=121), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/121] for update
09:20:56.560 INFO  [Executor task launch worker for task 327] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.560 INFO  [Executor task launch worker for task 327] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.560 INFO  [Executor task launch worker for task 326] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=120),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/120] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/120/2.delta
09:20:56.560 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 118.0 in stage 5.0 (TID 324) in 32 ms on localhost (executor driver) (119/200)
09:20:56.560 INFO  [Executor task launch worker for task 327] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=121),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/121] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/121/2.delta
09:20:56.560 INFO  [Executor task launch worker for task 325] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=119),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/119] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/119/2.delta
09:20:56.575 INFO  [Executor task launch worker for task 325] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=119),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/119]
09:20:56.575 INFO  [Executor task launch worker for task 325] org.apache.spark.executor.Executor - Finished task 119.0 in stage 5.0 (TID 325). 3408 bytes result sent to driver
09:20:56.575 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 122.0 in stage 5.0 (TID 328, localhost, executor driver, partition 122, PROCESS_LOCAL, 4726 bytes)
09:20:56.575 INFO  [Executor task launch worker for task 328] org.apache.spark.executor.Executor - Running task 122.0 in stage 5.0 (TID 328)
09:20:56.575 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 119.0 in stage 5.0 (TID 325) in 31 ms on localhost (executor driver) (120/200)
09:20:56.575 INFO  [Executor task launch worker for task 327] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=121),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/121]
09:20:56.575 INFO  [Executor task launch worker for task 326] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=120),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/120]
09:20:56.575 INFO  [Executor task launch worker for task 328] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=122), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/122] for update
09:20:56.575 INFO  [Executor task launch worker for task 326] org.apache.spark.executor.Executor - Finished task 120.0 in stage 5.0 (TID 326). 3322 bytes result sent to driver
09:20:56.575 INFO  [Executor task launch worker for task 327] org.apache.spark.executor.Executor - Finished task 121.0 in stage 5.0 (TID 327). 3322 bytes result sent to driver
09:20:56.575 INFO  [Executor task launch worker for task 328] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=122), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/122] for update
09:20:56.575 INFO  [Executor task launch worker for task 328] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.575 INFO  [Executor task launch worker for task 328] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.575 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 123.0 in stage 5.0 (TID 329, localhost, executor driver, partition 123, PROCESS_LOCAL, 4726 bytes)
09:20:56.575 INFO  [Executor task launch worker for task 329] org.apache.spark.executor.Executor - Running task 123.0 in stage 5.0 (TID 329)
09:20:56.575 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 124.0 in stage 5.0 (TID 330, localhost, executor driver, partition 124, PROCESS_LOCAL, 4726 bytes)
09:20:56.575 INFO  [Executor task launch worker for task 330] org.apache.spark.executor.Executor - Running task 124.0 in stage 5.0 (TID 330)
09:20:56.575 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 121.0 in stage 5.0 (TID 327) in 15 ms on localhost (executor driver) (121/200)
09:20:56.575 INFO  [Executor task launch worker for task 330] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=124), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/124] for update
09:20:56.575 INFO  [Executor task launch worker for task 329] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=123), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/123] for update
09:20:56.575 INFO  [Executor task launch worker for task 328] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=122),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/122] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/122/2.delta
09:20:56.591 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 120.0 in stage 5.0 (TID 326) in 47 ms on localhost (executor driver) (122/200)
09:20:56.591 INFO  [Executor task launch worker for task 330] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=124), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/124] for update
09:20:56.591 INFO  [Executor task launch worker for task 329] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=123), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/123] for update
09:20:56.591 INFO  [Executor task launch worker for task 330] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.591 INFO  [Executor task launch worker for task 329] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.591 INFO  [Executor task launch worker for task 330] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.591 INFO  [Executor task launch worker for task 329] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.591 INFO  [Executor task launch worker for task 328] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=122),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/122]
09:20:56.591 INFO  [Executor task launch worker for task 328] org.apache.spark.executor.Executor - Finished task 122.0 in stage 5.0 (TID 328). 3322 bytes result sent to driver
09:20:56.591 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 125.0 in stage 5.0 (TID 331, localhost, executor driver, partition 125, PROCESS_LOCAL, 4726 bytes)
09:20:56.591 INFO  [Executor task launch worker for task 331] org.apache.spark.executor.Executor - Running task 125.0 in stage 5.0 (TID 331)
09:20:56.591 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 122.0 in stage 5.0 (TID 328) in 16 ms on localhost (executor driver) (123/200)
09:20:56.591 INFO  [Executor task launch worker for task 331] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=125), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/125] for update
09:20:56.591 INFO  [Executor task launch worker for task 331] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=125), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/125] for update
09:20:56.591 INFO  [Executor task launch worker for task 330] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=124),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/124] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/124/2.delta
09:20:56.591 INFO  [Executor task launch worker for task 331] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.591 INFO  [Executor task launch worker for task 329] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=123),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/123] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/123/2.delta
09:20:56.591 INFO  [Executor task launch worker for task 330] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=124),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/124]
09:20:56.606 INFO  [Executor task launch worker for task 331] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 15 ms
09:20:56.606 INFO  [Executor task launch worker for task 330] org.apache.spark.executor.Executor - Finished task 124.0 in stage 5.0 (TID 330). 3322 bytes result sent to driver
09:20:56.606 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 126.0 in stage 5.0 (TID 332, localhost, executor driver, partition 126, PROCESS_LOCAL, 4726 bytes)
09:20:56.606 INFO  [Executor task launch worker for task 332] org.apache.spark.executor.Executor - Running task 126.0 in stage 5.0 (TID 332)
09:20:56.606 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 124.0 in stage 5.0 (TID 330) in 31 ms on localhost (executor driver) (124/200)
09:20:56.606 INFO  [Executor task launch worker for task 332] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=126), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/126] for update
09:20:56.606 INFO  [Executor task launch worker for task 332] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=126), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/126] for update
09:20:56.606 INFO  [Executor task launch worker for task 332] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.606 INFO  [Executor task launch worker for task 332] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.606 INFO  [Executor task launch worker for task 329] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=123),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/123]
09:20:56.606 INFO  [Executor task launch worker for task 329] org.apache.spark.executor.Executor - Finished task 123.0 in stage 5.0 (TID 329). 3322 bytes result sent to driver
09:20:56.606 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 127.0 in stage 5.0 (TID 333, localhost, executor driver, partition 127, PROCESS_LOCAL, 4726 bytes)
09:20:56.606 INFO  [Executor task launch worker for task 331] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=125),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/125] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/125/2.delta
09:20:56.606 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 123.0 in stage 5.0 (TID 329) in 31 ms on localhost (executor driver) (125/200)
09:20:56.606 INFO  [Executor task launch worker for task 333] org.apache.spark.executor.Executor - Running task 127.0 in stage 5.0 (TID 333)
09:20:56.606 INFO  [Executor task launch worker for task 333] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=127), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/127] for update
09:20:56.606 INFO  [Executor task launch worker for task 333] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=127), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/127] for update
09:20:56.606 INFO  [Executor task launch worker for task 332] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=126),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/126] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/126/2.delta
09:20:56.606 INFO  [Executor task launch worker for task 331] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=125),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/125]
09:20:56.622 INFO  [Executor task launch worker for task 333] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.622 INFO  [Executor task launch worker for task 333] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.622 INFO  [Executor task launch worker for task 331] org.apache.spark.executor.Executor - Finished task 125.0 in stage 5.0 (TID 331). 3322 bytes result sent to driver
09:20:56.622 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 128.0 in stage 5.0 (TID 334, localhost, executor driver, partition 128, PROCESS_LOCAL, 4726 bytes)
09:20:56.622 INFO  [Executor task launch worker for task 334] org.apache.spark.executor.Executor - Running task 128.0 in stage 5.0 (TID 334)
09:20:56.622 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 125.0 in stage 5.0 (TID 331) in 31 ms on localhost (executor driver) (126/200)
09:20:56.622 INFO  [Executor task launch worker for task 334] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=128), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/128] for update
09:20:56.622 INFO  [Executor task launch worker for task 334] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=128), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/128] for update
09:20:56.622 INFO  [Executor task launch worker for task 334] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.622 INFO  [Executor task launch worker for task 334] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.622 INFO  [Executor task launch worker for task 332] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=126),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/126]
09:20:56.622 INFO  [Executor task launch worker for task 332] org.apache.spark.executor.Executor - Finished task 126.0 in stage 5.0 (TID 332). 3322 bytes result sent to driver
09:20:56.622 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 129.0 in stage 5.0 (TID 335, localhost, executor driver, partition 129, PROCESS_LOCAL, 4726 bytes)
09:20:56.622 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 126.0 in stage 5.0 (TID 332) in 16 ms on localhost (executor driver) (127/200)
09:20:56.622 INFO  [Executor task launch worker for task 335] org.apache.spark.executor.Executor - Running task 129.0 in stage 5.0 (TID 335)
09:20:56.622 INFO  [Executor task launch worker for task 333] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=127),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/127] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/127/2.delta
09:20:56.622 INFO  [Executor task launch worker for task 335] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=129), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/129] for update
09:20:56.622 INFO  [Executor task launch worker for task 334] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=128),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/128] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/128/2.delta
09:20:56.622 INFO  [Executor task launch worker for task 333] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=127),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/127]
09:20:56.638 INFO  [Executor task launch worker for task 335] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=129), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/129] for update
09:20:56.638 INFO  [Executor task launch worker for task 335] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.638 INFO  [Executor task launch worker for task 335] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.638 INFO  [Executor task launch worker for task 333] org.apache.spark.executor.Executor - Finished task 127.0 in stage 5.0 (TID 333). 3322 bytes result sent to driver
09:20:56.638 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 130.0 in stage 5.0 (TID 336, localhost, executor driver, partition 130, PROCESS_LOCAL, 4726 bytes)
09:20:56.638 INFO  [Executor task launch worker for task 336] org.apache.spark.executor.Executor - Running task 130.0 in stage 5.0 (TID 336)
09:20:56.638 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 127.0 in stage 5.0 (TID 333) in 32 ms on localhost (executor driver) (128/200)
09:20:56.638 INFO  [Executor task launch worker for task 336] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=130), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/130] for update
09:20:56.638 INFO  [Executor task launch worker for task 336] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=130), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/130] for update
09:20:56.638 INFO  [Executor task launch worker for task 336] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.638 INFO  [Executor task launch worker for task 336] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.638 INFO  [Executor task launch worker for task 334] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=128),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/128]
09:20:56.638 INFO  [Executor task launch worker for task 334] org.apache.spark.executor.Executor - Finished task 128.0 in stage 5.0 (TID 334). 3322 bytes result sent to driver
09:20:56.638 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 131.0 in stage 5.0 (TID 337, localhost, executor driver, partition 131, PROCESS_LOCAL, 4726 bytes)
09:20:56.638 INFO  [Executor task launch worker for task 337] org.apache.spark.executor.Executor - Running task 131.0 in stage 5.0 (TID 337)
09:20:56.638 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 128.0 in stage 5.0 (TID 334) in 16 ms on localhost (executor driver) (129/200)
09:20:56.638 INFO  [Executor task launch worker for task 335] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=129),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/129] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/129/2.delta
09:20:56.638 INFO  [Executor task launch worker for task 337] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=131), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/131] for update
09:20:56.638 INFO  [Executor task launch worker for task 336] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=130),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/130] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/130/2.delta
09:20:56.653 INFO  [Executor task launch worker for task 337] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=131), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/131] for update
09:20:56.653 INFO  [Executor task launch worker for task 337] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.653 INFO  [Executor task launch worker for task 337] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.653 INFO  [Executor task launch worker for task 336] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=130),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/130]
09:20:56.653 INFO  [Executor task launch worker for task 335] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=129),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/129]
09:20:56.653 INFO  [Executor task launch worker for task 336] org.apache.spark.executor.Executor - Finished task 130.0 in stage 5.0 (TID 336). 3322 bytes result sent to driver
09:20:56.653 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 132.0 in stage 5.0 (TID 338, localhost, executor driver, partition 132, PROCESS_LOCAL, 4726 bytes)
09:20:56.653 INFO  [Executor task launch worker for task 335] org.apache.spark.executor.Executor - Finished task 129.0 in stage 5.0 (TID 335). 3322 bytes result sent to driver
09:20:56.653 INFO  [Executor task launch worker for task 338] org.apache.spark.executor.Executor - Running task 132.0 in stage 5.0 (TID 338)
09:20:56.653 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 133.0 in stage 5.0 (TID 339, localhost, executor driver, partition 133, PROCESS_LOCAL, 4726 bytes)
09:20:56.653 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 130.0 in stage 5.0 (TID 336) in 15 ms on localhost (executor driver) (130/200)
09:20:56.653 INFO  [Executor task launch worker for task 339] org.apache.spark.executor.Executor - Running task 133.0 in stage 5.0 (TID 339)
09:20:56.653 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 129.0 in stage 5.0 (TID 335) in 31 ms on localhost (executor driver) (131/200)
09:20:56.653 INFO  [Executor task launch worker for task 337] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=131),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/131] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/131/2.delta
09:20:56.653 INFO  [Executor task launch worker for task 338] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=132), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/132] for update
09:20:56.653 INFO  [Executor task launch worker for task 338] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=132), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/132] for update
09:20:56.653 INFO  [Executor task launch worker for task 339] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=133), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/133] for update
09:20:56.653 INFO  [Executor task launch worker for task 337] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=131),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/131]
09:20:56.669 INFO  [Executor task launch worker for task 339] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=133), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/133] for update
09:20:56.669 INFO  [Executor task launch worker for task 338] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.669 INFO  [Executor task launch worker for task 338] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.669 INFO  [Executor task launch worker for task 339] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.669 INFO  [Executor task launch worker for task 339] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.669 INFO  [Executor task launch worker for task 337] org.apache.spark.executor.Executor - Finished task 131.0 in stage 5.0 (TID 337). 3322 bytes result sent to driver
09:20:56.669 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 134.0 in stage 5.0 (TID 340, localhost, executor driver, partition 134, PROCESS_LOCAL, 4726 bytes)
09:20:56.669 INFO  [Executor task launch worker for task 340] org.apache.spark.executor.Executor - Running task 134.0 in stage 5.0 (TID 340)
09:20:56.669 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 131.0 in stage 5.0 (TID 337) in 31 ms on localhost (executor driver) (132/200)
09:20:56.669 INFO  [Executor task launch worker for task 340] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=134), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/134] for update
09:20:56.669 INFO  [Executor task launch worker for task 340] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=134), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/134] for update
09:20:56.669 INFO  [Executor task launch worker for task 340] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.669 INFO  [Executor task launch worker for task 340] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.669 INFO  [Executor task launch worker for task 338] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=132),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/132] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/132/2.delta
09:20:56.669 INFO  [Executor task launch worker for task 339] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=133),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/133] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/133/2.delta
09:20:56.669 INFO  [Executor task launch worker for task 340] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=134),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/134] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/134/2.delta
09:20:56.669 INFO  [Executor task launch worker for task 339] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=133),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/133]
09:20:56.669 INFO  [Executor task launch worker for task 338] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=132),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/132]
09:20:56.684 INFO  [Executor task launch worker for task 338] org.apache.spark.executor.Executor - Finished task 132.0 in stage 5.0 (TID 338). 3322 bytes result sent to driver
09:20:56.684 INFO  [Executor task launch worker for task 339] org.apache.spark.executor.Executor - Finished task 133.0 in stage 5.0 (TID 339). 3322 bytes result sent to driver
09:20:56.684 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 135.0 in stage 5.0 (TID 341, localhost, executor driver, partition 135, PROCESS_LOCAL, 4726 bytes)
09:20:56.684 INFO  [Executor task launch worker for task 341] org.apache.spark.executor.Executor - Running task 135.0 in stage 5.0 (TID 341)
09:20:56.684 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 136.0 in stage 5.0 (TID 342, localhost, executor driver, partition 136, PROCESS_LOCAL, 4726 bytes)
09:20:56.684 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 133.0 in stage 5.0 (TID 339) in 31 ms on localhost (executor driver) (133/200)
09:20:56.684 INFO  [Executor task launch worker for task 342] org.apache.spark.executor.Executor - Running task 136.0 in stage 5.0 (TID 342)
09:20:56.684 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 132.0 in stage 5.0 (TID 338) in 31 ms on localhost (executor driver) (134/200)
09:20:56.684 INFO  [Executor task launch worker for task 341] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=135), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/135] for update
09:20:56.684 INFO  [Executor task launch worker for task 341] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=135), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/135] for update
09:20:56.684 INFO  [Executor task launch worker for task 342] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=136), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/136] for update
09:20:56.684 INFO  [Executor task launch worker for task 342] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=136), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/136] for update
09:20:56.684 INFO  [Executor task launch worker for task 341] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.684 INFO  [Executor task launch worker for task 341] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.684 INFO  [Executor task launch worker for task 342] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.684 INFO  [Executor task launch worker for task 340] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=134),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/134]
09:20:56.684 INFO  [Executor task launch worker for task 341] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=135),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/135] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/135/2.delta
09:20:56.700 INFO  [Executor task launch worker for task 342] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 16 ms
09:20:56.700 INFO  [Executor task launch worker for task 340] org.apache.spark.executor.Executor - Finished task 134.0 in stage 5.0 (TID 340). 3322 bytes result sent to driver
09:20:56.700 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 137.0 in stage 5.0 (TID 343, localhost, executor driver, partition 137, PROCESS_LOCAL, 4726 bytes)
09:20:56.700 INFO  [Executor task launch worker for task 343] org.apache.spark.executor.Executor - Running task 137.0 in stage 5.0 (TID 343)
09:20:56.700 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 134.0 in stage 5.0 (TID 340) in 31 ms on localhost (executor driver) (135/200)
09:20:56.700 INFO  [Executor task launch worker for task 343] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=137), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/137] for update
09:20:56.700 INFO  [Executor task launch worker for task 343] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=137), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/137] for update
09:20:56.700 INFO  [Executor task launch worker for task 343] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.700 INFO  [Executor task launch worker for task 343] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.700 INFO  [Executor task launch worker for task 341] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=135),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/135]
09:20:56.700 INFO  [Executor task launch worker for task 341] org.apache.spark.executor.Executor - Finished task 135.0 in stage 5.0 (TID 341). 3322 bytes result sent to driver
09:20:56.700 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 138.0 in stage 5.0 (TID 344, localhost, executor driver, partition 138, PROCESS_LOCAL, 4726 bytes)
09:20:56.700 INFO  [Executor task launch worker for task 344] org.apache.spark.executor.Executor - Running task 138.0 in stage 5.0 (TID 344)
09:20:56.700 INFO  [Executor task launch worker for task 342] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=136),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/136] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/136/2.delta
09:20:56.700 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 135.0 in stage 5.0 (TID 341) in 16 ms on localhost (executor driver) (136/200)
09:20:56.700 INFO  [Executor task launch worker for task 344] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=138), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/138] for update
09:20:56.700 INFO  [Executor task launch worker for task 343] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=137),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/137] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/137/2.delta
09:20:56.700 INFO  [Executor task launch worker for task 342] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=136),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/136]
09:20:56.713 INFO  [Executor task launch worker for task 342] org.apache.spark.executor.Executor - Finished task 136.0 in stage 5.0 (TID 342). 3322 bytes result sent to driver
09:20:56.713 INFO  [Executor task launch worker for task 344] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=138), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/138] for update
09:20:56.713 INFO  [Executor task launch worker for task 344] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.713 INFO  [Executor task launch worker for task 344] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.713 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 139.0 in stage 5.0 (TID 345, localhost, executor driver, partition 139, PROCESS_LOCAL, 4726 bytes)
09:20:56.713 INFO  [Executor task launch worker for task 345] org.apache.spark.executor.Executor - Running task 139.0 in stage 5.0 (TID 345)
09:20:56.713 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 136.0 in stage 5.0 (TID 342) in 29 ms on localhost (executor driver) (137/200)
09:20:56.715 INFO  [Executor task launch worker for task 345] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=139), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/139] for update
09:20:56.715 INFO  [Executor task launch worker for task 345] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=139), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/139] for update
09:20:56.715 INFO  [Executor task launch worker for task 345] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.715 INFO  [Executor task launch worker for task 345] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.717 INFO  [Executor task launch worker for task 343] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=137),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/137]
09:20:56.717 INFO  [Executor task launch worker for task 343] org.apache.spark.executor.Executor - Finished task 137.0 in stage 5.0 (TID 343). 3322 bytes result sent to driver
09:20:56.717 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 140.0 in stage 5.0 (TID 346, localhost, executor driver, partition 140, PROCESS_LOCAL, 4726 bytes)
09:20:56.717 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 137.0 in stage 5.0 (TID 343) in 17 ms on localhost (executor driver) (138/200)
09:20:56.717 INFO  [Executor task launch worker for task 346] org.apache.spark.executor.Executor - Running task 140.0 in stage 5.0 (TID 346)
09:20:56.720 INFO  [Executor task launch worker for task 346] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=140), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/140] for update
09:20:56.720 INFO  [Executor task launch worker for task 346] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=140), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/140] for update
09:20:56.720 INFO  [Executor task launch worker for task 346] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.720 INFO  [Executor task launch worker for task 346] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.721 INFO  [Executor task launch worker for task 344] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=138),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/138] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/138/2.delta
09:20:56.722 INFO  [Executor task launch worker for task 345] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=139),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/139] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/139/2.delta
09:20:56.727 INFO  [Executor task launch worker for task 345] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=139),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/139]
09:20:56.727 INFO  [Executor task launch worker for task 345] org.apache.spark.executor.Executor - Finished task 139.0 in stage 5.0 (TID 345). 3408 bytes result sent to driver
09:20:56.732 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 141.0 in stage 5.0 (TID 347, localhost, executor driver, partition 141, PROCESS_LOCAL, 4726 bytes)
09:20:56.732 INFO  [Executor task launch worker for task 347] org.apache.spark.executor.Executor - Running task 141.0 in stage 5.0 (TID 347)
09:20:56.732 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 139.0 in stage 5.0 (TID 345) in 19 ms on localhost (executor driver) (139/200)
09:20:56.732 INFO  [Executor task launch worker for task 346] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=140),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/140] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/140/2.delta
09:20:56.732 INFO  [Executor task launch worker for task 344] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=138),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/138]
09:20:56.732 INFO  [Executor task launch worker for task 344] org.apache.spark.executor.Executor - Finished task 138.0 in stage 5.0 (TID 344). 3408 bytes result sent to driver
09:20:56.732 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 142.0 in stage 5.0 (TID 348, localhost, executor driver, partition 142, PROCESS_LOCAL, 4726 bytes)
09:20:56.732 INFO  [Executor task launch worker for task 348] org.apache.spark.executor.Executor - Running task 142.0 in stage 5.0 (TID 348)
09:20:56.732 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 138.0 in stage 5.0 (TID 344) in 32 ms on localhost (executor driver) (140/200)
09:20:56.732 INFO  [Executor task launch worker for task 347] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=141), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/141] for update
09:20:56.732 INFO  [Executor task launch worker for task 347] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=141), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/141] for update
09:20:56.732 INFO  [Executor task launch worker for task 347] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.732 INFO  [Executor task launch worker for task 347] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.732 INFO  [Executor task launch worker for task 348] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=142), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/142] for update
09:20:56.732 INFO  [Executor task launch worker for task 348] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=142), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/142] for update
09:20:56.732 INFO  [Executor task launch worker for task 348] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.732 INFO  [Executor task launch worker for task 346] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=140),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/140]
09:20:56.732 INFO  [Executor task launch worker for task 347] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=141),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/141] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/141/2.delta
09:20:56.748 INFO  [Executor task launch worker for task 348] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 16 ms
09:20:56.748 INFO  [Executor task launch worker for task 346] org.apache.spark.executor.Executor - Finished task 140.0 in stage 5.0 (TID 346). 3451 bytes result sent to driver
09:20:56.748 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 143.0 in stage 5.0 (TID 349, localhost, executor driver, partition 143, PROCESS_LOCAL, 4726 bytes)
09:20:56.748 INFO  [Executor task launch worker for task 349] org.apache.spark.executor.Executor - Running task 143.0 in stage 5.0 (TID 349)
09:20:56.748 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 140.0 in stage 5.0 (TID 346) in 31 ms on localhost (executor driver) (141/200)
09:20:56.748 INFO  [Executor task launch worker for task 349] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=143), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/143] for update
09:20:56.748 INFO  [Executor task launch worker for task 349] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=143), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/143] for update
09:20:56.748 INFO  [Executor task launch worker for task 349] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.748 INFO  [Executor task launch worker for task 349] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.748 INFO  [Executor task launch worker for task 347] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=141),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/141]
09:20:56.748 INFO  [Executor task launch worker for task 347] org.apache.spark.executor.Executor - Finished task 141.0 in stage 5.0 (TID 347). 3322 bytes result sent to driver
09:20:56.748 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 144.0 in stage 5.0 (TID 350, localhost, executor driver, partition 144, PROCESS_LOCAL, 4726 bytes)
09:20:56.748 INFO  [Executor task launch worker for task 350] org.apache.spark.executor.Executor - Running task 144.0 in stage 5.0 (TID 350)
09:20:56.748 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 141.0 in stage 5.0 (TID 347) in 16 ms on localhost (executor driver) (142/200)
09:20:56.748 INFO  [Executor task launch worker for task 348] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=142),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/142] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/142/2.delta
09:20:56.748 INFO  [Executor task launch worker for task 350] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=144), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/144] for update
09:20:56.748 INFO  [Executor task launch worker for task 350] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=144), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/144] for update
09:20:56.748 INFO  [Executor task launch worker for task 349] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=143),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/143] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/143/2.delta
09:20:56.748 INFO  [Executor task launch worker for task 348] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=142),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/142]
09:20:56.763 INFO  [Executor task launch worker for task 350] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.763 INFO  [Executor task launch worker for task 350] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.763 INFO  [Executor task launch worker for task 348] org.apache.spark.executor.Executor - Finished task 142.0 in stage 5.0 (TID 348). 3322 bytes result sent to driver
09:20:56.763 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 145.0 in stage 5.0 (TID 351, localhost, executor driver, partition 145, PROCESS_LOCAL, 4726 bytes)
09:20:56.763 INFO  [Executor task launch worker for task 351] org.apache.spark.executor.Executor - Running task 145.0 in stage 5.0 (TID 351)
09:20:56.763 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 142.0 in stage 5.0 (TID 348) in 31 ms on localhost (executor driver) (143/200)
09:20:56.763 INFO  [Executor task launch worker for task 351] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=145), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/145] for update
09:20:56.763 INFO  [Executor task launch worker for task 351] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=145), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/145] for update
09:20:56.763 INFO  [Executor task launch worker for task 351] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 2 blocks
09:20:56.763 INFO  [Executor task launch worker for task 351] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.763 INFO  [Executor task launch worker for task 349] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=143),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/143]
09:20:56.763 INFO  [Executor task launch worker for task 350] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=144),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/144] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/144/2.delta
09:20:56.763 INFO  [Executor task launch worker for task 349] org.apache.spark.executor.Executor - Finished task 143.0 in stage 5.0 (TID 349). 3322 bytes result sent to driver
09:20:56.763 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 146.0 in stage 5.0 (TID 352, localhost, executor driver, partition 146, PROCESS_LOCAL, 4726 bytes)
09:20:56.763 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 143.0 in stage 5.0 (TID 349) in 15 ms on localhost (executor driver) (144/200)
09:20:56.763 INFO  [Executor task launch worker for task 352] org.apache.spark.executor.Executor - Running task 146.0 in stage 5.0 (TID 352)
09:20:56.763 INFO  [Executor task launch worker for task 350] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=144),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/144]
09:20:56.763 INFO  [Executor task launch worker for task 352] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=146), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/146] for update
09:20:56.763 INFO  [Executor task launch worker for task 351] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=145),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/145] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/145/2.delta
09:20:56.779 INFO  [Executor task launch worker for task 352] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=146), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/146] for update
09:20:56.779 INFO  [Executor task launch worker for task 352] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.779 INFO  [Executor task launch worker for task 352] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.779 INFO  [Executor task launch worker for task 350] org.apache.spark.executor.Executor - Finished task 144.0 in stage 5.0 (TID 350). 3322 bytes result sent to driver
09:20:56.779 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 147.0 in stage 5.0 (TID 353, localhost, executor driver, partition 147, PROCESS_LOCAL, 4726 bytes)
09:20:56.779 INFO  [Executor task launch worker for task 353] org.apache.spark.executor.Executor - Running task 147.0 in stage 5.0 (TID 353)
09:20:56.779 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 144.0 in stage 5.0 (TID 350) in 31 ms on localhost (executor driver) (145/200)
09:20:56.779 INFO  [Executor task launch worker for task 353] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=147), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/147] for update
09:20:56.779 INFO  [Executor task launch worker for task 353] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=147), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/147] for update
09:20:56.779 INFO  [Executor task launch worker for task 353] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.779 INFO  [Executor task launch worker for task 353] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.779 INFO  [Executor task launch worker for task 351] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=145),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/145]
09:20:56.779 INFO  [Executor task launch worker for task 351] org.apache.spark.executor.Executor - Finished task 145.0 in stage 5.0 (TID 351). 3351 bytes result sent to driver
09:20:56.779 INFO  [Executor task launch worker for task 352] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=146),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/146] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/146/2.delta
09:20:56.779 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 148.0 in stage 5.0 (TID 354, localhost, executor driver, partition 148, PROCESS_LOCAL, 4726 bytes)
09:20:56.779 INFO  [Executor task launch worker for task 354] org.apache.spark.executor.Executor - Running task 148.0 in stage 5.0 (TID 354)
09:20:56.779 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 145.0 in stage 5.0 (TID 351) in 16 ms on localhost (executor driver) (146/200)
09:20:56.779 INFO  [Executor task launch worker for task 354] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=148), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/148] for update
09:20:56.779 INFO  [Executor task launch worker for task 352] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=146),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/146]
09:20:56.779 INFO  [Executor task launch worker for task 353] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=147),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/147] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/147/2.delta
09:20:56.795 INFO  [Executor task launch worker for task 354] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=148), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/148] for update
09:20:56.795 INFO  [Executor task launch worker for task 354] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.795 INFO  [Executor task launch worker for task 354] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.795 INFO  [Executor task launch worker for task 352] org.apache.spark.executor.Executor - Finished task 146.0 in stage 5.0 (TID 352). 3322 bytes result sent to driver
09:20:56.795 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 149.0 in stage 5.0 (TID 355, localhost, executor driver, partition 149, PROCESS_LOCAL, 4726 bytes)
09:20:56.795 INFO  [Executor task launch worker for task 355] org.apache.spark.executor.Executor - Running task 149.0 in stage 5.0 (TID 355)
09:20:56.795 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 146.0 in stage 5.0 (TID 352) in 32 ms on localhost (executor driver) (147/200)
09:20:56.795 INFO  [Executor task launch worker for task 355] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=149), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/149] for update
09:20:56.795 INFO  [Executor task launch worker for task 355] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=149), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/149] for update
09:20:56.795 INFO  [Executor task launch worker for task 355] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.795 INFO  [Executor task launch worker for task 355] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.795 INFO  [Executor task launch worker for task 353] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=147),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/147]
09:20:56.795 INFO  [Executor task launch worker for task 353] org.apache.spark.executor.Executor - Finished task 147.0 in stage 5.0 (TID 353). 3322 bytes result sent to driver
09:20:56.795 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 150.0 in stage 5.0 (TID 356, localhost, executor driver, partition 150, PROCESS_LOCAL, 4726 bytes)
09:20:56.795 INFO  [Executor task launch worker for task 356] org.apache.spark.executor.Executor - Running task 150.0 in stage 5.0 (TID 356)
09:20:56.795 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 147.0 in stage 5.0 (TID 353) in 16 ms on localhost (executor driver) (148/200)
09:20:56.795 INFO  [Executor task launch worker for task 354] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=148),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/148] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/148/2.delta
09:20:56.795 INFO  [Executor task launch worker for task 356] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=150), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/150] for update
09:20:56.810 INFO  [Executor task launch worker for task 356] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=150), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/150] for update
09:20:56.810 INFO  [Executor task launch worker for task 356] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.810 INFO  [Executor task launch worker for task 356] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.810 INFO  [Executor task launch worker for task 354] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=148),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/148]
09:20:56.810 INFO  [Executor task launch worker for task 354] org.apache.spark.executor.Executor - Finished task 148.0 in stage 5.0 (TID 354). 3365 bytes result sent to driver
09:20:56.810 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 151.0 in stage 5.0 (TID 357, localhost, executor driver, partition 151, PROCESS_LOCAL, 4726 bytes)
09:20:56.810 INFO  [Executor task launch worker for task 357] org.apache.spark.executor.Executor - Running task 151.0 in stage 5.0 (TID 357)
09:20:56.810 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 148.0 in stage 5.0 (TID 354) in 31 ms on localhost (executor driver) (149/200)
09:20:56.810 INFO  [Executor task launch worker for task 355] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=149),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/149] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/149/2.delta
09:20:56.810 INFO  [Executor task launch worker for task 356] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=150),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/150] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/150/2.delta
09:20:56.810 INFO  [Executor task launch worker for task 357] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=151), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/151] for update
09:20:56.810 INFO  [Executor task launch worker for task 357] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=151), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/151] for update
09:20:56.810 INFO  [Executor task launch worker for task 357] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 2 blocks
09:20:56.810 INFO  [Executor task launch worker for task 357] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.810 INFO  [Executor task launch worker for task 355] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=149),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/149]
09:20:56.826 INFO  [Executor task launch worker for task 356] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=150),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/150]
09:20:56.826 INFO  [Executor task launch worker for task 355] org.apache.spark.executor.Executor - Finished task 149.0 in stage 5.0 (TID 355). 3365 bytes result sent to driver
09:20:56.826 INFO  [Executor task launch worker for task 356] org.apache.spark.executor.Executor - Finished task 150.0 in stage 5.0 (TID 356). 3365 bytes result sent to driver
09:20:56.826 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 152.0 in stage 5.0 (TID 358, localhost, executor driver, partition 152, PROCESS_LOCAL, 4726 bytes)
09:20:56.826 INFO  [Executor task launch worker for task 358] org.apache.spark.executor.Executor - Running task 152.0 in stage 5.0 (TID 358)
09:20:56.826 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 149.0 in stage 5.0 (TID 355) in 31 ms on localhost (executor driver) (150/200)
09:20:56.826 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 153.0 in stage 5.0 (TID 359, localhost, executor driver, partition 153, PROCESS_LOCAL, 4726 bytes)
09:20:56.826 INFO  [Executor task launch worker for task 359] org.apache.spark.executor.Executor - Running task 153.0 in stage 5.0 (TID 359)
09:20:56.826 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 150.0 in stage 5.0 (TID 356) in 31 ms on localhost (executor driver) (151/200)
09:20:56.826 INFO  [Executor task launch worker for task 358] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=152), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/152] for update
09:20:56.826 INFO  [Executor task launch worker for task 358] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=152), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/152] for update
09:20:56.826 INFO  [Executor task launch worker for task 359] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=153), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/153] for update
09:20:56.826 INFO  [Executor task launch worker for task 359] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=153), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/153] for update
09:20:56.826 INFO  [Executor task launch worker for task 358] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.826 INFO  [Executor task launch worker for task 359] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.826 INFO  [Executor task launch worker for task 358] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.826 INFO  [Executor task launch worker for task 359] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.826 INFO  [Executor task launch worker for task 357] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=151),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/151] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/151/2.delta
09:20:56.826 INFO  [Executor task launch worker for task 358] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=152),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/152] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/152/2.delta
09:20:56.842 INFO  [Executor task launch worker for task 357] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=151),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/151]
09:20:56.842 INFO  [Executor task launch worker for task 357] org.apache.spark.executor.Executor - Finished task 151.0 in stage 5.0 (TID 357). 3394 bytes result sent to driver
09:20:56.842 INFO  [Executor task launch worker for task 358] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=152),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/152]
09:20:56.842 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 154.0 in stage 5.0 (TID 360, localhost, executor driver, partition 154, PROCESS_LOCAL, 4726 bytes)
09:20:56.842 INFO  [Executor task launch worker for task 358] org.apache.spark.executor.Executor - Finished task 152.0 in stage 5.0 (TID 358). 3322 bytes result sent to driver
09:20:56.842 INFO  [Executor task launch worker for task 360] org.apache.spark.executor.Executor - Running task 154.0 in stage 5.0 (TID 360)
09:20:56.842 INFO  [Executor task launch worker for task 359] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=153),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/153] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/153/2.delta
09:20:56.842 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 155.0 in stage 5.0 (TID 361, localhost, executor driver, partition 155, PROCESS_LOCAL, 4726 bytes)
09:20:56.842 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 151.0 in stage 5.0 (TID 357) in 32 ms on localhost (executor driver) (152/200)
09:20:56.842 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 152.0 in stage 5.0 (TID 358) in 16 ms on localhost (executor driver) (153/200)
09:20:56.842 INFO  [Executor task launch worker for task 360] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=154), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/154] for update
09:20:56.842 INFO  [Executor task launch worker for task 360] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=154), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/154] for update
09:20:56.842 INFO  [Executor task launch worker for task 361] org.apache.spark.executor.Executor - Running task 155.0 in stage 5.0 (TID 361)
09:20:56.842 INFO  [Executor task launch worker for task 359] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=153),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/153]
09:20:56.857 INFO  [Executor task launch worker for task 360] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.857 INFO  [Executor task launch worker for task 360] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.857 INFO  [Executor task launch worker for task 359] org.apache.spark.executor.Executor - Finished task 153.0 in stage 5.0 (TID 359). 3322 bytes result sent to driver
09:20:56.857 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 156.0 in stage 5.0 (TID 362, localhost, executor driver, partition 156, PROCESS_LOCAL, 4726 bytes)
09:20:56.857 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 153.0 in stage 5.0 (TID 359) in 31 ms on localhost (executor driver) (154/200)
09:20:56.857 INFO  [Executor task launch worker for task 362] org.apache.spark.executor.Executor - Running task 156.0 in stage 5.0 (TID 362)
09:20:56.857 INFO  [Executor task launch worker for task 361] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=155), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/155] for update
09:20:56.857 INFO  [Executor task launch worker for task 361] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=155), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/155] for update
09:20:56.857 INFO  [Executor task launch worker for task 361] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.857 INFO  [Executor task launch worker for task 361] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.857 INFO  [Executor task launch worker for task 362] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=156), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/156] for update
09:20:56.857 INFO  [Executor task launch worker for task 362] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=156), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/156] for update
09:20:56.857 INFO  [Executor task launch worker for task 362] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.857 INFO  [Executor task launch worker for task 362] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.857 INFO  [Executor task launch worker for task 360] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=154),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/154] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/154/2.delta
09:20:56.857 INFO  [Executor task launch worker for task 361] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=155),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/155] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/155/2.delta
09:20:56.857 INFO  [Executor task launch worker for task 360] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=154),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/154]
09:20:56.857 INFO  [Executor task launch worker for task 362] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=156),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/156] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/156/2.delta
09:20:56.873 INFO  [Executor task launch worker for task 360] org.apache.spark.executor.Executor - Finished task 154.0 in stage 5.0 (TID 360). 3322 bytes result sent to driver
09:20:56.873 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 157.0 in stage 5.0 (TID 363, localhost, executor driver, partition 157, PROCESS_LOCAL, 4726 bytes)
09:20:56.873 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 154.0 in stage 5.0 (TID 360) in 31 ms on localhost (executor driver) (155/200)
09:20:56.873 INFO  [Executor task launch worker for task 363] org.apache.spark.executor.Executor - Running task 157.0 in stage 5.0 (TID 363)
09:20:56.873 INFO  [Executor task launch worker for task 361] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=155),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/155]
09:20:56.873 INFO  [Executor task launch worker for task 363] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=157), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/157] for update
09:20:56.873 INFO  [Executor task launch worker for task 361] org.apache.spark.executor.Executor - Finished task 155.0 in stage 5.0 (TID 361). 3365 bytes result sent to driver
09:20:56.873 INFO  [Executor task launch worker for task 363] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=157), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/157] for update
09:20:56.873 INFO  [Executor task launch worker for task 363] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.873 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 158.0 in stage 5.0 (TID 364, localhost, executor driver, partition 158, PROCESS_LOCAL, 4726 bytes)
09:20:56.873 INFO  [Executor task launch worker for task 363] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.873 INFO  [Executor task launch worker for task 364] org.apache.spark.executor.Executor - Running task 158.0 in stage 5.0 (TID 364)
09:20:56.873 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 155.0 in stage 5.0 (TID 361) in 31 ms on localhost (executor driver) (156/200)
09:20:56.873 INFO  [Executor task launch worker for task 364] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=158), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/158] for update
09:20:56.873 INFO  [Executor task launch worker for task 362] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=156),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/156]
09:20:56.888 INFO  [Executor task launch worker for task 364] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=158), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/158] for update
09:20:56.873 INFO  [Executor task launch worker for task 363] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=157),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/157] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/157/2.delta
09:20:56.888 INFO  [Executor task launch worker for task 364] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.888 INFO  [Executor task launch worker for task 362] org.apache.spark.executor.Executor - Finished task 156.0 in stage 5.0 (TID 362). 3351 bytes result sent to driver
09:20:56.888 INFO  [Executor task launch worker for task 364] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.888 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 159.0 in stage 5.0 (TID 365, localhost, executor driver, partition 159, PROCESS_LOCAL, 4726 bytes)
09:20:56.888 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 156.0 in stage 5.0 (TID 362) in 31 ms on localhost (executor driver) (157/200)
09:20:56.888 INFO  [Executor task launch worker for task 365] org.apache.spark.executor.Executor - Running task 159.0 in stage 5.0 (TID 365)
09:20:56.888 INFO  [Executor task launch worker for task 363] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=157),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/157]
09:20:56.888 INFO  [Executor task launch worker for task 363] org.apache.spark.executor.Executor - Finished task 157.0 in stage 5.0 (TID 363). 3322 bytes result sent to driver
09:20:56.888 INFO  [Executor task launch worker for task 364] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=158),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/158] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/158/2.delta
09:20:56.888 INFO  [Executor task launch worker for task 365] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=159), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/159] for update
09:20:56.888 INFO  [Executor task launch worker for task 365] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=159), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/159] for update
09:20:56.888 INFO  [Executor task launch worker for task 365] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.888 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 160.0 in stage 5.0 (TID 366, localhost, executor driver, partition 160, PROCESS_LOCAL, 4726 bytes)
09:20:56.888 INFO  [Executor task launch worker for task 364] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=158),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/158]
09:20:56.904 INFO  [Executor task launch worker for task 365] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 16 ms
09:20:56.904 INFO  [Executor task launch worker for task 366] org.apache.spark.executor.Executor - Running task 160.0 in stage 5.0 (TID 366)
09:20:56.904 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 157.0 in stage 5.0 (TID 363) in 31 ms on localhost (executor driver) (158/200)
09:20:56.904 INFO  [Executor task launch worker for task 364] org.apache.spark.executor.Executor - Finished task 158.0 in stage 5.0 (TID 364). 3322 bytes result sent to driver
09:20:56.904 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 161.0 in stage 5.0 (TID 367, localhost, executor driver, partition 161, PROCESS_LOCAL, 4726 bytes)
09:20:56.904 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 158.0 in stage 5.0 (TID 364) in 31 ms on localhost (executor driver) (159/200)
09:20:56.904 INFO  [Executor task launch worker for task 367] org.apache.spark.executor.Executor - Running task 161.0 in stage 5.0 (TID 367)
09:20:56.904 INFO  [Executor task launch worker for task 366] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=160), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/160] for update
09:20:56.904 INFO  [Executor task launch worker for task 366] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=160), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/160] for update
09:20:56.904 INFO  [Executor task launch worker for task 366] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.904 INFO  [Executor task launch worker for task 366] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.904 INFO  [Executor task launch worker for task 367] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=161), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/161] for update
09:20:56.904 INFO  [Executor task launch worker for task 367] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=161), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/161] for update
09:20:56.904 INFO  [Executor task launch worker for task 367] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.904 INFO  [Executor task launch worker for task 367] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.904 INFO  [Executor task launch worker for task 365] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=159),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/159] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/159/2.delta
09:20:56.904 INFO  [Executor task launch worker for task 365] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=159),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/159]
09:20:56.920 INFO  [Executor task launch worker for task 365] org.apache.spark.executor.Executor - Finished task 159.0 in stage 5.0 (TID 365). 3322 bytes result sent to driver
09:20:56.920 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 162.0 in stage 5.0 (TID 368, localhost, executor driver, partition 162, PROCESS_LOCAL, 4726 bytes)
09:20:56.920 INFO  [Executor task launch worker for task 368] org.apache.spark.executor.Executor - Running task 162.0 in stage 5.0 (TID 368)
09:20:56.920 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 159.0 in stage 5.0 (TID 365) in 32 ms on localhost (executor driver) (160/200)
09:20:56.920 INFO  [Executor task launch worker for task 366] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=160),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/160] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/160/2.delta
09:20:56.920 INFO  [Executor task launch worker for task 368] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=162), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/162] for update
09:20:56.920 INFO  [Executor task launch worker for task 368] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=162), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/162] for update
09:20:56.920 INFO  [Executor task launch worker for task 368] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.920 INFO  [Executor task launch worker for task 368] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.920 INFO  [Executor task launch worker for task 367] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=161),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/161] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/161/2.delta
09:20:56.920 INFO  [Executor task launch worker for task 368] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=162),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/162] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/162/2.delta
09:20:56.920 INFO  [Executor task launch worker for task 367] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=161),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/161]
09:20:56.920 INFO  [Executor task launch worker for task 367] org.apache.spark.executor.Executor - Finished task 161.0 in stage 5.0 (TID 367). 3365 bytes result sent to driver
09:20:56.920 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 163.0 in stage 5.0 (TID 369, localhost, executor driver, partition 163, PROCESS_LOCAL, 4726 bytes)
09:20:56.920 INFO  [Executor task launch worker for task 369] org.apache.spark.executor.Executor - Running task 163.0 in stage 5.0 (TID 369)
09:20:56.920 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 161.0 in stage 5.0 (TID 367) in 16 ms on localhost (executor driver) (161/200)
09:20:56.920 INFO  [Executor task launch worker for task 366] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=160),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/160]
09:20:56.920 INFO  [Executor task launch worker for task 368] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=162),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/162]
09:20:56.935 INFO  [Executor task launch worker for task 366] org.apache.spark.executor.Executor - Finished task 160.0 in stage 5.0 (TID 366). 3365 bytes result sent to driver
09:20:56.935 INFO  [Executor task launch worker for task 368] org.apache.spark.executor.Executor - Finished task 162.0 in stage 5.0 (TID 368). 3322 bytes result sent to driver
09:20:56.935 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 164.0 in stage 5.0 (TID 370, localhost, executor driver, partition 164, PROCESS_LOCAL, 4726 bytes)
09:20:56.935 INFO  [Executor task launch worker for task 370] org.apache.spark.executor.Executor - Running task 164.0 in stage 5.0 (TID 370)
09:20:56.935 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 165.0 in stage 5.0 (TID 371, localhost, executor driver, partition 165, PROCESS_LOCAL, 4726 bytes)
09:20:56.935 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 160.0 in stage 5.0 (TID 366) in 47 ms on localhost (executor driver) (162/200)
09:20:56.935 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 162.0 in stage 5.0 (TID 368) in 15 ms on localhost (executor driver) (163/200)
09:20:56.935 INFO  [Executor task launch worker for task 371] org.apache.spark.executor.Executor - Running task 165.0 in stage 5.0 (TID 371)
09:20:56.935 INFO  [Executor task launch worker for task 370] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=164), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/164] for update
09:20:56.935 INFO  [Executor task launch worker for task 369] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=163), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/163] for update
09:20:56.935 INFO  [Executor task launch worker for task 371] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=165), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/165] for update
09:20:56.935 INFO  [Executor task launch worker for task 370] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=164), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/164] for update
09:20:56.935 INFO  [Executor task launch worker for task 369] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=163), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/163] for update
09:20:56.935 INFO  [Executor task launch worker for task 371] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=165), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/165] for update
09:20:56.935 INFO  [Executor task launch worker for task 370] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.951 INFO  [Executor task launch worker for task 370] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 16 ms
09:20:56.951 INFO  [Executor task launch worker for task 369] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.951 INFO  [Executor task launch worker for task 371] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.951 INFO  [Executor task launch worker for task 369] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.951 INFO  [Executor task launch worker for task 371] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.951 INFO  [Executor task launch worker for task 369] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=163),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/163] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/163/2.delta
09:20:56.951 INFO  [Executor task launch worker for task 371] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=165),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/165] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/165/2.delta
09:20:56.951 INFO  [Executor task launch worker for task 369] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=163),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/163]
09:20:56.951 INFO  [Executor task launch worker for task 369] org.apache.spark.executor.Executor - Finished task 163.0 in stage 5.0 (TID 369). 3365 bytes result sent to driver
09:20:56.951 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 166.0 in stage 5.0 (TID 372, localhost, executor driver, partition 166, PROCESS_LOCAL, 4726 bytes)
09:20:56.951 INFO  [Executor task launch worker for task 372] org.apache.spark.executor.Executor - Running task 166.0 in stage 5.0 (TID 372)
09:20:56.951 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 163.0 in stage 5.0 (TID 369) in 31 ms on localhost (executor driver) (164/200)
09:20:56.951 INFO  [Executor task launch worker for task 372] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=166), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/166] for update
09:20:56.951 INFO  [Executor task launch worker for task 371] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=165),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/165]
09:20:56.951 INFO  [Executor task launch worker for task 372] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=166), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/166] for update
09:20:56.951 INFO  [Executor task launch worker for task 370] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=164),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/164] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/164/2.delta
09:20:56.967 INFO  [Executor task launch worker for task 372] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.967 INFO  [Executor task launch worker for task 371] org.apache.spark.executor.Executor - Finished task 165.0 in stage 5.0 (TID 371). 3322 bytes result sent to driver
09:20:56.967 INFO  [Executor task launch worker for task 372] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.967 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 167.0 in stage 5.0 (TID 373, localhost, executor driver, partition 167, PROCESS_LOCAL, 4726 bytes)
09:20:56.967 INFO  [Executor task launch worker for task 373] org.apache.spark.executor.Executor - Running task 167.0 in stage 5.0 (TID 373)
09:20:56.967 INFO  [Executor task launch worker for task 373] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=167), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/167] for update
09:20:56.967 INFO  [Executor task launch worker for task 373] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=167), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/167] for update
09:20:56.967 INFO  [Executor task launch worker for task 370] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=164),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/164]
09:20:56.967 INFO  [Executor task launch worker for task 373] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.967 INFO  [Executor task launch worker for task 373] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.967 INFO  [Executor task launch worker for task 370] org.apache.spark.executor.Executor - Finished task 164.0 in stage 5.0 (TID 370). 3322 bytes result sent to driver
09:20:56.967 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 165.0 in stage 5.0 (TID 371) in 32 ms on localhost (executor driver) (165/200)
09:20:56.967 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 168.0 in stage 5.0 (TID 374, localhost, executor driver, partition 168, PROCESS_LOCAL, 4726 bytes)
09:20:56.967 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 164.0 in stage 5.0 (TID 370) in 32 ms on localhost (executor driver) (166/200)
09:20:56.967 INFO  [Executor task launch worker for task 374] org.apache.spark.executor.Executor - Running task 168.0 in stage 5.0 (TID 374)
09:20:56.967 INFO  [Executor task launch worker for task 373] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=167),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/167] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/167/2.delta
09:20:56.967 INFO  [Executor task launch worker for task 372] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=166),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/166] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/166/2.delta
09:20:56.982 INFO  [Executor task launch worker for task 374] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=168), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/168] for update
09:20:56.982 INFO  [Executor task launch worker for task 374] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=168), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/168] for update
09:20:56.982 INFO  [Executor task launch worker for task 374] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.982 INFO  [Executor task launch worker for task 374] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.982 INFO  [Executor task launch worker for task 372] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=166),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/166]
09:20:56.982 INFO  [Executor task launch worker for task 372] org.apache.spark.executor.Executor - Finished task 166.0 in stage 5.0 (TID 372). 3322 bytes result sent to driver
09:20:56.982 INFO  [Executor task launch worker for task 373] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=167),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/167]
09:20:56.982 INFO  [Executor task launch worker for task 374] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=168),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/168] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/168/2.delta
09:20:56.982 INFO  [Executor task launch worker for task 373] org.apache.spark.executor.Executor - Finished task 167.0 in stage 5.0 (TID 373). 3322 bytes result sent to driver
09:20:56.982 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 169.0 in stage 5.0 (TID 375, localhost, executor driver, partition 169, PROCESS_LOCAL, 4726 bytes)
09:20:56.982 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 170.0 in stage 5.0 (TID 376, localhost, executor driver, partition 170, PROCESS_LOCAL, 4726 bytes)
09:20:56.982 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 166.0 in stage 5.0 (TID 372) in 31 ms on localhost (executor driver) (167/200)
09:20:56.982 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 167.0 in stage 5.0 (TID 373) in 15 ms on localhost (executor driver) (168/200)
09:20:56.982 INFO  [Executor task launch worker for task 376] org.apache.spark.executor.Executor - Running task 170.0 in stage 5.0 (TID 376)
09:20:56.982 INFO  [Executor task launch worker for task 375] org.apache.spark.executor.Executor - Running task 169.0 in stage 5.0 (TID 375)
09:20:56.982 INFO  [Executor task launch worker for task 374] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=168),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/168]
09:20:56.982 INFO  [Executor task launch worker for task 376] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=170), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/170] for update
09:20:56.998 INFO  [Executor task launch worker for task 376] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=170), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/170] for update
09:20:56.998 INFO  [Executor task launch worker for task 376] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.998 INFO  [Executor task launch worker for task 374] org.apache.spark.executor.Executor - Finished task 168.0 in stage 5.0 (TID 374). 3365 bytes result sent to driver
09:20:56.998 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 171.0 in stage 5.0 (TID 377, localhost, executor driver, partition 171, PROCESS_LOCAL, 4726 bytes)
09:20:56.998 INFO  [Executor task launch worker for task 377] org.apache.spark.executor.Executor - Running task 171.0 in stage 5.0 (TID 377)
09:20:56.998 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 168.0 in stage 5.0 (TID 374) in 31 ms on localhost (executor driver) (169/200)
09:20:56.998 INFO  [Executor task launch worker for task 377] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=171), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/171] for update
09:20:56.998 INFO  [Executor task launch worker for task 377] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=171), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/171] for update
09:20:56.998 INFO  [Executor task launch worker for task 377] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.998 INFO  [Executor task launch worker for task 377] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.998 INFO  [Executor task launch worker for task 376] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.998 INFO  [Executor task launch worker for task 375] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=169), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/169] for update
09:20:56.998 INFO  [Executor task launch worker for task 375] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=169), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/169] for update
09:20:56.998 INFO  [Executor task launch worker for task 375] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:56.998 INFO  [Executor task launch worker for task 375] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:56.998 INFO  [Executor task launch worker for task 375] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=169),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/169] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/169/2.delta
09:20:57.013 INFO  [Executor task launch worker for task 375] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=169),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/169]
09:20:57.013 INFO  [Executor task launch worker for task 375] org.apache.spark.executor.Executor - Finished task 169.0 in stage 5.0 (TID 375). 3365 bytes result sent to driver
09:20:57.013 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 172.0 in stage 5.0 (TID 378, localhost, executor driver, partition 172, PROCESS_LOCAL, 4726 bytes)
09:20:57.013 INFO  [Executor task launch worker for task 378] org.apache.spark.executor.Executor - Running task 172.0 in stage 5.0 (TID 378)
09:20:57.013 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 169.0 in stage 5.0 (TID 375) in 31 ms on localhost (executor driver) (170/200)
09:20:57.013 INFO  [Executor task launch worker for task 378] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=172), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/172] for update
09:20:57.013 INFO  [Executor task launch worker for task 378] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=172), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/172] for update
09:20:57.013 INFO  [Executor task launch worker for task 378] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:57.013 INFO  [Executor task launch worker for task 378] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:57.013 INFO  [Executor task launch worker for task 376] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=170),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/170] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/170/2.delta
09:20:57.029 INFO  [Executor task launch worker for task 377] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=171),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/171] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/171/2.delta
09:20:57.029 INFO  [Executor task launch worker for task 378] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=172),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/172] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/172/2.delta
09:20:57.029 INFO  [Executor task launch worker for task 378] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=172),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/172]
09:20:57.029 INFO  [Executor task launch worker for task 378] org.apache.spark.executor.Executor - Finished task 172.0 in stage 5.0 (TID 378). 3365 bytes result sent to driver
09:20:57.029 INFO  [Executor task launch worker for task 377] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=171),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/171]
09:20:57.029 INFO  [Executor task launch worker for task 377] org.apache.spark.executor.Executor - Finished task 171.0 in stage 5.0 (TID 377). 3322 bytes result sent to driver
09:20:57.029 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 173.0 in stage 5.0 (TID 379, localhost, executor driver, partition 173, PROCESS_LOCAL, 4726 bytes)
09:20:57.029 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 174.0 in stage 5.0 (TID 380, localhost, executor driver, partition 174, PROCESS_LOCAL, 4726 bytes)
09:20:57.029 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 172.0 in stage 5.0 (TID 378) in 16 ms on localhost (executor driver) (171/200)
09:20:57.029 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 171.0 in stage 5.0 (TID 377) in 31 ms on localhost (executor driver) (172/200)
09:20:57.029 INFO  [Executor task launch worker for task 379] org.apache.spark.executor.Executor - Running task 173.0 in stage 5.0 (TID 379)
09:20:57.029 INFO  [Executor task launch worker for task 380] org.apache.spark.executor.Executor - Running task 174.0 in stage 5.0 (TID 380)
09:20:57.045 INFO  [Executor task launch worker for task 380] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=174), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/174] for update
09:20:57.045 INFO  [Executor task launch worker for task 380] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=174), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/174] for update
09:20:57.045 INFO  [Executor task launch worker for task 380] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:57.045 INFO  [Executor task launch worker for task 380] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:57.045 INFO  [Executor task launch worker for task 376] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=170),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/170]
09:20:57.045 INFO  [Executor task launch worker for task 376] org.apache.spark.executor.Executor - Finished task 170.0 in stage 5.0 (TID 376). 3365 bytes result sent to driver
09:20:57.045 INFO  [Executor task launch worker for task 379] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=173), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/173] for update
09:20:57.045 INFO  [Executor task launch worker for task 379] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=173), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/173] for update
09:20:57.045 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 175.0 in stage 5.0 (TID 381, localhost, executor driver, partition 175, PROCESS_LOCAL, 4726 bytes)
09:20:57.045 INFO  [Executor task launch worker for task 379] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:57.045 INFO  [Executor task launch worker for task 379] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:57.045 INFO  [Executor task launch worker for task 381] org.apache.spark.executor.Executor - Running task 175.0 in stage 5.0 (TID 381)
09:20:57.045 INFO  [Executor task launch worker for task 381] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=175), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/175] for update
09:20:57.045 INFO  [Executor task launch worker for task 381] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=175), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/175] for update
09:20:57.045 INFO  [Executor task launch worker for task 381] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:57.045 INFO  [Executor task launch worker for task 381] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:57.045 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 170.0 in stage 5.0 (TID 376) in 63 ms on localhost (executor driver) (173/200)
09:20:57.045 INFO  [Executor task launch worker for task 380] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=174),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/174] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/174/2.delta
09:20:57.060 INFO  [Executor task launch worker for task 379] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=173),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/173] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/173/2.delta
09:20:57.060 INFO  [Executor task launch worker for task 381] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=175),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/175] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/175/2.delta
09:20:57.060 INFO  [Executor task launch worker for task 381] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=175),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/175]
09:20:57.060 INFO  [Executor task launch worker for task 381] org.apache.spark.executor.Executor - Finished task 175.0 in stage 5.0 (TID 381). 3322 bytes result sent to driver
09:20:57.076 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 176.0 in stage 5.0 (TID 382, localhost, executor driver, partition 176, PROCESS_LOCAL, 4726 bytes)
09:20:57.076 INFO  [Executor task launch worker for task 382] org.apache.spark.executor.Executor - Running task 176.0 in stage 5.0 (TID 382)
09:20:57.076 INFO  [Executor task launch worker for task 380] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=174),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/174]
09:20:57.076 INFO  [Executor task launch worker for task 380] org.apache.spark.executor.Executor - Finished task 174.0 in stage 5.0 (TID 380). 3408 bytes result sent to driver
09:20:57.076 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 175.0 in stage 5.0 (TID 381) in 31 ms on localhost (executor driver) (174/200)
09:20:57.076 INFO  [Executor task launch worker for task 382] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=176), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/176] for update
09:20:57.076 INFO  [Executor task launch worker for task 382] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=176), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/176] for update
09:20:57.076 INFO  [Executor task launch worker for task 382] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:57.076 INFO  [Executor task launch worker for task 382] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:57.076 INFO  [Executor task launch worker for task 379] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=173),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/173]
09:20:57.076 INFO  [Executor task launch worker for task 379] org.apache.spark.executor.Executor - Finished task 173.0 in stage 5.0 (TID 379). 3408 bytes result sent to driver
09:20:57.076 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 177.0 in stage 5.0 (TID 383, localhost, executor driver, partition 177, PROCESS_LOCAL, 4726 bytes)
09:20:57.076 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 174.0 in stage 5.0 (TID 380) in 47 ms on localhost (executor driver) (175/200)
09:20:57.076 INFO  [Executor task launch worker for task 382] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=176),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/176] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/176/2.delta
09:20:57.092 INFO  [Executor task launch worker for task 382] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=176),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/176]
09:20:57.092 INFO  [Executor task launch worker for task 382] org.apache.spark.executor.Executor - Finished task 176.0 in stage 5.0 (TID 382). 3322 bytes result sent to driver
09:20:57.092 INFO  [Executor task launch worker for task 383] org.apache.spark.executor.Executor - Running task 177.0 in stage 5.0 (TID 383)
09:20:57.092 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 178.0 in stage 5.0 (TID 384, localhost, executor driver, partition 178, PROCESS_LOCAL, 4726 bytes)
09:20:57.092 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 179.0 in stage 5.0 (TID 385, localhost, executor driver, partition 179, PROCESS_LOCAL, 4726 bytes)
09:20:57.092 INFO  [Executor task launch worker for task 383] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=177), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/177] for update
09:20:57.092 INFO  [Executor task launch worker for task 383] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=177), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/177] for update
09:20:57.092 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 173.0 in stage 5.0 (TID 379) in 63 ms on localhost (executor driver) (176/200)
09:20:57.092 INFO  [Executor task launch worker for task 383] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:57.092 INFO  [Executor task launch worker for task 383] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:57.092 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 176.0 in stage 5.0 (TID 382) in 16 ms on localhost (executor driver) (177/200)
09:20:57.092 INFO  [Executor task launch worker for task 384] org.apache.spark.executor.Executor - Running task 178.0 in stage 5.0 (TID 384)
09:20:57.092 INFO  [Executor task launch worker for task 384] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=178), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/178] for update
09:20:57.092 INFO  [Executor task launch worker for task 384] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=178), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/178] for update
09:20:57.092 INFO  [Executor task launch worker for task 384] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:57.092 INFO  [Executor task launch worker for task 384] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:57.107 INFO  [Executor task launch worker for task 385] org.apache.spark.executor.Executor - Running task 179.0 in stage 5.0 (TID 385)
09:20:57.107 INFO  [Executor task launch worker for task 385] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=179), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/179] for update
09:20:57.107 INFO  [Executor task launch worker for task 385] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=179), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/179] for update
09:20:57.107 INFO  [Executor task launch worker for task 385] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:57.107 INFO  [Executor task launch worker for task 385] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:57.107 INFO  [Executor task launch worker for task 383] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=177),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/177] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/177/2.delta
09:20:57.107 INFO  [Executor task launch worker for task 384] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=178),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/178] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/178/2.delta
09:20:57.107 INFO  [Executor task launch worker for task 385] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=179),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/179] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/179/2.delta
09:20:57.107 INFO  [Executor task launch worker for task 383] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=177),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/177]
09:20:57.107 INFO  [Executor task launch worker for task 383] org.apache.spark.executor.Executor - Finished task 177.0 in stage 5.0 (TID 383). 3365 bytes result sent to driver
09:20:57.107 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 180.0 in stage 5.0 (TID 386, localhost, executor driver, partition 180, PROCESS_LOCAL, 4726 bytes)
09:20:57.107 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 177.0 in stage 5.0 (TID 383) in 31 ms on localhost (executor driver) (178/200)
09:20:57.107 INFO  [Executor task launch worker for task 386] org.apache.spark.executor.Executor - Running task 180.0 in stage 5.0 (TID 386)
09:20:57.107 INFO  [Executor task launch worker for task 386] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=180), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/180] for update
09:20:57.107 INFO  [Executor task launch worker for task 386] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=180), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/180] for update
09:20:57.123 INFO  [Executor task launch worker for task 386] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:57.123 INFO  [Executor task launch worker for task 386] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:57.123 INFO  [Executor task launch worker for task 385] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=179),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/179]
09:20:57.123 INFO  [Executor task launch worker for task 386] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=180),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/180] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/180/2.delta
09:20:57.123 INFO  [Executor task launch worker for task 385] org.apache.spark.executor.Executor - Finished task 179.0 in stage 5.0 (TID 385). 3322 bytes result sent to driver
09:20:57.123 INFO  [Executor task launch worker for task 384] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=178),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/178]
09:20:57.123 INFO  [Executor task launch worker for task 384] org.apache.spark.executor.Executor - Finished task 178.0 in stage 5.0 (TID 384). 3322 bytes result sent to driver
09:20:57.123 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 181.0 in stage 5.0 (TID 387, localhost, executor driver, partition 181, PROCESS_LOCAL, 4726 bytes)
09:20:57.123 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 182.0 in stage 5.0 (TID 388, localhost, executor driver, partition 182, PROCESS_LOCAL, 4726 bytes)
09:20:57.123 INFO  [Executor task launch worker for task 388] org.apache.spark.executor.Executor - Running task 182.0 in stage 5.0 (TID 388)
09:20:57.123 INFO  [Executor task launch worker for task 386] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=180),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/180]
09:20:57.123 INFO  [Executor task launch worker for task 386] org.apache.spark.executor.Executor - Finished task 180.0 in stage 5.0 (TID 386). 3322 bytes result sent to driver
09:20:57.123 INFO  [Executor task launch worker for task 388] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=182), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/182] for update
09:20:57.123 INFO  [Executor task launch worker for task 388] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=182), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/182] for update
09:20:57.123 INFO  [Executor task launch worker for task 388] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:57.123 INFO  [Executor task launch worker for task 388] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:57.123 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 179.0 in stage 5.0 (TID 385) in 31 ms on localhost (executor driver) (179/200)
09:20:57.123 INFO  [Executor task launch worker for task 387] org.apache.spark.executor.Executor - Running task 181.0 in stage 5.0 (TID 387)
09:20:57.154 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 183.0 in stage 5.0 (TID 389, localhost, executor driver, partition 183, PROCESS_LOCAL, 4726 bytes)
09:20:57.154 INFO  [Executor task launch worker for task 387] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=181), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/181] for update
09:20:57.154 INFO  [Executor task launch worker for task 387] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=181), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/181] for update
09:20:57.154 INFO  [Executor task launch worker for task 387] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:57.154 INFO  [Executor task launch worker for task 387] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:57.154 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 180.0 in stage 5.0 (TID 386) in 47 ms on localhost (executor driver) (180/200)
09:20:57.154 INFO  [Executor task launch worker for task 389] org.apache.spark.executor.Executor - Running task 183.0 in stage 5.0 (TID 389)
09:20:57.154 INFO  [Executor task launch worker for task 389] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=183), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/183] for update
09:20:57.154 INFO  [Executor task launch worker for task 389] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=183), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/183] for update
09:20:57.170 INFO  [Executor task launch worker for task 389] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:57.170 INFO  [Executor task launch worker for task 389] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:57.170 INFO  [Executor task launch worker for task 389] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=183),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/183] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/183/2.delta
09:20:57.170 INFO  [Executor task launch worker for task 388] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=182),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/182] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/182/2.delta
09:20:57.185 INFO  [Executor task launch worker for task 389] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=183),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/183]
09:20:57.185 INFO  [Executor task launch worker for task 389] org.apache.spark.executor.Executor - Finished task 183.0 in stage 5.0 (TID 389). 3365 bytes result sent to driver
09:20:57.185 INFO  [Executor task launch worker for task 388] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=182),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/182]
09:20:57.185 INFO  [Executor task launch worker for task 388] org.apache.spark.executor.Executor - Finished task 182.0 in stage 5.0 (TID 388). 3365 bytes result sent to driver
09:20:57.185 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 178.0 in stage 5.0 (TID 384) in 93 ms on localhost (executor driver) (181/200)
09:20:57.185 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 184.0 in stage 5.0 (TID 390, localhost, executor driver, partition 184, PROCESS_LOCAL, 4726 bytes)
09:20:57.185 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 185.0 in stage 5.0 (TID 391, localhost, executor driver, partition 185, PROCESS_LOCAL, 4726 bytes)
09:20:57.185 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 183.0 in stage 5.0 (TID 389) in 31 ms on localhost (executor driver) (182/200)
09:20:57.185 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 182.0 in stage 5.0 (TID 388) in 62 ms on localhost (executor driver) (183/200)
09:20:57.185 INFO  [Executor task launch worker for task 390] org.apache.spark.executor.Executor - Running task 184.0 in stage 5.0 (TID 390)
09:20:57.185 INFO  [Executor task launch worker for task 391] org.apache.spark.executor.Executor - Running task 185.0 in stage 5.0 (TID 391)
09:20:57.185 INFO  [Executor task launch worker for task 390] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=184), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/184] for update
09:20:57.185 INFO  [Executor task launch worker for task 390] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=184), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/184] for update
09:20:57.185 INFO  [Executor task launch worker for task 390] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:57.185 INFO  [Executor task launch worker for task 390] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:57.185 INFO  [Executor task launch worker for task 387] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=181),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/181] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/181/2.delta
09:20:57.185 INFO  [Executor task launch worker for task 391] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=185), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/185] for update
09:20:57.185 INFO  [Executor task launch worker for task 391] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=185), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/185] for update
09:20:57.201 INFO  [Executor task launch worker for task 391] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:57.201 INFO  [Executor task launch worker for task 391] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:57.201 INFO  [Executor task launch worker for task 391] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=185),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/185] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/185/2.delta
09:20:57.201 INFO  [Executor task launch worker for task 390] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=184),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/184] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/184/2.delta
09:20:57.201 INFO  [Executor task launch worker for task 391] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=185),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/185]
09:20:57.201 INFO  [Executor task launch worker for task 391] org.apache.spark.executor.Executor - Finished task 185.0 in stage 5.0 (TID 391). 3322 bytes result sent to driver
09:20:57.201 INFO  [Executor task launch worker for task 390] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=184),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/184]
09:20:57.201 INFO  [Executor task launch worker for task 390] org.apache.spark.executor.Executor - Finished task 184.0 in stage 5.0 (TID 390). 3322 bytes result sent to driver
09:20:57.201 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 186.0 in stage 5.0 (TID 392, localhost, executor driver, partition 186, PROCESS_LOCAL, 4726 bytes)
09:20:57.201 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 187.0 in stage 5.0 (TID 393, localhost, executor driver, partition 187, PROCESS_LOCAL, 4726 bytes)
09:20:57.201 INFO  [Executor task launch worker for task 393] org.apache.spark.executor.Executor - Running task 187.0 in stage 5.0 (TID 393)
09:20:57.201 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 185.0 in stage 5.0 (TID 391) in 16 ms on localhost (executor driver) (184/200)
09:20:57.201 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 184.0 in stage 5.0 (TID 390) in 16 ms on localhost (executor driver) (185/200)
09:20:57.201 INFO  [Executor task launch worker for task 392] org.apache.spark.executor.Executor - Running task 186.0 in stage 5.0 (TID 392)
09:20:57.201 INFO  [Executor task launch worker for task 393] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=187), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/187] for update
09:20:57.201 INFO  [Executor task launch worker for task 393] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=187), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/187] for update
09:20:57.217 INFO  [Executor task launch worker for task 393] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:57.217 INFO  [Executor task launch worker for task 393] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:57.217 INFO  [Executor task launch worker for task 392] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=186), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/186] for update
09:20:57.217 INFO  [Executor task launch worker for task 392] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=186), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/186] for update
09:20:57.217 INFO  [Executor task launch worker for task 392] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:57.217 INFO  [Executor task launch worker for task 392] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:57.217 INFO  [Executor task launch worker for task 393] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=187),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/187] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/187/2.delta
09:20:57.217 INFO  [Executor task launch worker for task 392] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=186),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/186] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/186/2.delta
09:20:57.217 INFO  [Executor task launch worker for task 393] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=187),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/187]
09:20:57.217 INFO  [Executor task launch worker for task 393] org.apache.spark.executor.Executor - Finished task 187.0 in stage 5.0 (TID 393). 3322 bytes result sent to driver
09:20:57.217 INFO  [Executor task launch worker for task 392] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=186),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/186]
09:20:57.217 INFO  [Executor task launch worker for task 392] org.apache.spark.executor.Executor - Finished task 186.0 in stage 5.0 (TID 392). 3365 bytes result sent to driver
09:20:57.217 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 188.0 in stage 5.0 (TID 394, localhost, executor driver, partition 188, PROCESS_LOCAL, 4726 bytes)
09:20:57.217 INFO  [Executor task launch worker for task 394] org.apache.spark.executor.Executor - Running task 188.0 in stage 5.0 (TID 394)
09:20:57.217 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 189.0 in stage 5.0 (TID 395, localhost, executor driver, partition 189, PROCESS_LOCAL, 4726 bytes)
09:20:57.217 INFO  [Executor task launch worker for task 395] org.apache.spark.executor.Executor - Running task 189.0 in stage 5.0 (TID 395)
09:20:57.217 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 187.0 in stage 5.0 (TID 393) in 16 ms on localhost (executor driver) (186/200)
09:20:57.217 INFO  [Executor task launch worker for task 394] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=188), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/188] for update
09:20:57.232 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 186.0 in stage 5.0 (TID 392) in 31 ms on localhost (executor driver) (187/200)
09:20:57.232 INFO  [Executor task launch worker for task 395] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=189), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/189] for update
09:20:57.232 INFO  [Executor task launch worker for task 395] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=189), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/189] for update
09:20:57.232 INFO  [Executor task launch worker for task 395] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:57.232 INFO  [Executor task launch worker for task 395] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:57.232 INFO  [Executor task launch worker for task 394] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=188), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/188] for update
09:20:57.232 INFO  [Executor task launch worker for task 387] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=181),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/181]
09:20:57.232 INFO  [Executor task launch worker for task 394] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:57.232 INFO  [Executor task launch worker for task 394] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:57.232 INFO  [Executor task launch worker for task 387] org.apache.spark.executor.Executor - Finished task 181.0 in stage 5.0 (TID 387). 3408 bytes result sent to driver
09:20:57.232 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 190.0 in stage 5.0 (TID 396, localhost, executor driver, partition 190, PROCESS_LOCAL, 4726 bytes)
09:20:57.232 INFO  [Executor task launch worker for task 396] org.apache.spark.executor.Executor - Running task 190.0 in stage 5.0 (TID 396)
09:20:57.232 INFO  [Executor task launch worker for task 396] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=190), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/190] for update
09:20:57.232 INFO  [Executor task launch worker for task 396] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=190), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/190] for update
09:20:57.232 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 181.0 in stage 5.0 (TID 387) in 109 ms on localhost (executor driver) (188/200)
09:20:57.232 INFO  [Executor task launch worker for task 394] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=188),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/188] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/188/2.delta
09:20:57.232 INFO  [Executor task launch worker for task 395] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=189),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/189] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/189/2.delta
09:20:57.248 INFO  [Executor task launch worker for task 396] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:57.248 INFO  [Executor task launch worker for task 396] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:57.248 INFO  [Executor task launch worker for task 394] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=188),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/188]
09:20:57.248 INFO  [Executor task launch worker for task 394] org.apache.spark.executor.Executor - Finished task 188.0 in stage 5.0 (TID 394). 3322 bytes result sent to driver
09:20:57.248 INFO  [Executor task launch worker for task 396] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=190),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/190] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/190/2.delta
09:20:57.248 INFO  [Executor task launch worker for task 395] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=189),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/189]
09:20:57.248 INFO  [Executor task launch worker for task 395] org.apache.spark.executor.Executor - Finished task 189.0 in stage 5.0 (TID 395). 3365 bytes result sent to driver
09:20:57.248 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 191.0 in stage 5.0 (TID 397, localhost, executor driver, partition 191, PROCESS_LOCAL, 4726 bytes)
09:20:57.248 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 192.0 in stage 5.0 (TID 398, localhost, executor driver, partition 192, PROCESS_LOCAL, 4726 bytes)
09:20:57.248 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 188.0 in stage 5.0 (TID 394) in 31 ms on localhost (executor driver) (189/200)
09:20:57.248 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 189.0 in stage 5.0 (TID 395) in 31 ms on localhost (executor driver) (190/200)
09:20:57.248 INFO  [Executor task launch worker for task 396] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=190),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/190]
09:20:57.248 INFO  [Executor task launch worker for task 397] org.apache.spark.executor.Executor - Running task 191.0 in stage 5.0 (TID 397)
09:20:57.263 INFO  [Executor task launch worker for task 396] org.apache.spark.executor.Executor - Finished task 190.0 in stage 5.0 (TID 396). 3322 bytes result sent to driver
09:20:57.248 INFO  [Executor task launch worker for task 398] org.apache.spark.executor.Executor - Running task 192.0 in stage 5.0 (TID 398)
09:20:57.263 INFO  [Executor task launch worker for task 397] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=191), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/191] for update
09:20:57.263 INFO  [Executor task launch worker for task 397] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=191), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/191] for update
09:20:57.263 INFO  [Executor task launch worker for task 397] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:57.263 INFO  [Executor task launch worker for task 397] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:57.263 INFO  [Executor task launch worker for task 398] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=192), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/192] for update
09:20:57.263 INFO  [Executor task launch worker for task 398] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=192), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/192] for update
09:20:57.263 INFO  [Executor task launch worker for task 398] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:57.263 INFO  [Executor task launch worker for task 398] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:57.263 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 193.0 in stage 5.0 (TID 399, localhost, executor driver, partition 193, PROCESS_LOCAL, 4726 bytes)
09:20:57.263 INFO  [Executor task launch worker for task 399] org.apache.spark.executor.Executor - Running task 193.0 in stage 5.0 (TID 399)
09:20:57.263 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 190.0 in stage 5.0 (TID 396) in 31 ms on localhost (executor driver) (191/200)
09:20:57.263 INFO  [Executor task launch worker for task 399] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=193), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/193] for update
09:20:57.263 INFO  [Executor task launch worker for task 399] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=193), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/193] for update
09:20:57.263 INFO  [Executor task launch worker for task 399] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:57.263 INFO  [Executor task launch worker for task 397] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=191),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/191] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/191/2.delta
09:20:57.279 INFO  [Executor task launch worker for task 399] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 16 ms
09:20:57.279 INFO  [Executor task launch worker for task 398] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=192),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/192] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/192/2.delta
09:20:57.279 INFO  [Executor task launch worker for task 398] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=192),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/192]
09:20:57.279 INFO  [Executor task launch worker for task 398] org.apache.spark.executor.Executor - Finished task 192.0 in stage 5.0 (TID 398). 3408 bytes result sent to driver
09:20:57.279 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 194.0 in stage 5.0 (TID 400, localhost, executor driver, partition 194, PROCESS_LOCAL, 4726 bytes)
09:20:57.279 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 192.0 in stage 5.0 (TID 398) in 31 ms on localhost (executor driver) (192/200)
09:20:57.279 INFO  [Executor task launch worker for task 400] org.apache.spark.executor.Executor - Running task 194.0 in stage 5.0 (TID 400)
09:20:57.279 INFO  [Executor task launch worker for task 399] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=193),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/193] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/193/2.delta
09:20:57.279 INFO  [Executor task launch worker for task 400] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=194), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/194] for update
09:20:57.279 INFO  [Executor task launch worker for task 400] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=194), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/194] for update
09:20:57.279 INFO  [Executor task launch worker for task 400] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:57.279 INFO  [Executor task launch worker for task 400] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:57.295 INFO  [Executor task launch worker for task 399] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=193),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/193]
09:20:57.295 INFO  [Executor task launch worker for task 399] org.apache.spark.executor.Executor - Finished task 193.0 in stage 5.0 (TID 399). 3365 bytes result sent to driver
09:20:57.295 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 195.0 in stage 5.0 (TID 401, localhost, executor driver, partition 195, PROCESS_LOCAL, 4726 bytes)
09:20:57.295 INFO  [Executor task launch worker for task 401] org.apache.spark.executor.Executor - Running task 195.0 in stage 5.0 (TID 401)
09:20:57.295 INFO  [Executor task launch worker for task 400] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=194),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/194] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/194/2.delta
09:20:57.295 INFO  [Executor task launch worker for task 401] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=195), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/195] for update
09:20:57.295 INFO  [Executor task launch worker for task 401] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=195), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/195] for update
09:20:57.295 INFO  [Executor task launch worker for task 401] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:57.295 INFO  [Executor task launch worker for task 401] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:57.295 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 193.0 in stage 5.0 (TID 399) in 32 ms on localhost (executor driver) (193/200)
09:20:57.295 INFO  [Executor task launch worker for task 397] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=191),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/191]
09:20:57.295 INFO  [Executor task launch worker for task 397] org.apache.spark.executor.Executor - Finished task 191.0 in stage 5.0 (TID 397). 3365 bytes result sent to driver
09:20:57.295 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 196.0 in stage 5.0 (TID 402, localhost, executor driver, partition 196, PROCESS_LOCAL, 4726 bytes)
09:20:57.295 INFO  [Executor task launch worker for task 402] org.apache.spark.executor.Executor - Running task 196.0 in stage 5.0 (TID 402)
09:20:57.295 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 191.0 in stage 5.0 (TID 397) in 47 ms on localhost (executor driver) (194/200)
09:20:57.295 INFO  [Executor task launch worker for task 400] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=194),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/194]
09:20:57.295 INFO  [Executor task launch worker for task 402] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=196), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/196] for update
09:20:57.295 INFO  [Executor task launch worker for task 401] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=195),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/195] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/195/2.delta
09:20:57.310 INFO  [Executor task launch worker for task 402] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=196), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/196] for update
09:20:57.310 INFO  [Executor task launch worker for task 400] org.apache.spark.executor.Executor - Finished task 194.0 in stage 5.0 (TID 400). 3365 bytes result sent to driver
09:20:57.310 INFO  [Executor task launch worker for task 402] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:57.310 INFO  [Executor task launch worker for task 402] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:57.310 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 197.0 in stage 5.0 (TID 403, localhost, executor driver, partition 197, PROCESS_LOCAL, 4726 bytes)
09:20:57.310 INFO  [Executor task launch worker for task 403] org.apache.spark.executor.Executor - Running task 197.0 in stage 5.0 (TID 403)
09:20:57.310 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 194.0 in stage 5.0 (TID 400) in 31 ms on localhost (executor driver) (195/200)
09:20:57.310 INFO  [Executor task launch worker for task 403] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=197), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/197] for update
09:20:57.310 INFO  [Executor task launch worker for task 403] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=197), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/197] for update
09:20:57.310 INFO  [Executor task launch worker for task 403] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:57.310 INFO  [Executor task launch worker for task 403] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:57.310 INFO  [Executor task launch worker for task 401] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=195),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/195]
09:20:57.310 INFO  [Executor task launch worker for task 401] org.apache.spark.executor.Executor - Finished task 195.0 in stage 5.0 (TID 401). 3322 bytes result sent to driver
09:20:57.310 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 198.0 in stage 5.0 (TID 404, localhost, executor driver, partition 198, PROCESS_LOCAL, 4726 bytes)
09:20:57.310 INFO  [Executor task launch worker for task 404] org.apache.spark.executor.Executor - Running task 198.0 in stage 5.0 (TID 404)
09:20:57.310 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 195.0 in stage 5.0 (TID 401) in 15 ms on localhost (executor driver) (196/200)
09:20:57.310 INFO  [Executor task launch worker for task 402] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=196),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/196] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/196/2.delta
09:20:57.310 INFO  [Executor task launch worker for task 404] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=198), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/198] for update
09:20:57.310 INFO  [Executor task launch worker for task 403] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=197),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/197] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/197/2.delta
09:20:57.326 INFO  [Executor task launch worker for task 404] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=198), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/198] for update
09:20:57.326 INFO  [Executor task launch worker for task 404] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:57.326 INFO  [Executor task launch worker for task 404] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:57.326 INFO  [Executor task launch worker for task 402] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=196),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/196]
09:20:57.326 INFO  [Executor task launch worker for task 403] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=197),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/197]
09:20:57.326 INFO  [Executor task launch worker for task 403] org.apache.spark.executor.Executor - Finished task 197.0 in stage 5.0 (TID 403). 3322 bytes result sent to driver
09:20:57.326 INFO  [Executor task launch worker for task 402] org.apache.spark.executor.Executor - Finished task 196.0 in stage 5.0 (TID 402). 3322 bytes result sent to driver
09:20:57.326 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 199.0 in stage 5.0 (TID 405, localhost, executor driver, partition 199, PROCESS_LOCAL, 4726 bytes)
09:20:57.326 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 197.0 in stage 5.0 (TID 403) in 16 ms on localhost (executor driver) (197/200)
09:20:57.326 INFO  [Executor task launch worker for task 405] org.apache.spark.executor.Executor - Running task 199.0 in stage 5.0 (TID 405)
09:20:57.326 INFO  [Executor task launch worker for task 405] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=199), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/199] for update
09:20:57.326 INFO  [Executor task launch worker for task 405] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 1 of HDFSStateStoreProvider[id = (op=0, part=199), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/199] for update
09:20:57.326 INFO  [Executor task launch worker for task 405] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 2 blocks
09:20:57.326 INFO  [Executor task launch worker for task 405] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:20:57.326 INFO  [Executor task launch worker for task 404] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=198),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/198] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/198/2.delta
09:20:57.326 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 196.0 in stage 5.0 (TID 402) in 31 ms on localhost (executor driver) (198/200)
09:20:57.341 INFO  [Executor task launch worker for task 404] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=198),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/198]
09:20:57.341 INFO  [Executor task launch worker for task 404] org.apache.spark.executor.Executor - Finished task 198.0 in stage 5.0 (TID 404). 3322 bytes result sent to driver
09:20:57.341 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 198.0 in stage 5.0 (TID 404) in 31 ms on localhost (executor driver) (199/200)
09:20:57.341 INFO  [Executor task launch worker for task 405] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 2 for HDFSStateStore[id=(op=0,part=199),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/199] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/199/2.delta
09:20:57.341 INFO  [Executor task launch worker for task 405] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 2 for HDFSStateStore[id=(op=0,part=199),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/199]
09:20:57.341 INFO  [Executor task launch worker for task 405] org.apache.spark.executor.Executor - Finished task 199.0 in stage 5.0 (TID 405). 3322 bytes result sent to driver
09:20:57.341 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 199.0 in stage 5.0 (TID 405) in 15 ms on localhost (executor driver) (200/200)
09:20:57.341 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
09:20:57.341 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - ResultStage 5 (start at demo.scala:28) finished in 2.097 s
09:20:57.341 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.scheduler.DAGScheduler - Job 3 finished: start at demo.scala:28, took 2.174509 s
09:20:57.357 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.SparkContext - Starting job: start at demo.scala:28
09:20:57.357 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Got job 4 (start at demo.scala:28) with 1 output partitions
09:20:57.357 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 6 (start at demo.scala:28)
09:20:57.357 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
09:20:57.357 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
09:20:57.357 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 6 (MapPartitionsRDD[33] at start at demo.scala:28), which has no missing parents
09:20:57.373 INFO  [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore - Block broadcast_10 stored as values in memory (estimated size 8.4 KB, free 1953.9 MB)
09:20:57.373 INFO  [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore - Block broadcast_10_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1953.9 MB)
09:20:57.373 INFO  [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerInfo - Added broadcast_10_piece0 in memory on 172.16.2.246:51465 (size: 4.6 KB, free: 1954.4 MB)
09:20:57.373 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext - Created broadcast 10 from broadcast at DAGScheduler.scala:1004
09:20:57.373 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[33] at start at demo.scala:28) (first 15 tasks are for partitions Vector(0))
09:20:57.373 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 6.0 with 1 tasks
09:20:57.373 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 6.0 (TID 406, localhost, executor driver, partition 0, PROCESS_LOCAL, 5926 bytes)
09:20:57.373 INFO  [Executor task launch worker for task 406] org.apache.spark.executor.Executor - Running task 0.0 in stage 6.0 (TID 406)
09:20:57.373 INFO  [Executor task launch worker for task 406] org.apache.spark.executor.Executor - Finished task 0.0 in stage 6.0 (TID 406). 856 bytes result sent to driver
09:20:57.373 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 6.0 (TID 406) in 0 ms on localhost (executor driver) (1/1)
09:20:57.373 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 6.0, whose tasks have all completed, from pool 
09:20:57.373 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - ResultStage 6 (start at demo.scala:28) finished in 0.000 s
09:20:57.373 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.scheduler.DAGScheduler - Job 4 finished: start at demo.scala:28, took 0.009502 s
09:20:57.373 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.SparkContext - Starting job: start at demo.scala:28
09:20:57.373 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Got job 5 (start at demo.scala:28) with 2 output partitions
09:20:57.373 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 7 (start at demo.scala:28)
09:20:57.373 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
09:20:57.373 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
09:20:57.373 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 7 (MapPartitionsRDD[33] at start at demo.scala:28), which has no missing parents
09:20:57.373 INFO  [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore - Block broadcast_11 stored as values in memory (estimated size 8.4 KB, free 1953.9 MB)
09:20:57.373 INFO  [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore - Block broadcast_11_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1953.9 MB)
09:20:57.388 INFO  [dispatcher-event-loop-5] org.apache.spark.storage.BlockManagerInfo - Added broadcast_11_piece0 in memory on 172.16.2.246:51465 (size: 4.6 KB, free: 1954.4 MB)
09:20:57.388 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext - Created broadcast 11 from broadcast at DAGScheduler.scala:1004
09:20:57.388 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from ResultStage 7 (MapPartitionsRDD[33] at start at demo.scala:28) (first 15 tasks are for partitions Vector(1, 2))
09:20:57.388 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 7.0 with 2 tasks
09:20:57.388 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 7.0 (TID 407, localhost, executor driver, partition 1, PROCESS_LOCAL, 5957 bytes)
09:20:57.388 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 7.0 (TID 408, localhost, executor driver, partition 2, PROCESS_LOCAL, 5959 bytes)
09:20:57.388 INFO  [Executor task launch worker for task 407] org.apache.spark.executor.Executor - Running task 0.0 in stage 7.0 (TID 407)
09:20:57.388 INFO  [Executor task launch worker for task 408] org.apache.spark.executor.Executor - Running task 1.0 in stage 7.0 (TID 408)
09:20:57.388 INFO  [Executor task launch worker for task 407] org.apache.spark.executor.Executor - Finished task 0.0 in stage 7.0 (TID 407). 865 bytes result sent to driver
09:20:57.388 INFO  [Executor task launch worker for task 408] org.apache.spark.executor.Executor - Finished task 1.0 in stage 7.0 (TID 408). 865 bytes result sent to driver
09:20:57.388 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 7.0 (TID 407) in 0 ms on localhost (executor driver) (1/2)
09:20:57.388 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 7.0 (TID 408) in 0 ms on localhost (executor driver) (2/2)
09:20:57.388 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 7.0, whose tasks have all completed, from pool 
09:20:57.388 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - ResultStage 7 (start at demo.scala:28) finished in 0.000 s
09:20:57.388 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.scheduler.DAGScheduler - Job 5 finished: start at demo.scala:28, took 0.009205 s
09:20:57.388 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.sql.execution.streaming.StreamExecution - Streaming query made progress: {
  "id" : "20adb406-fa0e-4b6d-891d-3b838da918df",
  "runId" : "042f103f-d70f-40a8-8188-bbfcfa159ed0",
  "name" : null,
  "timestamp" : "2020-10-12T01:20:54.884Z",
  "numInputRows" : 2,
  "inputRowsPerSecond" : 0.32378177108628786,
  "processedRowsPerSecond" : 0.7987220447284346,
  "durationMs" : {
    "addBatch" : 2316,
    "getBatch" : 31,
    "getOffset" : 0,
    "queryPlanning" : 16,
    "triggerExecution" : 2504,
    "walCommit" : 125
  },
  "stateOperators" : [ {
    "numRowsTotal" : 5,
    "numRowsUpdated" : 4
  } ],
  "sources" : [ {
    "description" : "TextSocketSource[host: 10.112.0.8, port: 1122]",
    "startOffset" : 0,
    "endOffset" : 2,
    "numInputRows" : 2,
    "inputRowsPerSecond" : 0.32378177108628786,
    "processedRowsPerSecond" : 0.7987220447284346
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSink@ee7e03"
  }
}
09:20:57.513 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.sql.execution.streaming.StreamExecution - Streaming query made progress: {
  "id" : "20adb406-fa0e-4b6d-891d-3b838da918df",
  "runId" : "042f103f-d70f-40a8-8188-bbfcfa159ed0",
  "name" : null,
  "timestamp" : "2020-10-12T01:20:57.513Z",
  "numInputRows" : 0,
  "inputRowsPerSecond" : 0.0,
  "durationMs" : {
    "getOffset" : 0,
    "triggerExecution" : 0
  },
  "stateOperators" : [ {
    "numRowsTotal" : 5,
    "numRowsUpdated" : 0
  } ],
  "sources" : [ {
    "description" : "TextSocketSource[host: 10.112.0.8, port: 1122]",
    "startOffset" : 2,
    "endOffset" : 2,
    "numInputRows" : 0,
    "inputRowsPerSecond" : 0.0
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSink@ee7e03"
  }
}
09:21:07.522 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.sql.execution.streaming.StreamExecution - Streaming query made progress: {
  "id" : "20adb406-fa0e-4b6d-891d-3b838da918df",
  "runId" : "042f103f-d70f-40a8-8188-bbfcfa159ed0",
  "name" : null,
  "timestamp" : "2020-10-12T01:21:07.522Z",
  "numInputRows" : 0,
  "inputRowsPerSecond" : 0.0,
  "durationMs" : {
    "getOffset" : 0,
    "triggerExecution" : 0
  },
  "stateOperators" : [ {
    "numRowsTotal" : 5,
    "numRowsUpdated" : 0
  } ],
  "sources" : [ {
    "description" : "TextSocketSource[host: 10.112.0.8, port: 1122]",
    "startOffset" : 2,
    "endOffset" : 2,
    "numInputRows" : 0,
    "inputRowsPerSecond" : 0.0
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSink@ee7e03"
  }
}
09:21:08.026 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.sql.execution.streaming.StreamExecution - Committed offsets for batch 2. Metadata OffsetSeqMetadata(0,1602465667916,Map(spark.sql.shuffle.partitions -> 200))
09:21:08.104 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.storage.memory.MemoryStore - Block broadcast_12 stored as values in memory (estimated size 250.7 KB, free 1953.6 MB)
09:21:08.104 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.storage.memory.MemoryStore - Block broadcast_12_piece0 stored as bytes in memory (estimated size 21.2 KB, free 1953.6 MB)
09:21:08.119 INFO  [dispatcher-event-loop-5] org.apache.spark.storage.BlockManagerInfo - Added broadcast_12_piece0 in memory on 172.16.2.246:51465 (size: 21.2 KB, free: 1954.4 MB)
09:21:08.119 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.SparkContext - Created broadcast 12 from start at demo.scala:28
09:21:08.135 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.storage.memory.MemoryStore - Block broadcast_13 stored as values in memory (estimated size 250.7 KB, free 1953.4 MB)
09:21:08.151 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.storage.memory.MemoryStore - Block broadcast_13_piece0 stored as bytes in memory (estimated size 21.2 KB, free 1953.4 MB)
09:21:08.151 INFO  [dispatcher-event-loop-0] org.apache.spark.storage.BlockManagerInfo - Added broadcast_13_piece0 in memory on 172.16.2.246:51465 (size: 21.2 KB, free: 1954.4 MB)
09:21:08.151 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.SparkContext - Created broadcast 13 from start at demo.scala:28
09:21:08.151 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.SparkContext - Starting job: start at demo.scala:28
09:21:08.151 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Registering RDD 39 (start at demo.scala:28)
09:21:08.151 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Got job 6 (start at demo.scala:28) with 200 output partitions
09:21:08.151 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 9 (start at demo.scala:28)
09:21:08.151 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 8)
09:21:08.151 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 8)
09:21:08.151 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 8 (MapPartitionsRDD[39] at start at demo.scala:28), which has no missing parents
09:21:08.166 INFO  [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore - Block broadcast_14 stored as values in memory (estimated size 23.8 KB, free 1953.3 MB)
09:21:08.166 INFO  [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore - Block broadcast_14_piece0 stored as bytes in memory (estimated size 10.7 KB, free 1953.3 MB)
09:21:08.166 INFO  [dispatcher-event-loop-4] org.apache.spark.storage.BlockManagerInfo - Added broadcast_14_piece0 in memory on 172.16.2.246:51465 (size: 10.7 KB, free: 1954.4 MB)
09:21:08.166 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext - Created broadcast 14 from broadcast at DAGScheduler.scala:1004
09:21:08.166 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[39] at start at demo.scala:28) (first 15 tasks are for partitions Vector(0))
09:21:08.166 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 8.0 with 1 tasks
09:21:08.166 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 8.0 (TID 409, localhost, executor driver, partition 0, PROCESS_LOCAL, 5000 bytes)
09:21:08.166 INFO  [Executor task launch worker for task 409] org.apache.spark.executor.Executor - Running task 0.0 in stage 8.0 (TID 409)
09:21:08.198 INFO  [Executor task launch worker for task 409] org.apache.spark.executor.Executor - Finished task 0.0 in stage 8.0 (TID 409). 1846 bytes result sent to driver
09:21:08.198 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 8.0 (TID 409) in 32 ms on localhost (executor driver) (1/1)
09:21:08.198 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 8.0, whose tasks have all completed, from pool 
09:21:08.198 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 8 (start at demo.scala:28) finished in 0.032 s
09:21:08.198 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
09:21:08.198 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - running: Set()
09:21:08.198 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 9)
09:21:08.198 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - failed: Set()
09:21:08.198 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 9 (MapPartitionsRDD[46] at start at demo.scala:28), which has no missing parents
09:21:08.213 INFO  [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore - Block broadcast_15 stored as values in memory (estimated size 45.4 KB, free 1953.3 MB)
09:21:08.213 INFO  [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore - Block broadcast_15_piece0 stored as bytes in memory (estimated size 16.7 KB, free 1953.3 MB)
09:21:08.213 INFO  [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerInfo - Added broadcast_15_piece0 in memory on 172.16.2.246:51465 (size: 16.7 KB, free: 1954.4 MB)
09:21:08.213 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext - Created broadcast 15 from broadcast at DAGScheduler.scala:1004
09:21:08.213 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Submitting 200 missing tasks from ResultStage 9 (MapPartitionsRDD[46] at start at demo.scala:28) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
09:21:08.213 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 9.0 with 200 tasks
09:21:08.213 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 9.0 (TID 410, localhost, executor driver, partition 0, PROCESS_LOCAL, 4726 bytes)
09:21:08.213 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 9.0 (TID 411, localhost, executor driver, partition 1, PROCESS_LOCAL, 4726 bytes)
09:21:08.213 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 9.0 (TID 412, localhost, executor driver, partition 2, PROCESS_LOCAL, 4726 bytes)
09:21:08.213 INFO  [Executor task launch worker for task 411] org.apache.spark.executor.Executor - Running task 1.0 in stage 9.0 (TID 411)
09:21:08.213 INFO  [Executor task launch worker for task 410] org.apache.spark.executor.Executor - Running task 0.0 in stage 9.0 (TID 410)
09:21:08.213 INFO  [Executor task launch worker for task 412] org.apache.spark.executor.Executor - Running task 2.0 in stage 9.0 (TID 412)
09:21:08.213 INFO  [Executor task launch worker for task 411] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=1), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/1] for update
09:21:08.213 INFO  [Executor task launch worker for task 412] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=2), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/2] for update
09:21:08.213 INFO  [Executor task launch worker for task 411] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=1), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/1] for update
09:21:08.213 INFO  [Executor task launch worker for task 412] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=2), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/2] for update
09:21:08.213 INFO  [Executor task launch worker for task 411] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.213 INFO  [Executor task launch worker for task 412] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.213 INFO  [Executor task launch worker for task 411] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.213 INFO  [Executor task launch worker for task 410] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=0), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/0] for update
09:21:08.229 INFO  [Executor task launch worker for task 412] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 16 ms
09:21:08.229 INFO  [Executor task launch worker for task 410] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=0), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/0] for update
09:21:08.229 INFO  [Executor task launch worker for task 410] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.229 INFO  [Executor task launch worker for task 410] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.229 INFO  [Executor task launch worker for task 411] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=1),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/1] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/1/3.delta
09:21:08.229 INFO  [Executor task launch worker for task 412] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=2),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/2] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/2/3.delta
09:21:08.229 INFO  [Executor task launch worker for task 410] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=0),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/0] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/0/3.delta
09:21:08.229 INFO  [Executor task launch worker for task 411] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=1),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/1]
09:21:08.229 INFO  [Executor task launch worker for task 410] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=0),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/0]
09:21:08.229 INFO  [Executor task launch worker for task 412] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=2),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/2]
09:21:08.229 INFO  [Executor task launch worker for task 411] org.apache.spark.executor.Executor - Finished task 1.0 in stage 9.0 (TID 411). 3322 bytes result sent to driver
09:21:08.229 INFO  [Executor task launch worker for task 410] org.apache.spark.executor.Executor - Finished task 0.0 in stage 9.0 (TID 410). 3322 bytes result sent to driver
09:21:08.229 INFO  [Executor task launch worker for task 412] org.apache.spark.executor.Executor - Finished task 2.0 in stage 9.0 (TID 412). 3322 bytes result sent to driver
09:21:08.229 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 9.0 (TID 413, localhost, executor driver, partition 3, PROCESS_LOCAL, 4726 bytes)
09:21:08.229 INFO  [Executor task launch worker for task 413] org.apache.spark.executor.Executor - Running task 3.0 in stage 9.0 (TID 413)
09:21:08.229 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 9.0 (TID 414, localhost, executor driver, partition 4, PROCESS_LOCAL, 4726 bytes)
09:21:08.229 INFO  [Executor task launch worker for task 413] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=3), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/3] for update
09:21:08.244 INFO  [Executor task launch worker for task 413] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=3), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/3] for update
09:21:08.244 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 9.0 (TID 415, localhost, executor driver, partition 5, PROCESS_LOCAL, 4726 bytes)
09:21:08.244 INFO  [Executor task launch worker for task 414] org.apache.spark.executor.Executor - Running task 4.0 in stage 9.0 (TID 414)
09:21:08.244 INFO  [Executor task launch worker for task 413] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.244 INFO  [Executor task launch worker for task 413] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.244 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 9.0 (TID 412) in 31 ms on localhost (executor driver) (1/200)
09:21:08.244 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 9.0 (TID 410) in 31 ms on localhost (executor driver) (2/200)
09:21:08.244 INFO  [Executor task launch worker for task 415] org.apache.spark.executor.Executor - Running task 5.0 in stage 9.0 (TID 415)
09:21:08.244 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 9.0 (TID 411) in 31 ms on localhost (executor driver) (3/200)
09:21:08.244 INFO  [Executor task launch worker for task 414] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=4), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/4] for update
09:21:08.244 INFO  [Executor task launch worker for task 414] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=4), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/4] for update
09:21:08.244 INFO  [Executor task launch worker for task 414] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.244 INFO  [Executor task launch worker for task 414] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.244 INFO  [Executor task launch worker for task 415] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=5), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/5] for update
09:21:08.244 INFO  [Executor task launch worker for task 415] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=5), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/5] for update
09:21:08.244 INFO  [Executor task launch worker for task 415] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.244 INFO  [Executor task launch worker for task 415] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.244 INFO  [Executor task launch worker for task 413] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=3),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/3] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/3/3.delta
09:21:08.244 INFO  [Executor task launch worker for task 414] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=4),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/4] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/4/3.delta
09:21:08.244 INFO  [Executor task launch worker for task 415] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=5),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/5] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/5/3.delta
09:21:08.244 INFO  [Executor task launch worker for task 413] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=3),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/3]
09:21:08.244 INFO  [Executor task launch worker for task 414] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=4),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/4]
09:21:08.260 INFO  [Executor task launch worker for task 413] org.apache.spark.executor.Executor - Finished task 3.0 in stage 9.0 (TID 413). 3322 bytes result sent to driver
09:21:08.260 INFO  [Executor task launch worker for task 414] org.apache.spark.executor.Executor - Finished task 4.0 in stage 9.0 (TID 414). 3322 bytes result sent to driver
09:21:08.244 INFO  [Executor task launch worker for task 415] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=5),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/5]
09:21:08.260 INFO  [Executor task launch worker for task 415] org.apache.spark.executor.Executor - Finished task 5.0 in stage 9.0 (TID 415). 3322 bytes result sent to driver
09:21:08.260 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 6.0 in stage 9.0 (TID 416, localhost, executor driver, partition 6, PROCESS_LOCAL, 4726 bytes)
09:21:08.260 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 7.0 in stage 9.0 (TID 417, localhost, executor driver, partition 7, PROCESS_LOCAL, 4726 bytes)
09:21:08.260 INFO  [Executor task launch worker for task 416] org.apache.spark.executor.Executor - Running task 6.0 in stage 9.0 (TID 416)
09:21:08.260 INFO  [Executor task launch worker for task 417] org.apache.spark.executor.Executor - Running task 7.0 in stage 9.0 (TID 417)
09:21:08.260 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 8.0 in stage 9.0 (TID 418, localhost, executor driver, partition 8, PROCESS_LOCAL, 4726 bytes)
09:21:08.260 INFO  [Executor task launch worker for task 418] org.apache.spark.executor.Executor - Running task 8.0 in stage 9.0 (TID 418)
09:21:08.260 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 9.0 (TID 415) in 16 ms on localhost (executor driver) (4/200)
09:21:08.260 INFO  [Executor task launch worker for task 416] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=6), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/6] for update
09:21:08.260 INFO  [Executor task launch worker for task 417] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=7), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/7] for update
09:21:08.260 INFO  [Executor task launch worker for task 416] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=6), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/6] for update
09:21:08.260 INFO  [Executor task launch worker for task 417] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=7), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/7] for update
09:21:08.260 INFO  [Executor task launch worker for task 418] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=8), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/8] for update
09:21:08.260 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 9.0 (TID 414) in 31 ms on localhost (executor driver) (5/200)
09:21:08.260 INFO  [Executor task launch worker for task 416] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.260 INFO  [Executor task launch worker for task 417] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.260 INFO  [Executor task launch worker for task 418] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=8), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/8] for update
09:21:08.260 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 9.0 (TID 413) in 31 ms on localhost (executor driver) (6/200)
09:21:08.260 INFO  [Executor task launch worker for task 416] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.260 INFO  [Executor task launch worker for task 417] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.260 INFO  [Executor task launch worker for task 418] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.260 INFO  [Executor task launch worker for task 418] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.276 INFO  [Executor task launch worker for task 417] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=7),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/7] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/7/3.delta
09:21:08.276 INFO  [Executor task launch worker for task 418] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=8),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/8] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/8/3.delta
09:21:08.276 INFO  [Executor task launch worker for task 416] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=6),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/6] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/6/3.delta
09:21:08.276 INFO  [Executor task launch worker for task 417] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=7),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/7]
09:21:08.276 INFO  [Executor task launch worker for task 418] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=8),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/8]
09:21:08.276 INFO  [Executor task launch worker for task 416] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=6),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/6]
09:21:08.276 INFO  [Executor task launch worker for task 418] org.apache.spark.executor.Executor - Finished task 8.0 in stage 9.0 (TID 418). 3365 bytes result sent to driver
09:21:08.276 INFO  [Executor task launch worker for task 417] org.apache.spark.executor.Executor - Finished task 7.0 in stage 9.0 (TID 417). 3365 bytes result sent to driver
09:21:08.276 INFO  [Executor task launch worker for task 416] org.apache.spark.executor.Executor - Finished task 6.0 in stage 9.0 (TID 416). 3365 bytes result sent to driver
09:21:08.276 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 9.0 in stage 9.0 (TID 419, localhost, executor driver, partition 9, PROCESS_LOCAL, 4726 bytes)
09:21:08.276 INFO  [Executor task launch worker for task 419] org.apache.spark.executor.Executor - Running task 9.0 in stage 9.0 (TID 419)
09:21:08.276 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 10.0 in stage 9.0 (TID 420, localhost, executor driver, partition 10, PROCESS_LOCAL, 4726 bytes)
09:21:08.276 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 8.0 in stage 9.0 (TID 418) in 16 ms on localhost (executor driver) (7/200)
09:21:08.276 INFO  [Executor task launch worker for task 420] org.apache.spark.executor.Executor - Running task 10.0 in stage 9.0 (TID 420)
09:21:08.276 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 7.0 in stage 9.0 (TID 417) in 16 ms on localhost (executor driver) (8/200)
09:21:08.276 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 11.0 in stage 9.0 (TID 421, localhost, executor driver, partition 11, PROCESS_LOCAL, 4726 bytes)
09:21:08.276 INFO  [Executor task launch worker for task 420] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=10), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/10] for update
09:21:08.276 INFO  [Executor task launch worker for task 419] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=9), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/9] for update
09:21:08.291 INFO  [Executor task launch worker for task 421] org.apache.spark.executor.Executor - Running task 11.0 in stage 9.0 (TID 421)
09:21:08.291 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 6.0 in stage 9.0 (TID 416) in 31 ms on localhost (executor driver) (9/200)
09:21:08.291 INFO  [Executor task launch worker for task 420] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=10), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/10] for update
09:21:08.291 INFO  [Executor task launch worker for task 419] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=9), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/9] for update
09:21:08.291 INFO  [Executor task launch worker for task 420] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.291 INFO  [Executor task launch worker for task 419] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.291 INFO  [Executor task launch worker for task 420] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.291 INFO  [Executor task launch worker for task 419] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.291 INFO  [Executor task launch worker for task 421] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=11), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/11] for update
09:21:08.291 INFO  [Executor task launch worker for task 421] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=11), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/11] for update
09:21:08.291 INFO  [Executor task launch worker for task 421] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.291 INFO  [Executor task launch worker for task 421] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.291 INFO  [Executor task launch worker for task 419] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=9),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/9] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/9/3.delta
09:21:08.291 INFO  [Executor task launch worker for task 420] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=10),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/10] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/10/3.delta
09:21:08.291 INFO  [Executor task launch worker for task 421] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=11),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/11] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/11/3.delta
09:21:08.291 INFO  [Executor task launch worker for task 420] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=10),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/10]
09:21:08.291 INFO  [Executor task launch worker for task 419] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=9),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/9]
09:21:08.291 INFO  [Executor task launch worker for task 420] org.apache.spark.executor.Executor - Finished task 10.0 in stage 9.0 (TID 420). 3322 bytes result sent to driver
09:21:08.291 INFO  [Executor task launch worker for task 419] org.apache.spark.executor.Executor - Finished task 9.0 in stage 9.0 (TID 419). 3322 bytes result sent to driver
09:21:08.291 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 12.0 in stage 9.0 (TID 422, localhost, executor driver, partition 12, PROCESS_LOCAL, 4726 bytes)
09:21:08.291 INFO  [Executor task launch worker for task 421] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=11),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/11]
09:21:08.307 INFO  [Executor task launch worker for task 422] org.apache.spark.executor.Executor - Running task 12.0 in stage 9.0 (TID 422)
09:21:08.307 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 13.0 in stage 9.0 (TID 423, localhost, executor driver, partition 13, PROCESS_LOCAL, 4726 bytes)
09:21:08.307 INFO  [Executor task launch worker for task 421] org.apache.spark.executor.Executor - Finished task 11.0 in stage 9.0 (TID 421). 3322 bytes result sent to driver
09:21:08.307 INFO  [Executor task launch worker for task 423] org.apache.spark.executor.Executor - Running task 13.0 in stage 9.0 (TID 423)
09:21:08.307 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 14.0 in stage 9.0 (TID 424, localhost, executor driver, partition 14, PROCESS_LOCAL, 4726 bytes)
09:21:08.307 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 10.0 in stage 9.0 (TID 420) in 31 ms on localhost (executor driver) (10/200)
09:21:08.307 INFO  [Executor task launch worker for task 424] org.apache.spark.executor.Executor - Running task 14.0 in stage 9.0 (TID 424)
09:21:08.307 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 11.0 in stage 9.0 (TID 421) in 31 ms on localhost (executor driver) (11/200)
09:21:08.307 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 9.0 in stage 9.0 (TID 419) in 31 ms on localhost (executor driver) (12/200)
09:21:08.307 INFO  [Executor task launch worker for task 423] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=13), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/13] for update
09:21:08.307 INFO  [Executor task launch worker for task 423] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=13), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/13] for update
09:21:08.307 INFO  [Executor task launch worker for task 422] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=12), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/12] for update
09:21:08.307 INFO  [Executor task launch worker for task 423] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.307 INFO  [Executor task launch worker for task 423] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.307 INFO  [Executor task launch worker for task 422] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=12), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/12] for update
09:21:08.307 INFO  [Executor task launch worker for task 422] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.307 INFO  [Executor task launch worker for task 424] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=14), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/14] for update
09:21:08.307 INFO  [Executor task launch worker for task 422] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.307 INFO  [Executor task launch worker for task 424] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=14), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/14] for update
09:21:08.307 INFO  [Executor task launch worker for task 424] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.307 INFO  [Executor task launch worker for task 424] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.307 INFO  [Executor task launch worker for task 422] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=12),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/12] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/12/3.delta
09:21:08.307 INFO  [Executor task launch worker for task 423] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=13),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/13] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/13/3.delta
09:21:08.323 INFO  [Executor task launch worker for task 423] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=13),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/13]
09:21:08.323 INFO  [Executor task launch worker for task 422] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=12),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/12]
09:21:08.323 INFO  [Executor task launch worker for task 423] org.apache.spark.executor.Executor - Finished task 13.0 in stage 9.0 (TID 423). 3322 bytes result sent to driver
09:21:08.323 INFO  [Executor task launch worker for task 422] org.apache.spark.executor.Executor - Finished task 12.0 in stage 9.0 (TID 422). 3322 bytes result sent to driver
09:21:08.323 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 15.0 in stage 9.0 (TID 425, localhost, executor driver, partition 15, PROCESS_LOCAL, 4726 bytes)
09:21:08.323 INFO  [Executor task launch worker for task 425] org.apache.spark.executor.Executor - Running task 15.0 in stage 9.0 (TID 425)
09:21:08.323 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 16.0 in stage 9.0 (TID 426, localhost, executor driver, partition 16, PROCESS_LOCAL, 4726 bytes)
09:21:08.323 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 13.0 in stage 9.0 (TID 423) in 16 ms on localhost (executor driver) (13/200)
09:21:08.323 INFO  [Executor task launch worker for task 426] org.apache.spark.executor.Executor - Running task 16.0 in stage 9.0 (TID 426)
09:21:08.323 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 12.0 in stage 9.0 (TID 422) in 32 ms on localhost (executor driver) (14/200)
09:21:08.323 INFO  [Executor task launch worker for task 424] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=14),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/14] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/14/3.delta
09:21:08.323 INFO  [Executor task launch worker for task 425] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=15), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/15] for update
09:21:08.323 INFO  [Executor task launch worker for task 425] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=15), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/15] for update
09:21:08.323 INFO  [Executor task launch worker for task 425] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.323 INFO  [Executor task launch worker for task 426] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=16), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/16] for update
09:21:08.323 INFO  [Executor task launch worker for task 425] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.323 INFO  [Executor task launch worker for task 426] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=16), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/16] for update
09:21:08.323 INFO  [Executor task launch worker for task 424] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=14),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/14]
09:21:08.338 INFO  [Executor task launch worker for task 426] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.338 INFO  [Executor task launch worker for task 426] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.338 INFO  [Executor task launch worker for task 424] org.apache.spark.executor.Executor - Finished task 14.0 in stage 9.0 (TID 424). 3322 bytes result sent to driver
09:21:08.338 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 17.0 in stage 9.0 (TID 427, localhost, executor driver, partition 17, PROCESS_LOCAL, 4726 bytes)
09:21:08.338 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 14.0 in stage 9.0 (TID 424) in 31 ms on localhost (executor driver) (15/200)
09:21:08.338 INFO  [Executor task launch worker for task 427] org.apache.spark.executor.Executor - Running task 17.0 in stage 9.0 (TID 427)
09:21:08.338 INFO  [Executor task launch worker for task 427] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=17), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/17] for update
09:21:08.338 INFO  [Executor task launch worker for task 427] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=17), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/17] for update
09:21:08.338 INFO  [Executor task launch worker for task 427] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.338 INFO  [Executor task launch worker for task 427] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.338 INFO  [Executor task launch worker for task 426] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=16),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/16] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/16/3.delta
09:21:08.338 INFO  [Executor task launch worker for task 425] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=15),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/15] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/15/3.delta
09:21:08.338 INFO  [Executor task launch worker for task 425] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=15),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/15]
09:21:08.338 INFO  [Executor task launch worker for task 425] org.apache.spark.executor.Executor - Finished task 15.0 in stage 9.0 (TID 425). 3322 bytes result sent to driver
09:21:08.338 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 18.0 in stage 9.0 (TID 428, localhost, executor driver, partition 18, PROCESS_LOCAL, 4726 bytes)
09:21:08.338 INFO  [Executor task launch worker for task 428] org.apache.spark.executor.Executor - Running task 18.0 in stage 9.0 (TID 428)
09:21:08.338 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 15.0 in stage 9.0 (TID 425) in 15 ms on localhost (executor driver) (16/200)
09:21:08.338 INFO  [Executor task launch worker for task 427] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=17),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/17] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/17/3.delta
09:21:08.338 INFO  [Executor task launch worker for task 426] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=16),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/16]
09:21:08.338 INFO  [Executor task launch worker for task 428] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=18), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/18] for update
09:21:08.354 INFO  [Executor task launch worker for task 428] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=18), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/18] for update
09:21:08.354 INFO  [Executor task launch worker for task 428] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.354 INFO  [Executor task launch worker for task 426] org.apache.spark.executor.Executor - Finished task 16.0 in stage 9.0 (TID 426). 3322 bytes result sent to driver
09:21:08.354 INFO  [Executor task launch worker for task 428] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.354 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 19.0 in stage 9.0 (TID 429, localhost, executor driver, partition 19, PROCESS_LOCAL, 4726 bytes)
09:21:08.354 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 16.0 in stage 9.0 (TID 426) in 31 ms on localhost (executor driver) (17/200)
09:21:08.354 INFO  [Executor task launch worker for task 429] org.apache.spark.executor.Executor - Running task 19.0 in stage 9.0 (TID 429)
09:21:08.354 INFO  [Executor task launch worker for task 429] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=19), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/19] for update
09:21:08.354 INFO  [Executor task launch worker for task 429] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=19), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/19] for update
09:21:08.354 INFO  [Executor task launch worker for task 429] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.354 INFO  [Executor task launch worker for task 429] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.354 INFO  [Executor task launch worker for task 427] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=17),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/17]
09:21:08.354 INFO  [Executor task launch worker for task 427] org.apache.spark.executor.Executor - Finished task 17.0 in stage 9.0 (TID 427). 3322 bytes result sent to driver
09:21:08.354 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 20.0 in stage 9.0 (TID 430, localhost, executor driver, partition 20, PROCESS_LOCAL, 4726 bytes)
09:21:08.354 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 17.0 in stage 9.0 (TID 427) in 16 ms on localhost (executor driver) (18/200)
09:21:08.354 INFO  [Executor task launch worker for task 430] org.apache.spark.executor.Executor - Running task 20.0 in stage 9.0 (TID 430)
09:21:08.354 INFO  [Executor task launch worker for task 428] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=18),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/18] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/18/3.delta
09:21:08.354 INFO  [Executor task launch worker for task 430] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=20), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/20] for update
09:21:08.354 INFO  [Executor task launch worker for task 429] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=19),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/19] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/19/3.delta
09:21:08.354 INFO  [Executor task launch worker for task 428] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=18),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/18]
09:21:08.369 INFO  [Executor task launch worker for task 430] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=20), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/20] for update
09:21:08.369 INFO  [Executor task launch worker for task 430] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.369 INFO  [Executor task launch worker for task 430] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.369 INFO  [Executor task launch worker for task 428] org.apache.spark.executor.Executor - Finished task 18.0 in stage 9.0 (TID 428). 3322 bytes result sent to driver
09:21:08.369 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 21.0 in stage 9.0 (TID 431, localhost, executor driver, partition 21, PROCESS_LOCAL, 4726 bytes)
09:21:08.369 INFO  [Executor task launch worker for task 431] org.apache.spark.executor.Executor - Running task 21.0 in stage 9.0 (TID 431)
09:21:08.369 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 18.0 in stage 9.0 (TID 428) in 31 ms on localhost (executor driver) (19/200)
09:21:08.369 INFO  [Executor task launch worker for task 431] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=21), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/21] for update
09:21:08.369 INFO  [Executor task launch worker for task 431] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=21), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/21] for update
09:21:08.369 INFO  [Executor task launch worker for task 431] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.369 INFO  [Executor task launch worker for task 431] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.369 INFO  [Executor task launch worker for task 429] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=19),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/19]
09:21:08.369 INFO  [Executor task launch worker for task 429] org.apache.spark.executor.Executor - Finished task 19.0 in stage 9.0 (TID 429). 3351 bytes result sent to driver
09:21:08.369 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 22.0 in stage 9.0 (TID 432, localhost, executor driver, partition 22, PROCESS_LOCAL, 4726 bytes)
09:21:08.369 INFO  [Executor task launch worker for task 432] org.apache.spark.executor.Executor - Running task 22.0 in stage 9.0 (TID 432)
09:21:08.369 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 19.0 in stage 9.0 (TID 429) in 15 ms on localhost (executor driver) (20/200)
09:21:08.369 INFO  [Executor task launch worker for task 430] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=20),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/20] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/20/3.delta
09:21:08.369 INFO  [Executor task launch worker for task 432] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=22), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/22] for update
09:21:08.369 INFO  [Executor task launch worker for task 431] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=21),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/21] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/21/3.delta
09:21:08.385 INFO  [Executor task launch worker for task 432] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=22), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/22] for update
09:21:08.385 INFO  [Executor task launch worker for task 432] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.385 INFO  [Executor task launch worker for task 432] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.385 INFO  [Executor task launch worker for task 430] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=20),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/20]
09:21:08.385 INFO  [Executor task launch worker for task 431] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=21),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/21]
09:21:08.385 INFO  [Executor task launch worker for task 430] org.apache.spark.executor.Executor - Finished task 20.0 in stage 9.0 (TID 430). 3322 bytes result sent to driver
09:21:08.385 INFO  [Executor task launch worker for task 431] org.apache.spark.executor.Executor - Finished task 21.0 in stage 9.0 (TID 431). 3322 bytes result sent to driver
09:21:08.385 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 23.0 in stage 9.0 (TID 433, localhost, executor driver, partition 23, PROCESS_LOCAL, 4726 bytes)
09:21:08.385 INFO  [Executor task launch worker for task 433] org.apache.spark.executor.Executor - Running task 23.0 in stage 9.0 (TID 433)
09:21:08.385 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 24.0 in stage 9.0 (TID 434, localhost, executor driver, partition 24, PROCESS_LOCAL, 4726 bytes)
09:21:08.385 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 20.0 in stage 9.0 (TID 430) in 31 ms on localhost (executor driver) (21/200)
09:21:08.385 INFO  [Executor task launch worker for task 434] org.apache.spark.executor.Executor - Running task 24.0 in stage 9.0 (TID 434)
09:21:08.385 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 21.0 in stage 9.0 (TID 431) in 16 ms on localhost (executor driver) (22/200)
09:21:08.385 INFO  [Executor task launch worker for task 432] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=22),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/22] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/22/3.delta
09:21:08.385 INFO  [Executor task launch worker for task 434] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=24), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/24] for update
09:21:08.385 INFO  [Executor task launch worker for task 434] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=24), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/24] for update
09:21:08.385 INFO  [Executor task launch worker for task 433] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=23), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/23] for update
09:21:08.385 INFO  [Executor task launch worker for task 432] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=22),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/22]
09:21:08.401 INFO  [Executor task launch worker for task 434] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.401 INFO  [Executor task launch worker for task 433] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=23), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/23] for update
09:21:08.401 INFO  [Executor task launch worker for task 434] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.401 INFO  [Executor task launch worker for task 433] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.401 INFO  [Executor task launch worker for task 433] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.401 INFO  [Executor task launch worker for task 432] org.apache.spark.executor.Executor - Finished task 22.0 in stage 9.0 (TID 432). 3322 bytes result sent to driver
09:21:08.401 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 25.0 in stage 9.0 (TID 435, localhost, executor driver, partition 25, PROCESS_LOCAL, 4726 bytes)
09:21:08.401 INFO  [Executor task launch worker for task 435] org.apache.spark.executor.Executor - Running task 25.0 in stage 9.0 (TID 435)
09:21:08.401 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 22.0 in stage 9.0 (TID 432) in 32 ms on localhost (executor driver) (23/200)
09:21:08.401 INFO  [Executor task launch worker for task 435] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=25), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/25] for update
09:21:08.401 INFO  [Executor task launch worker for task 435] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=25), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/25] for update
09:21:08.401 INFO  [Executor task launch worker for task 435] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.401 INFO  [Executor task launch worker for task 435] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.416 INFO  [Executor task launch worker for task 434] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=24),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/24] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/24/3.delta
09:21:08.416 INFO  [Executor task launch worker for task 433] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=23),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/23] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/23/3.delta
09:21:08.416 INFO  [Executor task launch worker for task 435] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=25),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/25] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/25/3.delta
09:21:08.416 INFO  [Executor task launch worker for task 433] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=23),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/23]
09:21:08.416 INFO  [Executor task launch worker for task 434] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=24),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/24]
09:21:08.416 INFO  [Executor task launch worker for task 433] org.apache.spark.executor.Executor - Finished task 23.0 in stage 9.0 (TID 433). 3365 bytes result sent to driver
09:21:08.416 INFO  [Executor task launch worker for task 434] org.apache.spark.executor.Executor - Finished task 24.0 in stage 9.0 (TID 434). 3365 bytes result sent to driver
09:21:08.416 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 26.0 in stage 9.0 (TID 436, localhost, executor driver, partition 26, PROCESS_LOCAL, 4726 bytes)
09:21:08.416 INFO  [Executor task launch worker for task 436] org.apache.spark.executor.Executor - Running task 26.0 in stage 9.0 (TID 436)
09:21:08.416 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 27.0 in stage 9.0 (TID 437, localhost, executor driver, partition 27, PROCESS_LOCAL, 4726 bytes)
09:21:08.416 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 24.0 in stage 9.0 (TID 434) in 31 ms on localhost (executor driver) (24/200)
09:21:08.416 INFO  [Executor task launch worker for task 437] org.apache.spark.executor.Executor - Running task 27.0 in stage 9.0 (TID 437)
09:21:08.416 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 23.0 in stage 9.0 (TID 433) in 31 ms on localhost (executor driver) (25/200)
09:21:08.416 INFO  [Executor task launch worker for task 435] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=25),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/25]
09:21:08.416 INFO  [Executor task launch worker for task 435] org.apache.spark.executor.Executor - Finished task 25.0 in stage 9.0 (TID 435). 3365 bytes result sent to driver
09:21:08.416 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 28.0 in stage 9.0 (TID 438, localhost, executor driver, partition 28, PROCESS_LOCAL, 4726 bytes)
09:21:08.432 INFO  [Executor task launch worker for task 438] org.apache.spark.executor.Executor - Running task 28.0 in stage 9.0 (TID 438)
09:21:08.432 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 25.0 in stage 9.0 (TID 435) in 31 ms on localhost (executor driver) (26/200)
09:21:08.432 INFO  [Executor task launch worker for task 437] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=27), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/27] for update
09:21:08.432 INFO  [Executor task launch worker for task 436] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=26), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/26] for update
09:21:08.432 INFO  [Executor task launch worker for task 437] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=27), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/27] for update
09:21:08.432 INFO  [Executor task launch worker for task 436] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=26), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/26] for update
09:21:08.432 INFO  [Executor task launch worker for task 437] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.432 INFO  [Executor task launch worker for task 436] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.432 INFO  [Executor task launch worker for task 437] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.432 INFO  [Executor task launch worker for task 436] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.432 INFO  [Executor task launch worker for task 438] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=28), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/28] for update
09:21:08.432 INFO  [Executor task launch worker for task 438] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=28), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/28] for update
09:21:08.432 INFO  [Executor task launch worker for task 438] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.432 INFO  [Executor task launch worker for task 438] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.432 INFO  [Executor task launch worker for task 436] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=26),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/26] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/26/3.delta
09:21:08.432 INFO  [Executor task launch worker for task 437] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=27),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/27] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/27/3.delta
09:21:08.448 INFO  [Executor task launch worker for task 438] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=28),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/28] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/28/3.delta
09:21:08.448 INFO  [Executor task launch worker for task 436] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=26),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/26]
09:21:08.448 INFO  [Executor task launch worker for task 436] org.apache.spark.executor.Executor - Finished task 26.0 in stage 9.0 (TID 436). 3451 bytes result sent to driver
09:21:08.448 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 29.0 in stage 9.0 (TID 439, localhost, executor driver, partition 29, PROCESS_LOCAL, 4726 bytes)
09:21:08.448 INFO  [Executor task launch worker for task 439] org.apache.spark.executor.Executor - Running task 29.0 in stage 9.0 (TID 439)
09:21:08.448 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 26.0 in stage 9.0 (TID 436) in 32 ms on localhost (executor driver) (27/200)
09:21:08.448 INFO  [Executor task launch worker for task 438] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=28),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/28]
09:21:08.448 INFO  [Executor task launch worker for task 438] org.apache.spark.executor.Executor - Finished task 28.0 in stage 9.0 (TID 438). 3365 bytes result sent to driver
09:21:08.448 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 30.0 in stage 9.0 (TID 440, localhost, executor driver, partition 30, PROCESS_LOCAL, 4726 bytes)
09:21:08.448 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 28.0 in stage 9.0 (TID 438) in 32 ms on localhost (executor driver) (28/200)
09:21:08.448 INFO  [Executor task launch worker for task 440] org.apache.spark.executor.Executor - Running task 30.0 in stage 9.0 (TID 440)
09:21:08.448 INFO  [Executor task launch worker for task 440] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=30), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/30] for update
09:21:08.448 INFO  [Executor task launch worker for task 439] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=29), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/29] for update
09:21:08.448 INFO  [Executor task launch worker for task 440] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=30), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/30] for update
09:21:08.448 INFO  [Executor task launch worker for task 439] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=29), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/29] for update
09:21:08.448 INFO  [Executor task launch worker for task 440] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.448 INFO  [Executor task launch worker for task 439] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.448 INFO  [Executor task launch worker for task 437] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=27),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/27]
09:21:08.463 INFO  [Executor task launch worker for task 440] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 15 ms
09:21:08.463 INFO  [Executor task launch worker for task 439] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 15 ms
09:21:08.463 INFO  [Executor task launch worker for task 437] org.apache.spark.executor.Executor - Finished task 27.0 in stage 9.0 (TID 437). 3451 bytes result sent to driver
09:21:08.463 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 31.0 in stage 9.0 (TID 441, localhost, executor driver, partition 31, PROCESS_LOCAL, 4726 bytes)
09:21:08.463 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 27.0 in stage 9.0 (TID 437) in 47 ms on localhost (executor driver) (29/200)
09:21:08.463 INFO  [Executor task launch worker for task 441] org.apache.spark.executor.Executor - Running task 31.0 in stage 9.0 (TID 441)
09:21:08.463 INFO  [Executor task launch worker for task 441] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=31), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/31] for update
09:21:08.463 INFO  [Executor task launch worker for task 441] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=31), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/31] for update
09:21:08.463 INFO  [Executor task launch worker for task 441] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.463 INFO  [Executor task launch worker for task 441] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.463 INFO  [Executor task launch worker for task 440] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=30),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/30] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/30/3.delta
09:21:08.463 INFO  [Executor task launch worker for task 440] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=30),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/30]
09:21:08.463 INFO  [Executor task launch worker for task 439] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=29),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/29] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/29/3.delta
09:21:08.463 INFO  [Executor task launch worker for task 440] org.apache.spark.executor.Executor - Finished task 30.0 in stage 9.0 (TID 440). 3322 bytes result sent to driver
09:21:08.479 INFO  [Executor task launch worker for task 441] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=31),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/31] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/31/3.delta
09:21:08.479 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 32.0 in stage 9.0 (TID 442, localhost, executor driver, partition 32, PROCESS_LOCAL, 4726 bytes)
09:21:08.479 INFO  [Executor task launch worker for task 442] org.apache.spark.executor.Executor - Running task 32.0 in stage 9.0 (TID 442)
09:21:08.479 INFO  [Executor task launch worker for task 439] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=29),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/29]
09:21:08.479 INFO  [Executor task launch worker for task 439] org.apache.spark.executor.Executor - Finished task 29.0 in stage 9.0 (TID 439). 3365 bytes result sent to driver
09:21:08.479 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 30.0 in stage 9.0 (TID 440) in 31 ms on localhost (executor driver) (30/200)
09:21:08.479 INFO  [Executor task launch worker for task 442] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=32), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/32] for update
09:21:08.479 INFO  [Executor task launch worker for task 442] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=32), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/32] for update
09:21:08.479 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 33.0 in stage 9.0 (TID 443, localhost, executor driver, partition 33, PROCESS_LOCAL, 4726 bytes)
09:21:08.479 INFO  [Executor task launch worker for task 442] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.479 INFO  [Executor task launch worker for task 442] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.479 INFO  [Executor task launch worker for task 443] org.apache.spark.executor.Executor - Running task 33.0 in stage 9.0 (TID 443)
09:21:08.479 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 29.0 in stage 9.0 (TID 439) in 31 ms on localhost (executor driver) (31/200)
09:21:08.479 INFO  [Executor task launch worker for task 441] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=31),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/31]
09:21:08.479 INFO  [Executor task launch worker for task 443] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=33), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/33] for update
09:21:08.479 INFO  [Executor task launch worker for task 441] org.apache.spark.executor.Executor - Finished task 31.0 in stage 9.0 (TID 441). 3365 bytes result sent to driver
09:21:08.479 INFO  [Executor task launch worker for task 442] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=32),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/32] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/32/3.delta
09:21:08.479 INFO  [Executor task launch worker for task 443] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=33), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/33] for update
09:21:08.494 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 34.0 in stage 9.0 (TID 444, localhost, executor driver, partition 34, PROCESS_LOCAL, 4726 bytes)
09:21:08.494 INFO  [Executor task launch worker for task 443] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.494 INFO  [Executor task launch worker for task 443] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.494 INFO  [Executor task launch worker for task 444] org.apache.spark.executor.Executor - Running task 34.0 in stage 9.0 (TID 444)
09:21:08.494 INFO  [Executor task launch worker for task 444] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=34), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/34] for update
09:21:08.494 INFO  [Executor task launch worker for task 444] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=34), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/34] for update
09:21:08.494 INFO  [Executor task launch worker for task 444] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
09:21:08.494 INFO  [Executor task launch worker for task 444] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.494 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 31.0 in stage 9.0 (TID 441) in 31 ms on localhost (executor driver) (32/200)
09:21:08.494 INFO  [Executor task launch worker for task 442] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=32),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/32]
09:21:08.494 INFO  [Executor task launch worker for task 442] org.apache.spark.executor.Executor - Finished task 32.0 in stage 9.0 (TID 442). 3322 bytes result sent to driver
09:21:08.494 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 35.0 in stage 9.0 (TID 445, localhost, executor driver, partition 35, PROCESS_LOCAL, 4726 bytes)
09:21:08.510 INFO  [Executor task launch worker for task 445] org.apache.spark.executor.Executor - Running task 35.0 in stage 9.0 (TID 445)
09:21:08.510 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 32.0 in stage 9.0 (TID 442) in 31 ms on localhost (executor driver) (33/200)
09:21:08.510 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner - Cleaned accumulator 272
09:21:08.510 INFO  [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerInfo - Removed broadcast_14_piece0 on 172.16.2.246:51465 in memory (size: 10.7 KB, free: 1954.4 MB)
09:21:08.510 INFO  [Executor task launch worker for task 445] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=35), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/35] for update
09:21:08.510 INFO  [dispatcher-event-loop-5] org.apache.spark.storage.BlockManagerInfo - Removed broadcast_10_piece0 on 172.16.2.246:51465 in memory (size: 4.6 KB, free: 1954.4 MB)
09:21:08.510 INFO  [Executor task launch worker for task 445] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=35), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/35] for update
09:21:08.510 INFO  [Executor task launch worker for task 445] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.510 INFO  [Executor task launch worker for task 445] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.510 INFO  [Executor task launch worker for task 443] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=33),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/33] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/33/3.delta
09:21:08.510 INFO  [Spark Context Cleaner] org.apache.spark.ContextCleaner - Cleaned accumulator 223
09:21:08.510 INFO  [dispatcher-event-loop-2] org.apache.spark.storage.BlockManagerInfo - Removed broadcast_11_piece0 on 172.16.2.246:51465 in memory (size: 4.6 KB, free: 1954.4 MB)
09:21:08.510 INFO  [Executor task launch worker for task 445] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=35),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/35] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/35/3.delta
09:21:08.510 INFO  [Executor task launch worker for task 443] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=33),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/33]
09:21:08.510 INFO  [Executor task launch worker for task 443] org.apache.spark.executor.Executor - Finished task 33.0 in stage 9.0 (TID 443). 3365 bytes result sent to driver
09:21:08.510 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 36.0 in stage 9.0 (TID 446, localhost, executor driver, partition 36, PROCESS_LOCAL, 4726 bytes)
09:21:08.510 INFO  [Executor task launch worker for task 446] org.apache.spark.executor.Executor - Running task 36.0 in stage 9.0 (TID 446)
09:21:08.510 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 33.0 in stage 9.0 (TID 443) in 31 ms on localhost (executor driver) (34/200)
09:21:08.526 INFO  [Executor task launch worker for task 445] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=35),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/35]
09:21:08.526 INFO  [Executor task launch worker for task 445] org.apache.spark.executor.Executor - Finished task 35.0 in stage 9.0 (TID 445). 3365 bytes result sent to driver
09:21:08.526 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 37.0 in stage 9.0 (TID 447, localhost, executor driver, partition 37, PROCESS_LOCAL, 4726 bytes)
09:21:08.526 INFO  [Executor task launch worker for task 446] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=36), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/36] for update
09:21:08.526 INFO  [Executor task launch worker for task 447] org.apache.spark.executor.Executor - Running task 37.0 in stage 9.0 (TID 447)
09:21:08.526 INFO  [Executor task launch worker for task 446] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=36), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/36] for update
09:21:08.526 INFO  [Executor task launch worker for task 446] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 non-empty blocks out of 1 blocks
09:21:08.526 INFO  [Executor task launch worker for task 446] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.526 INFO  [Executor task launch worker for task 444] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=34),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/34] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/34/3.delta
09:21:08.526 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 35.0 in stage 9.0 (TID 445) in 32 ms on localhost (executor driver) (35/200)
09:21:08.526 INFO  [Executor task launch worker for task 447] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=37), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/37] for update
09:21:08.526 INFO  [Executor task launch worker for task 447] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=37), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/37] for update
09:21:08.526 INFO  [Executor task launch worker for task 447] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.526 INFO  [Executor task launch worker for task 444] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=34),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/34]
09:21:08.526 INFO  [Executor task launch worker for task 444] org.apache.spark.executor.Executor - Finished task 34.0 in stage 9.0 (TID 444). 3437 bytes result sent to driver
09:21:08.526 INFO  [Executor task launch worker for task 446] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=36),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/36] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/36/3.delta
09:21:08.526 INFO  [Executor task launch worker for task 447] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.526 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 38.0 in stage 9.0 (TID 448, localhost, executor driver, partition 38, PROCESS_LOCAL, 4726 bytes)
09:21:08.541 INFO  [Executor task launch worker for task 448] org.apache.spark.executor.Executor - Running task 38.0 in stage 9.0 (TID 448)
09:21:08.541 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 34.0 in stage 9.0 (TID 444) in 47 ms on localhost (executor driver) (36/200)
09:21:08.541 INFO  [Executor task launch worker for task 448] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=38), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/38] for update
09:21:08.541 INFO  [Executor task launch worker for task 448] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=38), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/38] for update
09:21:08.541 INFO  [Executor task launch worker for task 448] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.541 INFO  [Executor task launch worker for task 448] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.541 INFO  [Executor task launch worker for task 446] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=36),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/36]
09:21:08.541 INFO  [Executor task launch worker for task 446] org.apache.spark.executor.Executor - Finished task 36.0 in stage 9.0 (TID 446). 3394 bytes result sent to driver
09:21:08.541 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 39.0 in stage 9.0 (TID 449, localhost, executor driver, partition 39, PROCESS_LOCAL, 4726 bytes)
09:21:08.541 INFO  [Executor task launch worker for task 449] org.apache.spark.executor.Executor - Running task 39.0 in stage 9.0 (TID 449)
09:21:08.541 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 36.0 in stage 9.0 (TID 446) in 31 ms on localhost (executor driver) (37/200)
09:21:08.541 INFO  [Executor task launch worker for task 449] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=39), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/39] for update
09:21:08.541 INFO  [Executor task launch worker for task 449] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=39), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/39] for update
09:21:08.541 INFO  [Executor task launch worker for task 447] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=37),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/37] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/37/3.delta
09:21:08.541 INFO  [Executor task launch worker for task 449] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.541 INFO  [Executor task launch worker for task 449] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.541 INFO  [Executor task launch worker for task 448] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=38),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/38] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/38/3.delta
09:21:08.541 INFO  [Executor task launch worker for task 447] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=37),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/37]
09:21:08.541 INFO  [Executor task launch worker for task 449] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=39),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/39] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/39/3.delta
09:21:08.557 INFO  [Executor task launch worker for task 447] org.apache.spark.executor.Executor - Finished task 37.0 in stage 9.0 (TID 447). 3322 bytes result sent to driver
09:21:08.557 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 40.0 in stage 9.0 (TID 450, localhost, executor driver, partition 40, PROCESS_LOCAL, 4726 bytes)
09:21:08.557 INFO  [Executor task launch worker for task 450] org.apache.spark.executor.Executor - Running task 40.0 in stage 9.0 (TID 450)
09:21:08.557 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 37.0 in stage 9.0 (TID 447) in 31 ms on localhost (executor driver) (38/200)
09:21:08.557 INFO  [Executor task launch worker for task 450] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=40), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/40] for update
09:21:08.557 INFO  [Executor task launch worker for task 450] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=40), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/40] for update
09:21:08.557 INFO  [Executor task launch worker for task 450] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.557 INFO  [Executor task launch worker for task 450] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.557 INFO  [Executor task launch worker for task 449] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=39),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/39]
09:21:08.557 INFO  [Executor task launch worker for task 448] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=38),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/38]
09:21:08.557 INFO  [Executor task launch worker for task 448] org.apache.spark.executor.Executor - Finished task 38.0 in stage 9.0 (TID 448). 3322 bytes result sent to driver
09:21:08.557 INFO  [Executor task launch worker for task 449] org.apache.spark.executor.Executor - Finished task 39.0 in stage 9.0 (TID 449). 3322 bytes result sent to driver
09:21:08.557 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 41.0 in stage 9.0 (TID 451, localhost, executor driver, partition 41, PROCESS_LOCAL, 4726 bytes)
09:21:08.557 INFO  [Executor task launch worker for task 451] org.apache.spark.executor.Executor - Running task 41.0 in stage 9.0 (TID 451)
09:21:08.557 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 42.0 in stage 9.0 (TID 452, localhost, executor driver, partition 42, PROCESS_LOCAL, 4726 bytes)
09:21:08.557 INFO  [Executor task launch worker for task 452] org.apache.spark.executor.Executor - Running task 42.0 in stage 9.0 (TID 452)
09:21:08.557 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 38.0 in stage 9.0 (TID 448) in 31 ms on localhost (executor driver) (39/200)
09:21:08.557 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 39.0 in stage 9.0 (TID 449) in 16 ms on localhost (executor driver) (40/200)
09:21:08.557 INFO  [Executor task launch worker for task 451] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=41), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/41] for update
09:21:08.557 INFO  [Executor task launch worker for task 452] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=42), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/42] for update
09:21:08.557 INFO  [Executor task launch worker for task 450] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=40),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/40] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/40/3.delta
09:21:08.573 INFO  [Executor task launch worker for task 451] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=41), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/41] for update
09:21:08.573 INFO  [Executor task launch worker for task 452] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=42), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/42] for update
09:21:08.573 INFO  [Executor task launch worker for task 451] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.573 INFO  [Executor task launch worker for task 452] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.573 INFO  [Executor task launch worker for task 451] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.573 INFO  [Executor task launch worker for task 452] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.573 INFO  [Executor task launch worker for task 450] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=40),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/40]
09:21:08.573 INFO  [Executor task launch worker for task 450] org.apache.spark.executor.Executor - Finished task 40.0 in stage 9.0 (TID 450). 3322 bytes result sent to driver
09:21:08.573 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 43.0 in stage 9.0 (TID 453, localhost, executor driver, partition 43, PROCESS_LOCAL, 4726 bytes)
09:21:08.573 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 40.0 in stage 9.0 (TID 450) in 16 ms on localhost (executor driver) (41/200)
09:21:08.573 INFO  [Executor task launch worker for task 453] org.apache.spark.executor.Executor - Running task 43.0 in stage 9.0 (TID 453)
09:21:08.573 INFO  [Executor task launch worker for task 452] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=42),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/42] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/42/3.delta
09:21:08.573 INFO  [Executor task launch worker for task 451] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=41),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/41] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/41/3.delta
09:21:08.573 INFO  [Executor task launch worker for task 453] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=43), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/43] for update
09:21:08.573 INFO  [Executor task launch worker for task 453] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=43), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/43] for update
09:21:08.573 INFO  [Executor task launch worker for task 453] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.573 INFO  [Executor task launch worker for task 453] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.573 INFO  [Executor task launch worker for task 452] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=42),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/42]
09:21:08.573 INFO  [Executor task launch worker for task 451] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=41),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/41]
09:21:08.573 INFO  [Executor task launch worker for task 453] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=43),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/43] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/43/3.delta
09:21:08.588 INFO  [Executor task launch worker for task 451] org.apache.spark.executor.Executor - Finished task 41.0 in stage 9.0 (TID 451). 3322 bytes result sent to driver
09:21:08.588 INFO  [Executor task launch worker for task 452] org.apache.spark.executor.Executor - Finished task 42.0 in stage 9.0 (TID 452). 3322 bytes result sent to driver
09:21:08.588 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 44.0 in stage 9.0 (TID 454, localhost, executor driver, partition 44, PROCESS_LOCAL, 4726 bytes)
09:21:08.588 INFO  [Executor task launch worker for task 454] org.apache.spark.executor.Executor - Running task 44.0 in stage 9.0 (TID 454)
09:21:08.588 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 45.0 in stage 9.0 (TID 455, localhost, executor driver, partition 45, PROCESS_LOCAL, 4726 bytes)
09:21:08.588 INFO  [Executor task launch worker for task 455] org.apache.spark.executor.Executor - Running task 45.0 in stage 9.0 (TID 455)
09:21:08.588 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 42.0 in stage 9.0 (TID 452) in 31 ms on localhost (executor driver) (42/200)
09:21:08.588 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 41.0 in stage 9.0 (TID 451) in 31 ms on localhost (executor driver) (43/200)
09:21:08.588 INFO  [Executor task launch worker for task 454] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=44), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/44] for update
09:21:08.588 INFO  [Executor task launch worker for task 454] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=44), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/44] for update
09:21:08.588 INFO  [Executor task launch worker for task 455] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=45), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/45] for update
09:21:08.588 INFO  [Executor task launch worker for task 454] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.588 INFO  [Executor task launch worker for task 454] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.588 INFO  [Executor task launch worker for task 455] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=45), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/45] for update
09:21:08.588 INFO  [Executor task launch worker for task 455] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.588 INFO  [Executor task launch worker for task 455] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.588 INFO  [Executor task launch worker for task 454] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=44),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/44] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/44/3.delta
09:21:08.588 INFO  [Executor task launch worker for task 453] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=43),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/43]
09:21:08.604 INFO  [Executor task launch worker for task 453] org.apache.spark.executor.Executor - Finished task 43.0 in stage 9.0 (TID 453). 3322 bytes result sent to driver
09:21:08.604 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 46.0 in stage 9.0 (TID 456, localhost, executor driver, partition 46, PROCESS_LOCAL, 4726 bytes)
09:21:08.604 INFO  [Executor task launch worker for task 456] org.apache.spark.executor.Executor - Running task 46.0 in stage 9.0 (TID 456)
09:21:08.604 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 43.0 in stage 9.0 (TID 453) in 31 ms on localhost (executor driver) (44/200)
09:21:08.604 INFO  [Executor task launch worker for task 456] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=46), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/46] for update
09:21:08.604 INFO  [Executor task launch worker for task 456] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=46), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/46] for update
09:21:08.604 INFO  [Executor task launch worker for task 456] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.604 INFO  [Executor task launch worker for task 456] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.604 INFO  [Executor task launch worker for task 454] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=44),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/44]
09:21:08.604 INFO  [Executor task launch worker for task 454] org.apache.spark.executor.Executor - Finished task 44.0 in stage 9.0 (TID 454). 3322 bytes result sent to driver
09:21:08.604 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 47.0 in stage 9.0 (TID 457, localhost, executor driver, partition 47, PROCESS_LOCAL, 4726 bytes)
09:21:08.604 INFO  [Executor task launch worker for task 457] org.apache.spark.executor.Executor - Running task 47.0 in stage 9.0 (TID 457)
09:21:08.604 INFO  [Executor task launch worker for task 455] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=45),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/45] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/45/3.delta
09:21:08.604 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 44.0 in stage 9.0 (TID 454) in 16 ms on localhost (executor driver) (45/200)
09:21:08.604 INFO  [Executor task launch worker for task 457] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=47), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/47] for update
09:21:08.604 INFO  [Executor task launch worker for task 457] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=47), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/47] for update
09:21:08.604 INFO  [Executor task launch worker for task 455] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=45),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/45]
09:21:08.604 INFO  [Executor task launch worker for task 456] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=46),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/46] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/46/3.delta
09:21:08.619 INFO  [Executor task launch worker for task 457] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.619 INFO  [Executor task launch worker for task 457] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.619 INFO  [Executor task launch worker for task 455] org.apache.spark.executor.Executor - Finished task 45.0 in stage 9.0 (TID 455). 3322 bytes result sent to driver
09:21:08.619 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 48.0 in stage 9.0 (TID 458, localhost, executor driver, partition 48, PROCESS_LOCAL, 4726 bytes)
09:21:08.619 INFO  [Executor task launch worker for task 458] org.apache.spark.executor.Executor - Running task 48.0 in stage 9.0 (TID 458)
09:21:08.619 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 45.0 in stage 9.0 (TID 455) in 31 ms on localhost (executor driver) (46/200)
09:21:08.619 INFO  [Executor task launch worker for task 458] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=48), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/48] for update
09:21:08.619 INFO  [Executor task launch worker for task 458] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=48), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/48] for update
09:21:08.619 INFO  [Executor task launch worker for task 458] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.619 INFO  [Executor task launch worker for task 458] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.619 INFO  [Executor task launch worker for task 456] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=46),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/46]
09:21:08.619 INFO  [Executor task launch worker for task 456] org.apache.spark.executor.Executor - Finished task 46.0 in stage 9.0 (TID 456). 3322 bytes result sent to driver
09:21:08.619 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 49.0 in stage 9.0 (TID 459, localhost, executor driver, partition 49, PROCESS_LOCAL, 4726 bytes)
09:21:08.619 INFO  [Executor task launch worker for task 459] org.apache.spark.executor.Executor - Running task 49.0 in stage 9.0 (TID 459)
09:21:08.619 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 46.0 in stage 9.0 (TID 456) in 15 ms on localhost (executor driver) (47/200)
09:21:08.619 INFO  [Executor task launch worker for task 457] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=47),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/47] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/47/3.delta
09:21:08.619 INFO  [Executor task launch worker for task 459] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=49), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/49] for update
09:21:08.619 INFO  [Executor task launch worker for task 458] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=48),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/48] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/48/3.delta
09:21:08.619 INFO  [Executor task launch worker for task 457] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=47),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/47]
09:21:08.635 INFO  [Executor task launch worker for task 459] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=49), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/49] for update
09:21:08.635 INFO  [Executor task launch worker for task 459] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.635 INFO  [Executor task launch worker for task 459] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.635 INFO  [Executor task launch worker for task 457] org.apache.spark.executor.Executor - Finished task 47.0 in stage 9.0 (TID 457). 3322 bytes result sent to driver
09:21:08.635 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 50.0 in stage 9.0 (TID 460, localhost, executor driver, partition 50, PROCESS_LOCAL, 4726 bytes)
09:21:08.635 INFO  [Executor task launch worker for task 460] org.apache.spark.executor.Executor - Running task 50.0 in stage 9.0 (TID 460)
09:21:08.635 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 47.0 in stage 9.0 (TID 457) in 31 ms on localhost (executor driver) (48/200)
09:21:08.635 INFO  [Executor task launch worker for task 460] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=50), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/50] for update
09:21:08.635 INFO  [Executor task launch worker for task 460] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=50), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/50] for update
09:21:08.635 INFO  [Executor task launch worker for task 460] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.635 INFO  [Executor task launch worker for task 460] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.635 INFO  [Executor task launch worker for task 458] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=48),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/48]
09:21:08.635 INFO  [Executor task launch worker for task 458] org.apache.spark.executor.Executor - Finished task 48.0 in stage 9.0 (TID 458). 3322 bytes result sent to driver
09:21:08.635 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 51.0 in stage 9.0 (TID 461, localhost, executor driver, partition 51, PROCESS_LOCAL, 4726 bytes)
09:21:08.635 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 48.0 in stage 9.0 (TID 458) in 16 ms on localhost (executor driver) (49/200)
09:21:08.635 INFO  [Executor task launch worker for task 461] org.apache.spark.executor.Executor - Running task 51.0 in stage 9.0 (TID 461)
09:21:08.635 INFO  [Executor task launch worker for task 459] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=49),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/49] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/49/3.delta
09:21:08.635 INFO  [Executor task launch worker for task 461] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=51), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/51] for update
09:21:08.635 INFO  [Executor task launch worker for task 460] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=50),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/50] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/50/3.delta
09:21:08.635 INFO  [Executor task launch worker for task 459] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=49),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/49]
09:21:08.651 INFO  [Executor task launch worker for task 461] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=51), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/51] for update
09:21:08.651 INFO  [Executor task launch worker for task 461] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.651 INFO  [Executor task launch worker for task 461] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.651 INFO  [Executor task launch worker for task 459] org.apache.spark.executor.Executor - Finished task 49.0 in stage 9.0 (TID 459). 3322 bytes result sent to driver
09:21:08.651 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 52.0 in stage 9.0 (TID 462, localhost, executor driver, partition 52, PROCESS_LOCAL, 4726 bytes)
09:21:08.651 INFO  [Executor task launch worker for task 462] org.apache.spark.executor.Executor - Running task 52.0 in stage 9.0 (TID 462)
09:21:08.651 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 49.0 in stage 9.0 (TID 459) in 32 ms on localhost (executor driver) (50/200)
09:21:08.651 INFO  [Executor task launch worker for task 462] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=52), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/52] for update
09:21:08.651 INFO  [Executor task launch worker for task 462] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=52), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/52] for update
09:21:08.651 INFO  [Executor task launch worker for task 462] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.651 INFO  [Executor task launch worker for task 462] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.651 INFO  [Executor task launch worker for task 460] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=50),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/50]
09:21:08.651 INFO  [Executor task launch worker for task 460] org.apache.spark.executor.Executor - Finished task 50.0 in stage 9.0 (TID 460). 3322 bytes result sent to driver
09:21:08.651 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 53.0 in stage 9.0 (TID 463, localhost, executor driver, partition 53, PROCESS_LOCAL, 4726 bytes)
09:21:08.651 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 50.0 in stage 9.0 (TID 460) in 16 ms on localhost (executor driver) (51/200)
09:21:08.651 INFO  [Executor task launch worker for task 463] org.apache.spark.executor.Executor - Running task 53.0 in stage 9.0 (TID 463)
09:21:08.651 INFO  [Executor task launch worker for task 461] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=51),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/51] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/51/3.delta
09:21:08.651 INFO  [Executor task launch worker for task 463] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=53), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/53] for update
09:21:08.651 INFO  [Executor task launch worker for task 462] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=52),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/52] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/52/3.delta
09:21:08.651 INFO  [Executor task launch worker for task 461] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=51),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/51]
09:21:08.666 INFO  [Executor task launch worker for task 463] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=53), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/53] for update
09:21:08.666 INFO  [Executor task launch worker for task 463] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.666 INFO  [Executor task launch worker for task 461] org.apache.spark.executor.Executor - Finished task 51.0 in stage 9.0 (TID 461). 3322 bytes result sent to driver
09:21:08.666 INFO  [Executor task launch worker for task 463] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.666 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 54.0 in stage 9.0 (TID 464, localhost, executor driver, partition 54, PROCESS_LOCAL, 4726 bytes)
09:21:08.666 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 51.0 in stage 9.0 (TID 461) in 31 ms on localhost (executor driver) (52/200)
09:21:08.666 INFO  [Executor task launch worker for task 464] org.apache.spark.executor.Executor - Running task 54.0 in stage 9.0 (TID 464)
09:21:08.666 INFO  [Executor task launch worker for task 464] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=54), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/54] for update
09:21:08.666 INFO  [Executor task launch worker for task 464] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=54), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/54] for update
09:21:08.666 INFO  [Executor task launch worker for task 464] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.666 INFO  [Executor task launch worker for task 464] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.666 INFO  [Executor task launch worker for task 462] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=52),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/52]
09:21:08.666 INFO  [Executor task launch worker for task 462] org.apache.spark.executor.Executor - Finished task 52.0 in stage 9.0 (TID 462). 3322 bytes result sent to driver
09:21:08.666 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 55.0 in stage 9.0 (TID 465, localhost, executor driver, partition 55, PROCESS_LOCAL, 4726 bytes)
09:21:08.666 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 52.0 in stage 9.0 (TID 462) in 15 ms on localhost (executor driver) (53/200)
09:21:08.666 INFO  [Executor task launch worker for task 465] org.apache.spark.executor.Executor - Running task 55.0 in stage 9.0 (TID 465)
09:21:08.666 INFO  [Executor task launch worker for task 463] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=53),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/53] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/53/3.delta
09:21:08.666 INFO  [Executor task launch worker for task 465] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=55), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/55] for update
09:21:08.666 INFO  [Executor task launch worker for task 464] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=54),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/54] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/54/3.delta
09:21:08.666 INFO  [Executor task launch worker for task 463] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=53),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/53]
09:21:08.682 INFO  [Executor task launch worker for task 465] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=55), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/55] for update
09:21:08.682 INFO  [Executor task launch worker for task 465] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.682 INFO  [Executor task launch worker for task 465] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.682 INFO  [Executor task launch worker for task 463] org.apache.spark.executor.Executor - Finished task 53.0 in stage 9.0 (TID 463). 3322 bytes result sent to driver
09:21:08.682 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 56.0 in stage 9.0 (TID 466, localhost, executor driver, partition 56, PROCESS_LOCAL, 4726 bytes)
09:21:08.682 INFO  [Executor task launch worker for task 466] org.apache.spark.executor.Executor - Running task 56.0 in stage 9.0 (TID 466)
09:21:08.682 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 53.0 in stage 9.0 (TID 463) in 31 ms on localhost (executor driver) (54/200)
09:21:08.682 INFO  [Executor task launch worker for task 466] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=56), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/56] for update
09:21:08.682 INFO  [Executor task launch worker for task 466] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=56), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/56] for update
09:21:08.682 INFO  [Executor task launch worker for task 466] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.682 INFO  [Executor task launch worker for task 466] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.682 INFO  [Executor task launch worker for task 464] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=54),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/54]
09:21:08.682 INFO  [Executor task launch worker for task 464] org.apache.spark.executor.Executor - Finished task 54.0 in stage 9.0 (TID 464). 3322 bytes result sent to driver
09:21:08.682 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 57.0 in stage 9.0 (TID 467, localhost, executor driver, partition 57, PROCESS_LOCAL, 4726 bytes)
09:21:08.682 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 54.0 in stage 9.0 (TID 464) in 16 ms on localhost (executor driver) (55/200)
09:21:08.682 INFO  [Executor task launch worker for task 467] org.apache.spark.executor.Executor - Running task 57.0 in stage 9.0 (TID 467)
09:21:08.682 INFO  [Executor task launch worker for task 465] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=55),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/55] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/55/3.delta
09:21:08.682 INFO  [Executor task launch worker for task 467] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=57), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/57] for update
09:21:08.682 INFO  [Executor task launch worker for task 466] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=56),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/56] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/56/3.delta
09:21:08.682 INFO  [Executor task launch worker for task 465] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=55),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/55]
09:21:08.697 INFO  [Executor task launch worker for task 467] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=57), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/57] for update
09:21:08.697 INFO  [Executor task launch worker for task 467] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.697 INFO  [Executor task launch worker for task 467] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.697 INFO  [Executor task launch worker for task 465] org.apache.spark.executor.Executor - Finished task 55.0 in stage 9.0 (TID 465). 3322 bytes result sent to driver
09:21:08.697 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 58.0 in stage 9.0 (TID 468, localhost, executor driver, partition 58, PROCESS_LOCAL, 4726 bytes)
09:21:08.697 INFO  [Executor task launch worker for task 468] org.apache.spark.executor.Executor - Running task 58.0 in stage 9.0 (TID 468)
09:21:08.697 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 55.0 in stage 9.0 (TID 465) in 31 ms on localhost (executor driver) (56/200)
09:21:08.697 INFO  [Executor task launch worker for task 468] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=58), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/58] for update
09:21:08.697 INFO  [Executor task launch worker for task 468] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=58), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/58] for update
09:21:08.697 INFO  [Executor task launch worker for task 468] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.697 INFO  [Executor task launch worker for task 468] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.697 INFO  [Executor task launch worker for task 466] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=56),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/56]
09:21:08.697 INFO  [Executor task launch worker for task 466] org.apache.spark.executor.Executor - Finished task 56.0 in stage 9.0 (TID 466). 3322 bytes result sent to driver
09:21:08.697 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 59.0 in stage 9.0 (TID 469, localhost, executor driver, partition 59, PROCESS_LOCAL, 4726 bytes)
09:21:08.697 INFO  [Executor task launch worker for task 469] org.apache.spark.executor.Executor - Running task 59.0 in stage 9.0 (TID 469)
09:21:08.697 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 56.0 in stage 9.0 (TID 466) in 15 ms on localhost (executor driver) (57/200)
09:21:08.697 INFO  [Executor task launch worker for task 467] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=57),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/57] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/57/3.delta
09:21:08.697 INFO  [Executor task launch worker for task 469] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=59), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/59] for update
09:21:08.706 INFO  [Executor task launch worker for task 469] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=59), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/59] for update
09:21:08.706 INFO  [Executor task launch worker for task 469] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.706 INFO  [Executor task launch worker for task 469] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.707 INFO  [Executor task launch worker for task 468] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=58),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/58] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/58/3.delta
09:21:08.710 INFO  [Executor task launch worker for task 467] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=57),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/57]
09:21:08.710 INFO  [Executor task launch worker for task 467] org.apache.spark.executor.Executor - Finished task 57.0 in stage 9.0 (TID 467). 3322 bytes result sent to driver
09:21:08.710 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 60.0 in stage 9.0 (TID 470, localhost, executor driver, partition 60, PROCESS_LOCAL, 4726 bytes)
09:21:08.710 INFO  [Executor task launch worker for task 470] org.apache.spark.executor.Executor - Running task 60.0 in stage 9.0 (TID 470)
09:21:08.710 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 57.0 in stage 9.0 (TID 467) in 28 ms on localhost (executor driver) (58/200)
09:21:08.711 INFO  [Executor task launch worker for task 468] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=58),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/58]
09:21:08.711 INFO  [Executor task launch worker for task 468] org.apache.spark.executor.Executor - Finished task 58.0 in stage 9.0 (TID 468). 3365 bytes result sent to driver
09:21:08.711 INFO  [Executor task launch worker for task 469] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=59),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/59] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/59/3.delta
09:21:08.711 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 61.0 in stage 9.0 (TID 471, localhost, executor driver, partition 61, PROCESS_LOCAL, 4726 bytes)
09:21:08.711 INFO  [Executor task launch worker for task 471] org.apache.spark.executor.Executor - Running task 61.0 in stage 9.0 (TID 471)
09:21:08.711 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 58.0 in stage 9.0 (TID 468) in 14 ms on localhost (executor driver) (59/200)
09:21:08.712 INFO  [Executor task launch worker for task 470] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=60), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/60] for update
09:21:08.713 INFO  [Executor task launch worker for task 470] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=60), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/60] for update
09:21:08.713 INFO  [Executor task launch worker for task 470] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.713 INFO  [Executor task launch worker for task 470] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.713 INFO  [Executor task launch worker for task 471] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=61), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/61] for update
09:21:08.715 INFO  [Executor task launch worker for task 469] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=59),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/59]
09:21:08.716 INFO  [Executor task launch worker for task 471] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=61), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/61] for update
09:21:08.716 INFO  [Executor task launch worker for task 471] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.716 INFO  [Executor task launch worker for task 471] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.716 INFO  [Executor task launch worker for task 469] org.apache.spark.executor.Executor - Finished task 59.0 in stage 9.0 (TID 469). 3322 bytes result sent to driver
09:21:08.716 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 62.0 in stage 9.0 (TID 472, localhost, executor driver, partition 62, PROCESS_LOCAL, 4726 bytes)
09:21:08.716 INFO  [Executor task launch worker for task 472] org.apache.spark.executor.Executor - Running task 62.0 in stage 9.0 (TID 472)
09:21:08.717 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 59.0 in stage 9.0 (TID 469) in 19 ms on localhost (executor driver) (60/200)
09:21:08.718 INFO  [Executor task launch worker for task 470] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=60),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/60] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/60/3.delta
09:21:08.718 INFO  [Executor task launch worker for task 472] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=62), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/62] for update
09:21:08.718 INFO  [Executor task launch worker for task 472] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=62), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/62] for update
09:21:08.718 INFO  [Executor task launch worker for task 472] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.718 INFO  [Executor task launch worker for task 472] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.721 INFO  [Executor task launch worker for task 471] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=61),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/61] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/61/3.delta
09:21:08.721 INFO  [Executor task launch worker for task 470] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=60),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/60]
09:21:08.722 INFO  [Executor task launch worker for task 470] org.apache.spark.executor.Executor - Finished task 60.0 in stage 9.0 (TID 470). 3408 bytes result sent to driver
09:21:08.722 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 63.0 in stage 9.0 (TID 473, localhost, executor driver, partition 63, PROCESS_LOCAL, 4726 bytes)
09:21:08.722 INFO  [Executor task launch worker for task 473] org.apache.spark.executor.Executor - Running task 63.0 in stage 9.0 (TID 473)
09:21:08.722 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 60.0 in stage 9.0 (TID 470) in 12 ms on localhost (executor driver) (61/200)
09:21:08.723 INFO  [Executor task launch worker for task 472] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=62),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/62] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/62/3.delta
09:21:08.724 INFO  [Executor task launch worker for task 473] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=63), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/63] for update
09:21:08.724 INFO  [Executor task launch worker for task 473] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=63), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/63] for update
09:21:08.724 INFO  [Executor task launch worker for task 473] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.724 INFO  [Executor task launch worker for task 473] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.725 INFO  [Executor task launch worker for task 471] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=61),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/61]
09:21:08.725 INFO  [Executor task launch worker for task 471] org.apache.spark.executor.Executor - Finished task 61.0 in stage 9.0 (TID 471). 3408 bytes result sent to driver
09:21:08.725 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 64.0 in stage 9.0 (TID 474, localhost, executor driver, partition 64, PROCESS_LOCAL, 4726 bytes)
09:21:08.725 INFO  [Executor task launch worker for task 474] org.apache.spark.executor.Executor - Running task 64.0 in stage 9.0 (TID 474)
09:21:08.725 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 61.0 in stage 9.0 (TID 471) in 14 ms on localhost (executor driver) (62/200)
09:21:08.727 INFO  [Executor task launch worker for task 472] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=62),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/62]
09:21:08.727 INFO  [Executor task launch worker for task 472] org.apache.spark.executor.Executor - Finished task 62.0 in stage 9.0 (TID 472). 3408 bytes result sent to driver
09:21:08.727 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 65.0 in stage 9.0 (TID 475, localhost, executor driver, partition 65, PROCESS_LOCAL, 4726 bytes)
09:21:08.727 INFO  [Executor task launch worker for task 474] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=64), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/64] for update
09:21:08.727 INFO  [Executor task launch worker for task 474] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=64), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/64] for update
09:21:08.727 INFO  [Executor task launch worker for task 475] org.apache.spark.executor.Executor - Running task 65.0 in stage 9.0 (TID 475)
09:21:08.727 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 62.0 in stage 9.0 (TID 472) in 11 ms on localhost (executor driver) (63/200)
09:21:08.728 INFO  [Executor task launch worker for task 474] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.728 INFO  [Executor task launch worker for task 474] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
09:21:08.728 INFO  [Executor task launch worker for task 475] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=65), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/65] for update
09:21:08.728 INFO  [Executor task launch worker for task 475] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=65), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/65] for update
09:21:08.728 INFO  [Executor task launch worker for task 473] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=63),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/63] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/63/3.delta
09:21:08.728 INFO  [Executor task launch worker for task 475] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.728 INFO  [Executor task launch worker for task 475] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.728 INFO  [Executor task launch worker for task 473] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=63),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/63]
09:21:08.728 INFO  [Executor task launch worker for task 474] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=64),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/64] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/64/3.delta
09:21:08.728 INFO  [Executor task launch worker for task 473] org.apache.spark.executor.Executor - Finished task 63.0 in stage 9.0 (TID 473). 3365 bytes result sent to driver
09:21:08.728 INFO  [Executor task launch worker for task 475] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=65),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/65] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/65/3.delta
09:21:08.744 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 66.0 in stage 9.0 (TID 476, localhost, executor driver, partition 66, PROCESS_LOCAL, 4726 bytes)
09:21:08.744 INFO  [Executor task launch worker for task 476] org.apache.spark.executor.Executor - Running task 66.0 in stage 9.0 (TID 476)
09:21:08.744 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 63.0 in stage 9.0 (TID 473) in 22 ms on localhost (executor driver) (64/200)
09:21:08.744 INFO  [Executor task launch worker for task 476] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=66), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/66] for update
09:21:08.744 INFO  [Executor task launch worker for task 476] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=66), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/66] for update
09:21:08.744 INFO  [Executor task launch worker for task 476] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.744 INFO  [Executor task launch worker for task 476] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.744 INFO  [Executor task launch worker for task 474] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=64),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/64]
09:21:08.744 INFO  [Executor task launch worker for task 474] org.apache.spark.executor.Executor - Finished task 64.0 in stage 9.0 (TID 474). 3365 bytes result sent to driver
09:21:08.744 INFO  [Executor task launch worker for task 475] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=65),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/65]
09:21:08.744 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 67.0 in stage 9.0 (TID 477, localhost, executor driver, partition 67, PROCESS_LOCAL, 4726 bytes)
09:21:08.744 INFO  [Executor task launch worker for task 477] org.apache.spark.executor.Executor - Running task 67.0 in stage 9.0 (TID 477)
09:21:08.744 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 64.0 in stage 9.0 (TID 474) in 19 ms on localhost (executor driver) (65/200)
09:21:08.744 INFO  [Executor task launch worker for task 475] org.apache.spark.executor.Executor - Finished task 65.0 in stage 9.0 (TID 475). 3365 bytes result sent to driver
09:21:08.744 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 68.0 in stage 9.0 (TID 478, localhost, executor driver, partition 68, PROCESS_LOCAL, 4726 bytes)
09:21:08.744 INFO  [Executor task launch worker for task 478] org.apache.spark.executor.Executor - Running task 68.0 in stage 9.0 (TID 478)
09:21:08.744 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 65.0 in stage 9.0 (TID 475) in 17 ms on localhost (executor driver) (66/200)
09:21:08.759 INFO  [Executor task launch worker for task 477] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=67), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/67] for update
09:21:08.759 INFO  [Executor task launch worker for task 477] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=67), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/67] for update
09:21:08.759 INFO  [Executor task launch worker for task 477] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.759 INFO  [Executor task launch worker for task 477] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.759 INFO  [Executor task launch worker for task 478] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=68), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/68] for update
09:21:08.759 INFO  [Executor task launch worker for task 478] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=68), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/68] for update
09:21:08.759 INFO  [Executor task launch worker for task 478] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.759 INFO  [Executor task launch worker for task 478] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.759 INFO  [Executor task launch worker for task 476] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=66),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/66] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/66/3.delta
09:21:08.759 INFO  [Executor task launch worker for task 477] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=67),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/67] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/67/3.delta
09:21:08.759 INFO  [Executor task launch worker for task 478] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=68),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/68] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/68/3.delta
09:21:08.775 INFO  [Executor task launch worker for task 476] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=66),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/66]
09:21:08.775 INFO  [Executor task launch worker for task 477] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=67),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/67]
09:21:08.775 INFO  [Executor task launch worker for task 476] org.apache.spark.executor.Executor - Finished task 66.0 in stage 9.0 (TID 476). 3365 bytes result sent to driver
09:21:08.775 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 69.0 in stage 9.0 (TID 479, localhost, executor driver, partition 69, PROCESS_LOCAL, 4726 bytes)
09:21:08.775 INFO  [Executor task launch worker for task 477] org.apache.spark.executor.Executor - Finished task 67.0 in stage 9.0 (TID 477). 3451 bytes result sent to driver
09:21:08.775 INFO  [Executor task launch worker for task 479] org.apache.spark.executor.Executor - Running task 69.0 in stage 9.0 (TID 479)
09:21:08.775 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 70.0 in stage 9.0 (TID 480, localhost, executor driver, partition 70, PROCESS_LOCAL, 4726 bytes)
09:21:08.775 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 66.0 in stage 9.0 (TID 476) in 31 ms on localhost (executor driver) (67/200)
09:21:08.775 INFO  [Executor task launch worker for task 480] org.apache.spark.executor.Executor - Running task 70.0 in stage 9.0 (TID 480)
09:21:08.775 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 67.0 in stage 9.0 (TID 477) in 31 ms on localhost (executor driver) (68/200)
09:21:08.775 INFO  [Executor task launch worker for task 480] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=70), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/70] for update
09:21:08.775 INFO  [Executor task launch worker for task 480] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=70), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/70] for update
09:21:08.775 INFO  [Executor task launch worker for task 480] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.775 INFO  [Executor task launch worker for task 480] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.775 INFO  [Executor task launch worker for task 479] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=69), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/69] for update
09:21:08.775 INFO  [Executor task launch worker for task 479] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=69), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/69] for update
09:21:08.775 INFO  [Executor task launch worker for task 479] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.775 INFO  [Executor task launch worker for task 479] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.775 INFO  [Executor task launch worker for task 478] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=68),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/68]
09:21:08.775 INFO  [Executor task launch worker for task 478] org.apache.spark.executor.Executor - Finished task 68.0 in stage 9.0 (TID 478). 3451 bytes result sent to driver
09:21:08.775 INFO  [Executor task launch worker for task 479] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=69),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/69] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/69/3.delta
09:21:08.775 INFO  [Executor task launch worker for task 480] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=70),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/70] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/70/3.delta
09:21:08.790 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 71.0 in stage 9.0 (TID 481, localhost, executor driver, partition 71, PROCESS_LOCAL, 4726 bytes)
09:21:08.790 INFO  [Executor task launch worker for task 481] org.apache.spark.executor.Executor - Running task 71.0 in stage 9.0 (TID 481)
09:21:08.790 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 68.0 in stage 9.0 (TID 478) in 46 ms on localhost (executor driver) (69/200)
09:21:08.790 INFO  [Executor task launch worker for task 481] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=71), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/71] for update
09:21:08.790 INFO  [Executor task launch worker for task 481] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=71), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/71] for update
09:21:08.790 INFO  [Executor task launch worker for task 481] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.790 INFO  [Executor task launch worker for task 481] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.790 INFO  [Executor task launch worker for task 479] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=69),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/69]
09:21:08.790 INFO  [Executor task launch worker for task 480] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=70),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/70]
09:21:08.790 INFO  [Executor task launch worker for task 479] org.apache.spark.executor.Executor - Finished task 69.0 in stage 9.0 (TID 479). 3322 bytes result sent to driver
09:21:08.790 INFO  [Executor task launch worker for task 480] org.apache.spark.executor.Executor - Finished task 70.0 in stage 9.0 (TID 480). 3322 bytes result sent to driver
09:21:08.790 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 72.0 in stage 9.0 (TID 482, localhost, executor driver, partition 72, PROCESS_LOCAL, 4726 bytes)
09:21:08.790 INFO  [Executor task launch worker for task 482] org.apache.spark.executor.Executor - Running task 72.0 in stage 9.0 (TID 482)
09:21:08.790 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 73.0 in stage 9.0 (TID 483, localhost, executor driver, partition 73, PROCESS_LOCAL, 4726 bytes)
09:21:08.790 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 69.0 in stage 9.0 (TID 479) in 15 ms on localhost (executor driver) (70/200)
09:21:08.790 INFO  [Executor task launch worker for task 483] org.apache.spark.executor.Executor - Running task 73.0 in stage 9.0 (TID 483)
09:21:08.790 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 70.0 in stage 9.0 (TID 480) in 15 ms on localhost (executor driver) (71/200)
09:21:08.790 INFO  [Executor task launch worker for task 483] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=73), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/73] for update
09:21:08.790 INFO  [Executor task launch worker for task 482] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=72), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/72] for update
09:21:08.790 INFO  [Executor task launch worker for task 481] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=71),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/71] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/71/3.delta
09:21:08.806 INFO  [Executor task launch worker for task 483] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=73), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/73] for update
09:21:08.806 INFO  [Executor task launch worker for task 482] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=72), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/72] for update
09:21:08.806 INFO  [Executor task launch worker for task 482] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.806 INFO  [Executor task launch worker for task 483] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.806 INFO  [Executor task launch worker for task 482] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.806 INFO  [Executor task launch worker for task 483] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.806 INFO  [Executor task launch worker for task 481] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=71),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/71]
09:21:08.806 INFO  [Executor task launch worker for task 481] org.apache.spark.executor.Executor - Finished task 71.0 in stage 9.0 (TID 481). 3322 bytes result sent to driver
09:21:08.806 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 74.0 in stage 9.0 (TID 484, localhost, executor driver, partition 74, PROCESS_LOCAL, 4726 bytes)
09:21:08.806 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 71.0 in stage 9.0 (TID 481) in 16 ms on localhost (executor driver) (72/200)
09:21:08.806 INFO  [Executor task launch worker for task 484] org.apache.spark.executor.Executor - Running task 74.0 in stage 9.0 (TID 484)
09:21:08.806 INFO  [Executor task launch worker for task 483] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=73),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/73] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/73/3.delta
09:21:08.806 INFO  [Executor task launch worker for task 482] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=72),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/72] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/72/3.delta
09:21:08.822 INFO  [Executor task launch worker for task 484] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=74), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/74] for update
09:21:08.822 INFO  [Executor task launch worker for task 484] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=74), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/74] for update
09:21:08.822 INFO  [Executor task launch worker for task 484] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.822 INFO  [Executor task launch worker for task 484] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.822 INFO  [Executor task launch worker for task 483] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=73),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/73]
09:21:08.822 INFO  [Executor task launch worker for task 482] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=72),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/72]
09:21:08.822 INFO  [Executor task launch worker for task 483] org.apache.spark.executor.Executor - Finished task 73.0 in stage 9.0 (TID 483). 3365 bytes result sent to driver
09:21:08.822 INFO  [Executor task launch worker for task 482] org.apache.spark.executor.Executor - Finished task 72.0 in stage 9.0 (TID 482). 3365 bytes result sent to driver
09:21:08.822 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 75.0 in stage 9.0 (TID 485, localhost, executor driver, partition 75, PROCESS_LOCAL, 4726 bytes)
09:21:08.822 INFO  [Executor task launch worker for task 485] org.apache.spark.executor.Executor - Running task 75.0 in stage 9.0 (TID 485)
09:21:08.822 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 76.0 in stage 9.0 (TID 486, localhost, executor driver, partition 76, PROCESS_LOCAL, 4726 bytes)
09:21:08.822 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 73.0 in stage 9.0 (TID 483) in 32 ms on localhost (executor driver) (73/200)
09:21:08.822 INFO  [Executor task launch worker for task 486] org.apache.spark.executor.Executor - Running task 76.0 in stage 9.0 (TID 486)
09:21:08.822 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 72.0 in stage 9.0 (TID 482) in 32 ms on localhost (executor driver) (74/200)
09:21:08.822 INFO  [Executor task launch worker for task 484] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=74),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/74] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/74/3.delta
09:21:08.822 INFO  [Executor task launch worker for task 486] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=76), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/76] for update
09:21:08.822 INFO  [Executor task launch worker for task 485] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=75), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/75] for update
09:21:08.822 INFO  [Executor task launch worker for task 484] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=74),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/74]
09:21:08.837 INFO  [Executor task launch worker for task 486] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=76), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/76] for update
09:21:08.837 INFO  [Executor task launch worker for task 485] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=75), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/75] for update
09:21:08.837 INFO  [Executor task launch worker for task 485] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.837 INFO  [Executor task launch worker for task 486] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.837 INFO  [Executor task launch worker for task 485] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.837 INFO  [Executor task launch worker for task 486] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.837 INFO  [Executor task launch worker for task 484] org.apache.spark.executor.Executor - Finished task 74.0 in stage 9.0 (TID 484). 3408 bytes result sent to driver
09:21:08.837 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 77.0 in stage 9.0 (TID 487, localhost, executor driver, partition 77, PROCESS_LOCAL, 4726 bytes)
09:21:08.837 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 74.0 in stage 9.0 (TID 484) in 31 ms on localhost (executor driver) (75/200)
09:21:08.837 INFO  [Executor task launch worker for task 487] org.apache.spark.executor.Executor - Running task 77.0 in stage 9.0 (TID 487)
09:21:08.837 INFO  [Executor task launch worker for task 487] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=77), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/77] for update
09:21:08.837 INFO  [Executor task launch worker for task 487] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=77), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/77] for update
09:21:08.837 INFO  [Executor task launch worker for task 487] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.837 INFO  [Executor task launch worker for task 487] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.837 INFO  [Executor task launch worker for task 486] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=76),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/76] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/76/3.delta
09:21:08.837 INFO  [Executor task launch worker for task 485] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=75),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/75] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/75/3.delta
09:21:08.837 INFO  [Executor task launch worker for task 487] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=77),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/77] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/77/3.delta
09:21:08.837 INFO  [Executor task launch worker for task 486] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=76),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/76]
09:21:08.837 INFO  [Executor task launch worker for task 485] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=75),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/75]
09:21:08.837 INFO  [Executor task launch worker for task 487] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=77),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/77]
09:21:08.853 INFO  [Executor task launch worker for task 486] org.apache.spark.executor.Executor - Finished task 76.0 in stage 9.0 (TID 486). 3322 bytes result sent to driver
09:21:08.853 INFO  [Executor task launch worker for task 485] org.apache.spark.executor.Executor - Finished task 75.0 in stage 9.0 (TID 485). 3322 bytes result sent to driver
09:21:08.853 INFO  [Executor task launch worker for task 487] org.apache.spark.executor.Executor - Finished task 77.0 in stage 9.0 (TID 487). 3322 bytes result sent to driver
09:21:08.853 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 78.0 in stage 9.0 (TID 488, localhost, executor driver, partition 78, PROCESS_LOCAL, 4726 bytes)
09:21:08.853 INFO  [Executor task launch worker for task 488] org.apache.spark.executor.Executor - Running task 78.0 in stage 9.0 (TID 488)
09:21:08.853 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 79.0 in stage 9.0 (TID 489, localhost, executor driver, partition 79, PROCESS_LOCAL, 4726 bytes)
09:21:08.853 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 76.0 in stage 9.0 (TID 486) in 31 ms on localhost (executor driver) (76/200)
09:21:08.853 INFO  [Executor task launch worker for task 489] org.apache.spark.executor.Executor - Running task 79.0 in stage 9.0 (TID 489)
09:21:08.853 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 75.0 in stage 9.0 (TID 485) in 31 ms on localhost (executor driver) (77/200)
09:21:08.853 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 80.0 in stage 9.0 (TID 490, localhost, executor driver, partition 80, PROCESS_LOCAL, 4726 bytes)
09:21:08.853 INFO  [Executor task launch worker for task 490] org.apache.spark.executor.Executor - Running task 80.0 in stage 9.0 (TID 490)
09:21:08.853 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 77.0 in stage 9.0 (TID 487) in 16 ms on localhost (executor driver) (78/200)
09:21:08.853 INFO  [Executor task launch worker for task 489] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=79), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/79] for update
09:21:08.853 INFO  [Executor task launch worker for task 488] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=78), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/78] for update
09:21:08.853 INFO  [Executor task launch worker for task 489] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=79), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/79] for update
09:21:08.853 INFO  [Executor task launch worker for task 488] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=78), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/78] for update
09:21:08.853 INFO  [Executor task launch worker for task 489] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.853 INFO  [Executor task launch worker for task 488] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.853 INFO  [Executor task launch worker for task 489] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.853 INFO  [Executor task launch worker for task 490] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=80), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/80] for update
09:21:08.869 INFO  [Executor task launch worker for task 488] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 16 ms
09:21:08.869 INFO  [Executor task launch worker for task 490] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=80), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/80] for update
09:21:08.869 INFO  [Executor task launch worker for task 490] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.869 INFO  [Executor task launch worker for task 490] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.869 INFO  [Executor task launch worker for task 488] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=78),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/78] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/78/3.delta
09:21:08.869 INFO  [Executor task launch worker for task 488] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=78),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/78]
09:21:08.869 INFO  [Executor task launch worker for task 488] org.apache.spark.executor.Executor - Finished task 78.0 in stage 9.0 (TID 488). 3322 bytes result sent to driver
09:21:08.869 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 81.0 in stage 9.0 (TID 491, localhost, executor driver, partition 81, PROCESS_LOCAL, 4726 bytes)
09:21:08.869 INFO  [Executor task launch worker for task 491] org.apache.spark.executor.Executor - Running task 81.0 in stage 9.0 (TID 491)
09:21:08.869 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 78.0 in stage 9.0 (TID 488) in 16 ms on localhost (executor driver) (79/200)
09:21:08.869 INFO  [Executor task launch worker for task 489] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=79),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/79] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/79/3.delta
09:21:08.869 INFO  [Executor task launch worker for task 490] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=80),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/80] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/80/3.delta
09:21:08.869 INFO  [Executor task launch worker for task 491] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=81), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/81] for update
09:21:08.869 INFO  [Executor task launch worker for task 491] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=81), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/81] for update
09:21:08.869 INFO  [Executor task launch worker for task 491] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.869 INFO  [Executor task launch worker for task 491] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.869 INFO  [Executor task launch worker for task 489] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=79),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/79]
09:21:08.869 INFO  [Executor task launch worker for task 490] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=80),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/80]
09:21:08.884 INFO  [Executor task launch worker for task 490] org.apache.spark.executor.Executor - Finished task 80.0 in stage 9.0 (TID 490). 3322 bytes result sent to driver
09:21:08.884 INFO  [Executor task launch worker for task 489] org.apache.spark.executor.Executor - Finished task 79.0 in stage 9.0 (TID 489). 3322 bytes result sent to driver
09:21:08.884 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 82.0 in stage 9.0 (TID 492, localhost, executor driver, partition 82, PROCESS_LOCAL, 4726 bytes)
09:21:08.884 INFO  [Executor task launch worker for task 492] org.apache.spark.executor.Executor - Running task 82.0 in stage 9.0 (TID 492)
09:21:08.884 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 83.0 in stage 9.0 (TID 493, localhost, executor driver, partition 83, PROCESS_LOCAL, 4726 bytes)
09:21:08.884 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 79.0 in stage 9.0 (TID 489) in 31 ms on localhost (executor driver) (80/200)
09:21:08.884 INFO  [Executor task launch worker for task 493] org.apache.spark.executor.Executor - Running task 83.0 in stage 9.0 (TID 493)
09:21:08.884 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 80.0 in stage 9.0 (TID 490) in 31 ms on localhost (executor driver) (81/200)
09:21:08.884 INFO  [Executor task launch worker for task 492] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=82), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/82] for update
09:21:08.884 INFO  [Executor task launch worker for task 492] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=82), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/82] for update
09:21:08.884 INFO  [Executor task launch worker for task 493] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=83), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/83] for update
09:21:08.884 INFO  [Executor task launch worker for task 492] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.884 INFO  [Executor task launch worker for task 493] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=83), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/83] for update
09:21:08.884 INFO  [Executor task launch worker for task 492] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.884 INFO  [Executor task launch worker for task 493] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.884 INFO  [Executor task launch worker for task 493] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.884 INFO  [Executor task launch worker for task 491] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=81),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/81] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/81/3.delta
09:21:08.884 INFO  [Executor task launch worker for task 492] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=82),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/82] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/82/3.delta
09:21:08.884 INFO  [Executor task launch worker for task 493] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=83),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/83] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/83/3.delta
09:21:08.884 INFO  [Executor task launch worker for task 491] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=81),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/81]
09:21:08.900 INFO  [Executor task launch worker for task 491] org.apache.spark.executor.Executor - Finished task 81.0 in stage 9.0 (TID 491). 3322 bytes result sent to driver
09:21:08.900 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 84.0 in stage 9.0 (TID 494, localhost, executor driver, partition 84, PROCESS_LOCAL, 4726 bytes)
09:21:08.900 INFO  [Executor task launch worker for task 494] org.apache.spark.executor.Executor - Running task 84.0 in stage 9.0 (TID 494)
09:21:08.900 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 81.0 in stage 9.0 (TID 491) in 31 ms on localhost (executor driver) (82/200)
09:21:08.900 INFO  [Executor task launch worker for task 494] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=84), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/84] for update
09:21:08.900 INFO  [Executor task launch worker for task 494] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=84), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/84] for update
09:21:08.900 INFO  [Executor task launch worker for task 494] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.900 INFO  [Executor task launch worker for task 494] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.900 INFO  [Executor task launch worker for task 493] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=83),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/83]
09:21:08.900 INFO  [Executor task launch worker for task 493] org.apache.spark.executor.Executor - Finished task 83.0 in stage 9.0 (TID 493). 3322 bytes result sent to driver
09:21:08.900 INFO  [Executor task launch worker for task 492] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=82),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/82]
09:21:08.900 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 85.0 in stage 9.0 (TID 495, localhost, executor driver, partition 85, PROCESS_LOCAL, 4726 bytes)
09:21:08.900 INFO  [Executor task launch worker for task 495] org.apache.spark.executor.Executor - Running task 85.0 in stage 9.0 (TID 495)
09:21:08.900 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 83.0 in stage 9.0 (TID 493) in 16 ms on localhost (executor driver) (83/200)
09:21:08.900 INFO  [Executor task launch worker for task 492] org.apache.spark.executor.Executor - Finished task 82.0 in stage 9.0 (TID 492). 3322 bytes result sent to driver
09:21:08.900 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 86.0 in stage 9.0 (TID 496, localhost, executor driver, partition 86, PROCESS_LOCAL, 4726 bytes)
09:21:08.900 INFO  [Executor task launch worker for task 496] org.apache.spark.executor.Executor - Running task 86.0 in stage 9.0 (TID 496)
09:21:08.900 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 82.0 in stage 9.0 (TID 492) in 16 ms on localhost (executor driver) (84/200)
09:21:08.900 INFO  [Executor task launch worker for task 495] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=85), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/85] for update
09:21:08.900 INFO  [Executor task launch worker for task 496] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=86), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/86] for update
09:21:08.900 INFO  [Executor task launch worker for task 494] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=84),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/84] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/84/3.delta
09:21:08.915 INFO  [Executor task launch worker for task 495] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=85), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/85] for update
09:21:08.915 INFO  [Executor task launch worker for task 496] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=86), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/86] for update
09:21:08.915 INFO  [Executor task launch worker for task 495] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.915 INFO  [Executor task launch worker for task 495] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.915 INFO  [Executor task launch worker for task 496] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.915 INFO  [Executor task launch worker for task 496] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.915 INFO  [Executor task launch worker for task 494] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=84),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/84]
09:21:08.915 INFO  [Executor task launch worker for task 494] org.apache.spark.executor.Executor - Finished task 84.0 in stage 9.0 (TID 494). 3322 bytes result sent to driver
09:21:08.915 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 87.0 in stage 9.0 (TID 497, localhost, executor driver, partition 87, PROCESS_LOCAL, 4726 bytes)
09:21:08.915 INFO  [Executor task launch worker for task 497] org.apache.spark.executor.Executor - Running task 87.0 in stage 9.0 (TID 497)
09:21:08.915 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 84.0 in stage 9.0 (TID 494) in 15 ms on localhost (executor driver) (85/200)
09:21:08.915 INFO  [Executor task launch worker for task 495] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=85),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/85] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/85/3.delta
09:21:08.915 INFO  [Executor task launch worker for task 496] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=86),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/86] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/86/3.delta
09:21:08.915 INFO  [Executor task launch worker for task 497] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=87), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/87] for update
09:21:08.915 INFO  [Executor task launch worker for task 497] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=87), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/87] for update
09:21:08.915 INFO  [Executor task launch worker for task 497] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.915 INFO  [Executor task launch worker for task 497] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.931 INFO  [Executor task launch worker for task 495] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=85),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/85]
09:21:08.931 INFO  [Executor task launch worker for task 495] org.apache.spark.executor.Executor - Finished task 85.0 in stage 9.0 (TID 495). 3365 bytes result sent to driver
09:21:08.931 INFO  [Executor task launch worker for task 496] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=86),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/86]
09:21:08.931 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 88.0 in stage 9.0 (TID 498, localhost, executor driver, partition 88, PROCESS_LOCAL, 4726 bytes)
09:21:08.931 INFO  [Executor task launch worker for task 498] org.apache.spark.executor.Executor - Running task 88.0 in stage 9.0 (TID 498)
09:21:08.931 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 85.0 in stage 9.0 (TID 495) in 31 ms on localhost (executor driver) (86/200)
09:21:08.931 INFO  [Executor task launch worker for task 496] org.apache.spark.executor.Executor - Finished task 86.0 in stage 9.0 (TID 496). 3365 bytes result sent to driver
09:21:08.931 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 89.0 in stage 9.0 (TID 499, localhost, executor driver, partition 89, PROCESS_LOCAL, 4726 bytes)
09:21:08.931 INFO  [Executor task launch worker for task 499] org.apache.spark.executor.Executor - Running task 89.0 in stage 9.0 (TID 499)
09:21:08.931 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 86.0 in stage 9.0 (TID 496) in 31 ms on localhost (executor driver) (87/200)
09:21:08.931 INFO  [Executor task launch worker for task 499] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=89), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/89] for update
09:21:08.931 INFO  [Executor task launch worker for task 499] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=89), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/89] for update
09:21:08.931 INFO  [Executor task launch worker for task 499] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.931 INFO  [Executor task launch worker for task 499] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.931 INFO  [Executor task launch worker for task 497] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=87),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/87] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/87/3.delta
09:21:08.931 INFO  [Executor task launch worker for task 498] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=88), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/88] for update
09:21:08.931 INFO  [Executor task launch worker for task 497] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=87),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/87]
09:21:08.931 INFO  [Executor task launch worker for task 499] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=89),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/89] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/89/3.delta
09:21:08.947 INFO  [Executor task launch worker for task 498] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=88), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/88] for update
09:21:08.947 INFO  [Executor task launch worker for task 498] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.947 INFO  [Executor task launch worker for task 498] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.947 INFO  [Executor task launch worker for task 497] org.apache.spark.executor.Executor - Finished task 87.0 in stage 9.0 (TID 497). 3365 bytes result sent to driver
09:21:08.947 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 90.0 in stage 9.0 (TID 500, localhost, executor driver, partition 90, PROCESS_LOCAL, 4726 bytes)
09:21:08.947 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 87.0 in stage 9.0 (TID 497) in 32 ms on localhost (executor driver) (88/200)
09:21:08.947 INFO  [Executor task launch worker for task 500] org.apache.spark.executor.Executor - Running task 90.0 in stage 9.0 (TID 500)
09:21:08.947 INFO  [Executor task launch worker for task 500] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=90), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/90] for update
09:21:08.947 INFO  [Executor task launch worker for task 500] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=90), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/90] for update
09:21:08.947 INFO  [Executor task launch worker for task 500] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.947 INFO  [Executor task launch worker for task 500] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.947 INFO  [Executor task launch worker for task 499] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=89),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/89]
09:21:08.947 INFO  [Executor task launch worker for task 499] org.apache.spark.executor.Executor - Finished task 89.0 in stage 9.0 (TID 499). 3322 bytes result sent to driver
09:21:08.947 INFO  [Executor task launch worker for task 498] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=88),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/88] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/88/3.delta
09:21:08.947 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 91.0 in stage 9.0 (TID 501, localhost, executor driver, partition 91, PROCESS_LOCAL, 4726 bytes)
09:21:08.947 INFO  [Executor task launch worker for task 501] org.apache.spark.executor.Executor - Running task 91.0 in stage 9.0 (TID 501)
09:21:08.947 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 89.0 in stage 9.0 (TID 499) in 16 ms on localhost (executor driver) (89/200)
09:21:08.947 INFO  [Executor task launch worker for task 500] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=90),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/90] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/90/3.delta
09:21:08.947 INFO  [Executor task launch worker for task 501] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=91), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/91] for update
09:21:08.947 INFO  [Executor task launch worker for task 498] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=88),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/88]
09:21:08.947 INFO  [Executor task launch worker for task 500] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=90),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/90]
09:21:08.962 INFO  [Executor task launch worker for task 501] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=91), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/91] for update
09:21:08.962 INFO  [Executor task launch worker for task 501] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.962 INFO  [Executor task launch worker for task 501] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.962 INFO  [Executor task launch worker for task 498] org.apache.spark.executor.Executor - Finished task 88.0 in stage 9.0 (TID 498). 3322 bytes result sent to driver
09:21:08.962 INFO  [Executor task launch worker for task 500] org.apache.spark.executor.Executor - Finished task 90.0 in stage 9.0 (TID 500). 3322 bytes result sent to driver
09:21:08.962 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 92.0 in stage 9.0 (TID 502, localhost, executor driver, partition 92, PROCESS_LOCAL, 4726 bytes)
09:21:08.962 INFO  [Executor task launch worker for task 502] org.apache.spark.executor.Executor - Running task 92.0 in stage 9.0 (TID 502)
09:21:08.962 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 93.0 in stage 9.0 (TID 503, localhost, executor driver, partition 93, PROCESS_LOCAL, 4726 bytes)
09:21:08.962 INFO  [Executor task launch worker for task 503] org.apache.spark.executor.Executor - Running task 93.0 in stage 9.0 (TID 503)
09:21:08.962 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 88.0 in stage 9.0 (TID 498) in 31 ms on localhost (executor driver) (90/200)
09:21:08.962 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 90.0 in stage 9.0 (TID 500) in 15 ms on localhost (executor driver) (91/200)
09:21:08.962 INFO  [Executor task launch worker for task 503] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=93), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/93] for update
09:21:08.962 INFO  [Executor task launch worker for task 502] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=92), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/92] for update
09:21:08.962 INFO  [Executor task launch worker for task 503] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=93), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/93] for update
09:21:08.962 INFO  [Executor task launch worker for task 502] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=92), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/92] for update
09:21:08.962 INFO  [Executor task launch worker for task 503] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.962 INFO  [Executor task launch worker for task 502] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.962 INFO  [Executor task launch worker for task 503] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.962 INFO  [Executor task launch worker for task 502] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.962 INFO  [Executor task launch worker for task 501] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=91),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/91] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/91/3.delta
09:21:08.962 INFO  [Executor task launch worker for task 503] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=93),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/93] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/93/3.delta
09:21:08.978 INFO  [Executor task launch worker for task 503] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=93),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/93]
09:21:08.978 INFO  [Executor task launch worker for task 503] org.apache.spark.executor.Executor - Finished task 93.0 in stage 9.0 (TID 503). 3322 bytes result sent to driver
09:21:08.978 INFO  [Executor task launch worker for task 501] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=91),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/91]
09:21:08.994 INFO  [Executor task launch worker for task 501] org.apache.spark.executor.Executor - Finished task 91.0 in stage 9.0 (TID 501). 3365 bytes result sent to driver
09:21:08.994 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 94.0 in stage 9.0 (TID 504, localhost, executor driver, partition 94, PROCESS_LOCAL, 4726 bytes)
09:21:08.994 INFO  [Executor task launch worker for task 504] org.apache.spark.executor.Executor - Running task 94.0 in stage 9.0 (TID 504)
09:21:08.994 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 95.0 in stage 9.0 (TID 505, localhost, executor driver, partition 95, PROCESS_LOCAL, 4726 bytes)
09:21:08.994 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 93.0 in stage 9.0 (TID 503) in 32 ms on localhost (executor driver) (92/200)
09:21:08.994 INFO  [Executor task launch worker for task 505] org.apache.spark.executor.Executor - Running task 95.0 in stage 9.0 (TID 505)
09:21:08.994 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 91.0 in stage 9.0 (TID 501) in 47 ms on localhost (executor driver) (93/200)
09:21:08.994 INFO  [Executor task launch worker for task 502] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=92),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/92] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/92/3.delta
09:21:08.994 INFO  [Executor task launch worker for task 505] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=95), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/95] for update
09:21:08.994 INFO  [Executor task launch worker for task 504] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=94), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/94] for update
09:21:08.994 INFO  [Executor task launch worker for task 505] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=95), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/95] for update
09:21:08.994 INFO  [Executor task launch worker for task 504] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=94), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/94] for update
09:21:08.994 INFO  [Executor task launch worker for task 504] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.994 INFO  [Executor task launch worker for task 505] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:08.994 INFO  [Executor task launch worker for task 504] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.994 INFO  [Executor task launch worker for task 505] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:08.994 INFO  [Executor task launch worker for task 502] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=92),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/92]
09:21:08.994 INFO  [Executor task launch worker for task 505] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=95),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/95] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/95/3.delta
09:21:09.009 INFO  [Executor task launch worker for task 502] org.apache.spark.executor.Executor - Finished task 92.0 in stage 9.0 (TID 502). 3322 bytes result sent to driver
09:21:09.009 INFO  [Executor task launch worker for task 504] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=94),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/94] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/94/3.delta
09:21:09.009 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 96.0 in stage 9.0 (TID 506, localhost, executor driver, partition 96, PROCESS_LOCAL, 4726 bytes)
09:21:09.009 INFO  [Executor task launch worker for task 506] org.apache.spark.executor.Executor - Running task 96.0 in stage 9.0 (TID 506)
09:21:09.009 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 92.0 in stage 9.0 (TID 502) in 47 ms on localhost (executor driver) (94/200)
09:21:09.009 INFO  [Executor task launch worker for task 506] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=96), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/96] for update
09:21:09.009 INFO  [Executor task launch worker for task 506] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=96), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/96] for update
09:21:09.009 INFO  [Executor task launch worker for task 506] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.009 INFO  [Executor task launch worker for task 506] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.009 INFO  [Executor task launch worker for task 505] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=95),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/95]
09:21:09.009 INFO  [Executor task launch worker for task 505] org.apache.spark.executor.Executor - Finished task 95.0 in stage 9.0 (TID 505). 3322 bytes result sent to driver
09:21:09.009 INFO  [Executor task launch worker for task 504] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=94),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/94]
09:21:09.009 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 97.0 in stage 9.0 (TID 507, localhost, executor driver, partition 97, PROCESS_LOCAL, 4726 bytes)
09:21:09.009 INFO  [Executor task launch worker for task 507] org.apache.spark.executor.Executor - Running task 97.0 in stage 9.0 (TID 507)
09:21:09.009 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 95.0 in stage 9.0 (TID 505) in 15 ms on localhost (executor driver) (95/200)
09:21:09.009 INFO  [Executor task launch worker for task 504] org.apache.spark.executor.Executor - Finished task 94.0 in stage 9.0 (TID 504). 3365 bytes result sent to driver
09:21:09.009 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 98.0 in stage 9.0 (TID 508, localhost, executor driver, partition 98, PROCESS_LOCAL, 4726 bytes)
09:21:09.009 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 94.0 in stage 9.0 (TID 504) in 15 ms on localhost (executor driver) (96/200)
09:21:09.009 INFO  [Executor task launch worker for task 508] org.apache.spark.executor.Executor - Running task 98.0 in stage 9.0 (TID 508)
09:21:09.009 INFO  [Executor task launch worker for task 507] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=97), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/97] for update
09:21:09.009 INFO  [Executor task launch worker for task 508] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=98), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/98] for update
09:21:09.009 INFO  [Executor task launch worker for task 506] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=96),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/96] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/96/3.delta
09:21:09.025 INFO  [Executor task launch worker for task 507] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=97), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/97] for update
09:21:09.025 INFO  [Executor task launch worker for task 508] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=98), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/98] for update
09:21:09.025 INFO  [Executor task launch worker for task 508] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.025 INFO  [Executor task launch worker for task 507] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.025 INFO  [Executor task launch worker for task 508] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.025 INFO  [Executor task launch worker for task 507] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.025 INFO  [Executor task launch worker for task 506] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=96),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/96]
09:21:09.025 INFO  [Executor task launch worker for task 506] org.apache.spark.executor.Executor - Finished task 96.0 in stage 9.0 (TID 506). 3322 bytes result sent to driver
09:21:09.025 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 99.0 in stage 9.0 (TID 509, localhost, executor driver, partition 99, PROCESS_LOCAL, 4726 bytes)
09:21:09.025 INFO  [Executor task launch worker for task 507] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=97),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/97] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/97/3.delta
09:21:09.025 INFO  [Executor task launch worker for task 509] org.apache.spark.executor.Executor - Running task 99.0 in stage 9.0 (TID 509)
09:21:09.025 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 96.0 in stage 9.0 (TID 506) in 16 ms on localhost (executor driver) (97/200)
09:21:09.025 INFO  [Executor task launch worker for task 508] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=98),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/98] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/98/3.delta
09:21:09.025 INFO  [Executor task launch worker for task 509] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=99), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/99] for update
09:21:09.025 INFO  [Executor task launch worker for task 509] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=99), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/99] for update
09:21:09.025 INFO  [Executor task launch worker for task 509] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.025 INFO  [Executor task launch worker for task 509] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.025 INFO  [Executor task launch worker for task 507] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=97),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/97]
09:21:09.025 INFO  [Executor task launch worker for task 507] org.apache.spark.executor.Executor - Finished task 97.0 in stage 9.0 (TID 507). 3322 bytes result sent to driver
09:21:09.025 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 100.0 in stage 9.0 (TID 510, localhost, executor driver, partition 100, PROCESS_LOCAL, 4726 bytes)
09:21:09.025 INFO  [Executor task launch worker for task 510] org.apache.spark.executor.Executor - Running task 100.0 in stage 9.0 (TID 510)
09:21:09.025 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 97.0 in stage 9.0 (TID 507) in 16 ms on localhost (executor driver) (98/200)
09:21:09.025 INFO  [Executor task launch worker for task 508] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=98),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/98]
09:21:09.025 INFO  [Executor task launch worker for task 508] org.apache.spark.executor.Executor - Finished task 98.0 in stage 9.0 (TID 508). 3322 bytes result sent to driver
09:21:09.025 INFO  [Executor task launch worker for task 510] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=100), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/100] for update
09:21:09.025 INFO  [Executor task launch worker for task 509] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=99),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/99] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/99/3.delta
09:21:09.040 INFO  [Executor task launch worker for task 510] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=100), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/100] for update
09:21:09.040 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 101.0 in stage 9.0 (TID 511, localhost, executor driver, partition 101, PROCESS_LOCAL, 4726 bytes)
09:21:09.040 INFO  [Executor task launch worker for task 510] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.040 INFO  [Executor task launch worker for task 510] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.040 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 98.0 in stage 9.0 (TID 508) in 31 ms on localhost (executor driver) (99/200)
09:21:09.040 INFO  [Executor task launch worker for task 511] org.apache.spark.executor.Executor - Running task 101.0 in stage 9.0 (TID 511)
09:21:09.040 INFO  [Executor task launch worker for task 511] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=101), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/101] for update
09:21:09.040 INFO  [Executor task launch worker for task 511] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=101), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/101] for update
09:21:09.040 INFO  [Executor task launch worker for task 511] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.040 INFO  [Executor task launch worker for task 511] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.040 INFO  [Executor task launch worker for task 509] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=99),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/99]
09:21:09.040 INFO  [Executor task launch worker for task 509] org.apache.spark.executor.Executor - Finished task 99.0 in stage 9.0 (TID 509). 3322 bytes result sent to driver
09:21:09.040 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 102.0 in stage 9.0 (TID 512, localhost, executor driver, partition 102, PROCESS_LOCAL, 4726 bytes)
09:21:09.040 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 99.0 in stage 9.0 (TID 509) in 15 ms on localhost (executor driver) (100/200)
09:21:09.040 INFO  [Executor task launch worker for task 512] org.apache.spark.executor.Executor - Running task 102.0 in stage 9.0 (TID 512)
09:21:09.040 INFO  [Executor task launch worker for task 510] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=100),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/100] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/100/3.delta
09:21:09.040 INFO  [Executor task launch worker for task 512] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=102), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/102] for update
09:21:09.040 INFO  [Executor task launch worker for task 511] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=101),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/101] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/101/3.delta
09:21:09.040 INFO  [Executor task launch worker for task 510] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=100),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/100]
09:21:09.056 INFO  [Executor task launch worker for task 512] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=102), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/102] for update
09:21:09.056 INFO  [Executor task launch worker for task 512] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.056 INFO  [Executor task launch worker for task 512] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.056 INFO  [Executor task launch worker for task 510] org.apache.spark.executor.Executor - Finished task 100.0 in stage 9.0 (TID 510). 3322 bytes result sent to driver
09:21:09.056 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 103.0 in stage 9.0 (TID 513, localhost, executor driver, partition 103, PROCESS_LOCAL, 4726 bytes)
09:21:09.056 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 100.0 in stage 9.0 (TID 510) in 31 ms on localhost (executor driver) (101/200)
09:21:09.056 INFO  [Executor task launch worker for task 513] org.apache.spark.executor.Executor - Running task 103.0 in stage 9.0 (TID 513)
09:21:09.056 INFO  [Executor task launch worker for task 513] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=103), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/103] for update
09:21:09.056 INFO  [Executor task launch worker for task 513] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=103), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/103] for update
09:21:09.056 INFO  [Executor task launch worker for task 513] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.056 INFO  [Executor task launch worker for task 513] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.056 INFO  [Executor task launch worker for task 511] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=101),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/101]
09:21:09.056 INFO  [Executor task launch worker for task 511] org.apache.spark.executor.Executor - Finished task 101.0 in stage 9.0 (TID 511). 3322 bytes result sent to driver
09:21:09.056 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 104.0 in stage 9.0 (TID 514, localhost, executor driver, partition 104, PROCESS_LOCAL, 4726 bytes)
09:21:09.056 INFO  [Executor task launch worker for task 514] org.apache.spark.executor.Executor - Running task 104.0 in stage 9.0 (TID 514)
09:21:09.056 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 101.0 in stage 9.0 (TID 511) in 16 ms on localhost (executor driver) (102/200)
09:21:09.056 INFO  [Executor task launch worker for task 512] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=102),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/102] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/102/3.delta
09:21:09.056 INFO  [Executor task launch worker for task 514] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=104), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/104] for update
09:21:09.056 INFO  [Executor task launch worker for task 513] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=103),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/103] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/103/3.delta
09:21:09.072 INFO  [Executor task launch worker for task 514] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=104), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/104] for update
09:21:09.072 INFO  [Executor task launch worker for task 514] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.072 INFO  [Executor task launch worker for task 514] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.072 INFO  [Executor task launch worker for task 512] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=102),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/102]
09:21:09.072 INFO  [Executor task launch worker for task 513] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=103),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/103]
09:21:09.072 INFO  [Executor task launch worker for task 512] org.apache.spark.executor.Executor - Finished task 102.0 in stage 9.0 (TID 512). 3322 bytes result sent to driver
09:21:09.072 INFO  [Executor task launch worker for task 513] org.apache.spark.executor.Executor - Finished task 103.0 in stage 9.0 (TID 513). 3322 bytes result sent to driver
09:21:09.072 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 105.0 in stage 9.0 (TID 515, localhost, executor driver, partition 105, PROCESS_LOCAL, 4726 bytes)
09:21:09.072 INFO  [Executor task launch worker for task 515] org.apache.spark.executor.Executor - Running task 105.0 in stage 9.0 (TID 515)
09:21:09.072 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 106.0 in stage 9.0 (TID 516, localhost, executor driver, partition 106, PROCESS_LOCAL, 4726 bytes)
09:21:09.072 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 102.0 in stage 9.0 (TID 512) in 32 ms on localhost (executor driver) (103/200)
09:21:09.072 INFO  [Executor task launch worker for task 516] org.apache.spark.executor.Executor - Running task 106.0 in stage 9.0 (TID 516)
09:21:09.072 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 103.0 in stage 9.0 (TID 513) in 16 ms on localhost (executor driver) (104/200)
09:21:09.072 INFO  [Executor task launch worker for task 514] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=104),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/104] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/104/3.delta
09:21:09.072 INFO  [Executor task launch worker for task 515] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=105), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/105] for update
09:21:09.072 INFO  [Executor task launch worker for task 516] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=106), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/106] for update
09:21:09.072 INFO  [Executor task launch worker for task 515] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=105), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/105] for update
09:21:09.072 INFO  [Executor task launch worker for task 516] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=106), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/106] for update
09:21:09.072 INFO  [Executor task launch worker for task 514] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=104),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/104]
09:21:09.087 INFO  [Executor task launch worker for task 515] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.087 INFO  [Executor task launch worker for task 516] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.087 INFO  [Executor task launch worker for task 515] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.087 INFO  [Executor task launch worker for task 516] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.087 INFO  [Executor task launch worker for task 514] org.apache.spark.executor.Executor - Finished task 104.0 in stage 9.0 (TID 514). 3351 bytes result sent to driver
09:21:09.087 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 107.0 in stage 9.0 (TID 517, localhost, executor driver, partition 107, PROCESS_LOCAL, 4726 bytes)
09:21:09.087 INFO  [Executor task launch worker for task 517] org.apache.spark.executor.Executor - Running task 107.0 in stage 9.0 (TID 517)
09:21:09.087 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 104.0 in stage 9.0 (TID 514) in 31 ms on localhost (executor driver) (105/200)
09:21:09.087 INFO  [Executor task launch worker for task 517] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=107), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/107] for update
09:21:09.087 INFO  [Executor task launch worker for task 517] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=107), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/107] for update
09:21:09.087 INFO  [Executor task launch worker for task 517] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.087 INFO  [Executor task launch worker for task 517] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.087 INFO  [Executor task launch worker for task 515] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=105),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/105] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/105/3.delta
09:21:09.087 INFO  [Executor task launch worker for task 516] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=106),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/106] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/106/3.delta
09:21:09.087 INFO  [Executor task launch worker for task 515] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=105),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/105]
09:21:09.087 INFO  [Executor task launch worker for task 516] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=106),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/106]
09:21:09.087 INFO  [Executor task launch worker for task 515] org.apache.spark.executor.Executor - Finished task 105.0 in stage 9.0 (TID 515). 3322 bytes result sent to driver
09:21:09.087 INFO  [Executor task launch worker for task 517] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=107),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/107] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/107/3.delta
09:21:09.103 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 108.0 in stage 9.0 (TID 518, localhost, executor driver, partition 108, PROCESS_LOCAL, 4726 bytes)
09:21:09.103 INFO  [Executor task launch worker for task 518] org.apache.spark.executor.Executor - Running task 108.0 in stage 9.0 (TID 518)
09:21:09.103 INFO  [Executor task launch worker for task 516] org.apache.spark.executor.Executor - Finished task 106.0 in stage 9.0 (TID 516). 3322 bytes result sent to driver
09:21:09.103 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 105.0 in stage 9.0 (TID 515) in 31 ms on localhost (executor driver) (106/200)
09:21:09.103 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 106.0 in stage 9.0 (TID 516) in 31 ms on localhost (executor driver) (107/200)
09:21:09.103 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 109.0 in stage 9.0 (TID 519, localhost, executor driver, partition 109, PROCESS_LOCAL, 4726 bytes)
09:21:09.103 INFO  [Executor task launch worker for task 519] org.apache.spark.executor.Executor - Running task 109.0 in stage 9.0 (TID 519)
09:21:09.103 INFO  [Executor task launch worker for task 518] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=108), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/108] for update
09:21:09.103 INFO  [Executor task launch worker for task 518] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=108), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/108] for update
09:21:09.103 INFO  [Executor task launch worker for task 518] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.103 INFO  [Executor task launch worker for task 518] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.103 INFO  [Executor task launch worker for task 519] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=109), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/109] for update
09:21:09.103 INFO  [Executor task launch worker for task 519] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=109), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/109] for update
09:21:09.103 INFO  [Executor task launch worker for task 519] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.103 INFO  [Executor task launch worker for task 519] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.103 INFO  [Executor task launch worker for task 517] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=107),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/107]
09:21:09.103 INFO  [Executor task launch worker for task 517] org.apache.spark.executor.Executor - Finished task 107.0 in stage 9.0 (TID 517). 3322 bytes result sent to driver
09:21:09.103 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 110.0 in stage 9.0 (TID 520, localhost, executor driver, partition 110, PROCESS_LOCAL, 4726 bytes)
09:21:09.103 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 107.0 in stage 9.0 (TID 517) in 16 ms on localhost (executor driver) (108/200)
09:21:09.103 INFO  [Executor task launch worker for task 520] org.apache.spark.executor.Executor - Running task 110.0 in stage 9.0 (TID 520)
09:21:09.103 INFO  [Executor task launch worker for task 519] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=109),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/109] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/109/3.delta
09:21:09.119 INFO  [Executor task launch worker for task 518] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=108),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/108] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/108/3.delta
09:21:09.119 INFO  [Executor task launch worker for task 520] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=110), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/110] for update
09:21:09.119 INFO  [Executor task launch worker for task 520] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=110), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/110] for update
09:21:09.119 INFO  [Executor task launch worker for task 520] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.119 INFO  [Executor task launch worker for task 520] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.119 INFO  [Executor task launch worker for task 519] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=109),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/109]
09:21:09.119 INFO  [Executor task launch worker for task 519] org.apache.spark.executor.Executor - Finished task 109.0 in stage 9.0 (TID 519). 3322 bytes result sent to driver
09:21:09.119 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 111.0 in stage 9.0 (TID 521, localhost, executor driver, partition 111, PROCESS_LOCAL, 4726 bytes)
09:21:09.119 INFO  [Executor task launch worker for task 521] org.apache.spark.executor.Executor - Running task 111.0 in stage 9.0 (TID 521)
09:21:09.119 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 109.0 in stage 9.0 (TID 519) in 16 ms on localhost (executor driver) (109/200)
09:21:09.119 INFO  [Executor task launch worker for task 521] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=111), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/111] for update
09:21:09.119 INFO  [Executor task launch worker for task 521] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=111), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/111] for update
09:21:09.119 INFO  [Executor task launch worker for task 521] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.119 INFO  [Executor task launch worker for task 521] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.119 INFO  [Executor task launch worker for task 520] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=110),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/110] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/110/3.delta
09:21:09.119 INFO  [Executor task launch worker for task 518] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=108),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/108]
09:21:09.119 INFO  [Executor task launch worker for task 521] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=111),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/111] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/111/3.delta
09:21:09.134 INFO  [Executor task launch worker for task 518] org.apache.spark.executor.Executor - Finished task 108.0 in stage 9.0 (TID 518). 3365 bytes result sent to driver
09:21:09.134 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 112.0 in stage 9.0 (TID 522, localhost, executor driver, partition 112, PROCESS_LOCAL, 4726 bytes)
09:21:09.134 INFO  [Executor task launch worker for task 522] org.apache.spark.executor.Executor - Running task 112.0 in stage 9.0 (TID 522)
09:21:09.134 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 108.0 in stage 9.0 (TID 518) in 31 ms on localhost (executor driver) (110/200)
09:21:09.134 INFO  [Executor task launch worker for task 522] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=112), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/112] for update
09:21:09.134 INFO  [Executor task launch worker for task 522] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=112), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/112] for update
09:21:09.134 INFO  [Executor task launch worker for task 522] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.134 INFO  [Executor task launch worker for task 522] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.134 INFO  [Executor task launch worker for task 520] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=110),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/110]
09:21:09.134 INFO  [Executor task launch worker for task 520] org.apache.spark.executor.Executor - Finished task 110.0 in stage 9.0 (TID 520). 3365 bytes result sent to driver
09:21:09.134 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 113.0 in stage 9.0 (TID 523, localhost, executor driver, partition 113, PROCESS_LOCAL, 4726 bytes)
09:21:09.134 INFO  [Executor task launch worker for task 523] org.apache.spark.executor.Executor - Running task 113.0 in stage 9.0 (TID 523)
09:21:09.134 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 110.0 in stage 9.0 (TID 520) in 31 ms on localhost (executor driver) (111/200)
09:21:09.134 INFO  [Executor task launch worker for task 523] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=113), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/113] for update
09:21:09.134 INFO  [Executor task launch worker for task 523] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=113), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/113] for update
09:21:09.134 INFO  [Executor task launch worker for task 523] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.134 INFO  [Executor task launch worker for task 523] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.134 INFO  [Executor task launch worker for task 521] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=111),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/111]
09:21:09.134 INFO  [Executor task launch worker for task 522] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=112),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/112] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/112/3.delta
09:21:09.134 INFO  [Executor task launch worker for task 523] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=113),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/113] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/113/3.delta
09:21:09.150 INFO  [Executor task launch worker for task 521] org.apache.spark.executor.Executor - Finished task 111.0 in stage 9.0 (TID 521). 3322 bytes result sent to driver
09:21:09.150 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 114.0 in stage 9.0 (TID 524, localhost, executor driver, partition 114, PROCESS_LOCAL, 4726 bytes)
09:21:09.150 INFO  [Executor task launch worker for task 524] org.apache.spark.executor.Executor - Running task 114.0 in stage 9.0 (TID 524)
09:21:09.150 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 111.0 in stage 9.0 (TID 521) in 31 ms on localhost (executor driver) (112/200)
09:21:09.150 INFO  [Executor task launch worker for task 524] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=114), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/114] for update
09:21:09.150 INFO  [Executor task launch worker for task 524] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=114), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/114] for update
09:21:09.150 INFO  [Executor task launch worker for task 524] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.150 INFO  [Executor task launch worker for task 524] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.150 INFO  [Executor task launch worker for task 522] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=112),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/112]
09:21:09.150 INFO  [Executor task launch worker for task 523] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=113),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/113]
09:21:09.150 INFO  [Executor task launch worker for task 522] org.apache.spark.executor.Executor - Finished task 112.0 in stage 9.0 (TID 522). 3322 bytes result sent to driver
09:21:09.150 INFO  [Executor task launch worker for task 523] org.apache.spark.executor.Executor - Finished task 113.0 in stage 9.0 (TID 523). 3322 bytes result sent to driver
09:21:09.150 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 115.0 in stage 9.0 (TID 525, localhost, executor driver, partition 115, PROCESS_LOCAL, 4726 bytes)
09:21:09.150 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 116.0 in stage 9.0 (TID 526, localhost, executor driver, partition 116, PROCESS_LOCAL, 4726 bytes)
09:21:09.150 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 113.0 in stage 9.0 (TID 523) in 16 ms on localhost (executor driver) (113/200)
09:21:09.150 INFO  [Executor task launch worker for task 526] org.apache.spark.executor.Executor - Running task 116.0 in stage 9.0 (TID 526)
09:21:09.150 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 112.0 in stage 9.0 (TID 522) in 16 ms on localhost (executor driver) (114/200)
09:21:09.150 INFO  [Executor task launch worker for task 525] org.apache.spark.executor.Executor - Running task 115.0 in stage 9.0 (TID 525)
09:21:09.150 INFO  [Executor task launch worker for task 524] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=114),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/114] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/114/3.delta
09:21:09.165 INFO  [Executor task launch worker for task 526] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=116), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/116] for update
09:21:09.165 INFO  [Executor task launch worker for task 525] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=115), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/115] for update
09:21:09.165 INFO  [Executor task launch worker for task 526] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=116), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/116] for update
09:21:09.165 INFO  [Executor task launch worker for task 525] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=115), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/115] for update
09:21:09.165 INFO  [Executor task launch worker for task 526] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.165 INFO  [Executor task launch worker for task 525] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.165 INFO  [Executor task launch worker for task 526] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.165 INFO  [Executor task launch worker for task 525] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.165 INFO  [Executor task launch worker for task 524] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=114),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/114]
09:21:09.165 INFO  [Executor task launch worker for task 524] org.apache.spark.executor.Executor - Finished task 114.0 in stage 9.0 (TID 524). 3322 bytes result sent to driver
09:21:09.165 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 117.0 in stage 9.0 (TID 527, localhost, executor driver, partition 117, PROCESS_LOCAL, 4726 bytes)
09:21:09.165 INFO  [Executor task launch worker for task 527] org.apache.spark.executor.Executor - Running task 117.0 in stage 9.0 (TID 527)
09:21:09.165 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 114.0 in stage 9.0 (TID 524) in 15 ms on localhost (executor driver) (115/200)
09:21:09.165 INFO  [Executor task launch worker for task 527] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=117), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/117] for update
09:21:09.165 INFO  [Executor task launch worker for task 525] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=115),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/115] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/115/3.delta
09:21:09.165 INFO  [Executor task launch worker for task 526] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=116),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/116] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/116/3.delta
09:21:09.181 INFO  [Executor task launch worker for task 527] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=117), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/117] for update
09:21:09.181 INFO  [Executor task launch worker for task 527] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.181 INFO  [Executor task launch worker for task 527] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.181 INFO  [Executor task launch worker for task 525] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=115),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/115]
09:21:09.181 INFO  [Executor task launch worker for task 526] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=116),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/116]
09:21:09.181 INFO  [Executor task launch worker for task 525] org.apache.spark.executor.Executor - Finished task 115.0 in stage 9.0 (TID 525). 3365 bytes result sent to driver
09:21:09.181 INFO  [Executor task launch worker for task 526] org.apache.spark.executor.Executor - Finished task 116.0 in stage 9.0 (TID 526). 3365 bytes result sent to driver
09:21:09.181 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 118.0 in stage 9.0 (TID 528, localhost, executor driver, partition 118, PROCESS_LOCAL, 4726 bytes)
09:21:09.181 INFO  [Executor task launch worker for task 528] org.apache.spark.executor.Executor - Running task 118.0 in stage 9.0 (TID 528)
09:21:09.181 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 119.0 in stage 9.0 (TID 529, localhost, executor driver, partition 119, PROCESS_LOCAL, 4726 bytes)
09:21:09.181 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 115.0 in stage 9.0 (TID 525) in 31 ms on localhost (executor driver) (116/200)
09:21:09.181 INFO  [Executor task launch worker for task 529] org.apache.spark.executor.Executor - Running task 119.0 in stage 9.0 (TID 529)
09:21:09.181 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 116.0 in stage 9.0 (TID 526) in 31 ms on localhost (executor driver) (117/200)
09:21:09.181 INFO  [Executor task launch worker for task 527] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=117),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/117] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/117/3.delta
09:21:09.181 INFO  [Executor task launch worker for task 529] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=119), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/119] for update
09:21:09.181 INFO  [Executor task launch worker for task 528] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=118), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/118] for update
09:21:09.181 INFO  [Executor task launch worker for task 529] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=119), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/119] for update
09:21:09.181 INFO  [Executor task launch worker for task 528] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=118), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/118] for update
09:21:09.181 INFO  [Executor task launch worker for task 527] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=117),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/117]
09:21:09.197 INFO  [Executor task launch worker for task 528] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.197 INFO  [Executor task launch worker for task 529] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.197 INFO  [Executor task launch worker for task 528] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.197 INFO  [Executor task launch worker for task 529] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.197 INFO  [Executor task launch worker for task 527] org.apache.spark.executor.Executor - Finished task 117.0 in stage 9.0 (TID 527). 3322 bytes result sent to driver
09:21:09.197 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 120.0 in stage 9.0 (TID 530, localhost, executor driver, partition 120, PROCESS_LOCAL, 4726 bytes)
09:21:09.197 INFO  [Executor task launch worker for task 530] org.apache.spark.executor.Executor - Running task 120.0 in stage 9.0 (TID 530)
09:21:09.197 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 117.0 in stage 9.0 (TID 527) in 32 ms on localhost (executor driver) (118/200)
09:21:09.197 INFO  [Executor task launch worker for task 530] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=120), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/120] for update
09:21:09.197 INFO  [Executor task launch worker for task 530] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=120), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/120] for update
09:21:09.197 INFO  [Executor task launch worker for task 530] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.197 INFO  [Executor task launch worker for task 530] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.197 INFO  [Executor task launch worker for task 529] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=119),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/119] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/119/3.delta
09:21:09.197 INFO  [Executor task launch worker for task 528] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=118),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/118] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/118/3.delta
09:21:09.197 INFO  [Executor task launch worker for task 530] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=120),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/120] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/120/3.delta
09:21:09.197 INFO  [Executor task launch worker for task 529] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=119),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/119]
09:21:09.197 INFO  [Executor task launch worker for task 528] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=118),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/118]
09:21:09.197 INFO  [Executor task launch worker for task 530] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=120),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/120]
09:21:09.212 INFO  [Executor task launch worker for task 529] org.apache.spark.executor.Executor - Finished task 119.0 in stage 9.0 (TID 529). 3322 bytes result sent to driver
09:21:09.212 INFO  [Executor task launch worker for task 530] org.apache.spark.executor.Executor - Finished task 120.0 in stage 9.0 (TID 530). 3322 bytes result sent to driver
09:21:09.212 INFO  [Executor task launch worker for task 528] org.apache.spark.executor.Executor - Finished task 118.0 in stage 9.0 (TID 528). 3322 bytes result sent to driver
09:21:09.212 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 121.0 in stage 9.0 (TID 531, localhost, executor driver, partition 121, PROCESS_LOCAL, 4726 bytes)
09:21:09.212 INFO  [Executor task launch worker for task 531] org.apache.spark.executor.Executor - Running task 121.0 in stage 9.0 (TID 531)
09:21:09.212 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 122.0 in stage 9.0 (TID 532, localhost, executor driver, partition 122, PROCESS_LOCAL, 4726 bytes)
09:21:09.212 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 119.0 in stage 9.0 (TID 529) in 31 ms on localhost (executor driver) (119/200)
09:21:09.212 INFO  [Executor task launch worker for task 532] org.apache.spark.executor.Executor - Running task 122.0 in stage 9.0 (TID 532)
09:21:09.212 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 123.0 in stage 9.0 (TID 533, localhost, executor driver, partition 123, PROCESS_LOCAL, 4726 bytes)
09:21:09.212 INFO  [Executor task launch worker for task 533] org.apache.spark.executor.Executor - Running task 123.0 in stage 9.0 (TID 533)
09:21:09.212 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 120.0 in stage 9.0 (TID 530) in 15 ms on localhost (executor driver) (120/200)
09:21:09.212 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 118.0 in stage 9.0 (TID 528) in 31 ms on localhost (executor driver) (121/200)
09:21:09.212 INFO  [Executor task launch worker for task 531] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=121), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/121] for update
09:21:09.212 INFO  [Executor task launch worker for task 533] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=123), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/123] for update
09:21:09.212 INFO  [Executor task launch worker for task 531] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=121), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/121] for update
09:21:09.212 INFO  [Executor task launch worker for task 532] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=122), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/122] for update
09:21:09.212 INFO  [Executor task launch worker for task 533] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=123), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/123] for update
09:21:09.212 INFO  [Executor task launch worker for task 531] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.212 INFO  [Executor task launch worker for task 532] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=122), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/122] for update
09:21:09.228 INFO  [Executor task launch worker for task 531] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 16 ms
09:21:09.228 INFO  [Executor task launch worker for task 533] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.228 INFO  [Executor task launch worker for task 532] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.228 INFO  [Executor task launch worker for task 533] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.228 INFO  [Executor task launch worker for task 532] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.228 INFO  [Executor task launch worker for task 533] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=123),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/123] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/123/3.delta
09:21:09.228 INFO  [Executor task launch worker for task 532] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=122),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/122] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/122/3.delta
09:21:09.228 INFO  [Executor task launch worker for task 531] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=121),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/121] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/121/3.delta
09:21:09.228 INFO  [Executor task launch worker for task 531] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=121),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/121]
09:21:09.228 INFO  [Executor task launch worker for task 533] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=123),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/123]
09:21:09.228 INFO  [Executor task launch worker for task 533] org.apache.spark.executor.Executor - Finished task 123.0 in stage 9.0 (TID 533). 3322 bytes result sent to driver
09:21:09.228 INFO  [Executor task launch worker for task 531] org.apache.spark.executor.Executor - Finished task 121.0 in stage 9.0 (TID 531). 3322 bytes result sent to driver
09:21:09.228 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 124.0 in stage 9.0 (TID 534, localhost, executor driver, partition 124, PROCESS_LOCAL, 4726 bytes)
09:21:09.228 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 123.0 in stage 9.0 (TID 533) in 16 ms on localhost (executor driver) (122/200)
09:21:09.228 INFO  [Executor task launch worker for task 532] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=122),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/122]
09:21:09.228 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 125.0 in stage 9.0 (TID 535, localhost, executor driver, partition 125, PROCESS_LOCAL, 4726 bytes)
09:21:09.228 INFO  [Executor task launch worker for task 534] org.apache.spark.executor.Executor - Running task 124.0 in stage 9.0 (TID 534)
09:21:09.228 INFO  [Executor task launch worker for task 535] org.apache.spark.executor.Executor - Running task 125.0 in stage 9.0 (TID 535)
09:21:09.228 INFO  [Executor task launch worker for task 532] org.apache.spark.executor.Executor - Finished task 122.0 in stage 9.0 (TID 532). 3322 bytes result sent to driver
09:21:09.228 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 121.0 in stage 9.0 (TID 531) in 16 ms on localhost (executor driver) (123/200)
09:21:09.228 INFO  [Executor task launch worker for task 535] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=125), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/125] for update
09:21:09.228 INFO  [Executor task launch worker for task 534] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=124), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/124] for update
09:21:09.243 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 126.0 in stage 9.0 (TID 536, localhost, executor driver, partition 126, PROCESS_LOCAL, 4726 bytes)
09:21:09.243 INFO  [Executor task launch worker for task 535] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=125), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/125] for update
09:21:09.243 INFO  [Executor task launch worker for task 535] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.243 INFO  [Executor task launch worker for task 535] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.243 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 122.0 in stage 9.0 (TID 532) in 31 ms on localhost (executor driver) (124/200)
09:21:09.243 INFO  [Executor task launch worker for task 536] org.apache.spark.executor.Executor - Running task 126.0 in stage 9.0 (TID 536)
09:21:09.243 INFO  [Executor task launch worker for task 534] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=124), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/124] for update
09:21:09.243 INFO  [Executor task launch worker for task 534] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.243 INFO  [Executor task launch worker for task 534] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.243 INFO  [Executor task launch worker for task 536] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=126), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/126] for update
09:21:09.243 INFO  [Executor task launch worker for task 536] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=126), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/126] for update
09:21:09.243 INFO  [Executor task launch worker for task 536] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.243 INFO  [Executor task launch worker for task 536] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.243 INFO  [Executor task launch worker for task 534] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=124),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/124] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/124/3.delta
09:21:09.243 INFO  [Executor task launch worker for task 535] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=125),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/125] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/125/3.delta
09:21:09.243 INFO  [Executor task launch worker for task 536] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=126),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/126] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/126/3.delta
09:21:09.259 INFO  [Executor task launch worker for task 534] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=124),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/124]
09:21:09.259 INFO  [Executor task launch worker for task 536] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=126),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/126]
09:21:09.259 INFO  [Executor task launch worker for task 535] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=125),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/125]
09:21:09.259 INFO  [Executor task launch worker for task 536] org.apache.spark.executor.Executor - Finished task 126.0 in stage 9.0 (TID 536). 3322 bytes result sent to driver
09:21:09.259 INFO  [Executor task launch worker for task 535] org.apache.spark.executor.Executor - Finished task 125.0 in stage 9.0 (TID 535). 3322 bytes result sent to driver
09:21:09.259 INFO  [Executor task launch worker for task 534] org.apache.spark.executor.Executor - Finished task 124.0 in stage 9.0 (TID 534). 3322 bytes result sent to driver
09:21:09.259 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 127.0 in stage 9.0 (TID 537, localhost, executor driver, partition 127, PROCESS_LOCAL, 4726 bytes)
09:21:09.259 INFO  [Executor task launch worker for task 537] org.apache.spark.executor.Executor - Running task 127.0 in stage 9.0 (TID 537)
09:21:09.259 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 128.0 in stage 9.0 (TID 538, localhost, executor driver, partition 128, PROCESS_LOCAL, 4726 bytes)
09:21:09.259 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 129.0 in stage 9.0 (TID 539, localhost, executor driver, partition 129, PROCESS_LOCAL, 4726 bytes)
09:21:09.259 INFO  [Executor task launch worker for task 538] org.apache.spark.executor.Executor - Running task 128.0 in stage 9.0 (TID 538)
09:21:09.259 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 126.0 in stage 9.0 (TID 536) in 16 ms on localhost (executor driver) (125/200)
09:21:09.259 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 124.0 in stage 9.0 (TID 534) in 31 ms on localhost (executor driver) (126/200)
09:21:09.259 INFO  [Executor task launch worker for task 539] org.apache.spark.executor.Executor - Running task 129.0 in stage 9.0 (TID 539)
09:21:09.259 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 125.0 in stage 9.0 (TID 535) in 31 ms on localhost (executor driver) (127/200)
09:21:09.259 INFO  [Executor task launch worker for task 538] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=128), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/128] for update
09:21:09.259 INFO  [Executor task launch worker for task 537] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=127), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/127] for update
09:21:09.259 INFO  [Executor task launch worker for task 538] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=128), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/128] for update
09:21:09.259 INFO  [Executor task launch worker for task 539] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=129), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/129] for update
09:21:09.275 INFO  [Executor task launch worker for task 539] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=129), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/129] for update
09:21:09.275 INFO  [Executor task launch worker for task 537] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=127), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/127] for update
09:21:09.275 INFO  [Executor task launch worker for task 538] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.275 INFO  [Executor task launch worker for task 538] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.275 INFO  [Executor task launch worker for task 539] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.275 INFO  [Executor task launch worker for task 537] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.275 INFO  [Executor task launch worker for task 539] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.275 INFO  [Executor task launch worker for task 537] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.275 INFO  [Executor task launch worker for task 538] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=128),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/128] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/128/3.delta
09:21:09.275 INFO  [Executor task launch worker for task 539] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=129),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/129] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/129/3.delta
09:21:09.275 INFO  [Executor task launch worker for task 537] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=127),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/127] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/127/3.delta
09:21:09.290 INFO  [Executor task launch worker for task 538] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=128),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/128]
09:21:09.290 INFO  [Executor task launch worker for task 538] org.apache.spark.executor.Executor - Finished task 128.0 in stage 9.0 (TID 538). 3322 bytes result sent to driver
09:21:09.290 INFO  [Executor task launch worker for task 539] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=129),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/129]
09:21:09.290 INFO  [Executor task launch worker for task 539] org.apache.spark.executor.Executor - Finished task 129.0 in stage 9.0 (TID 539). 3365 bytes result sent to driver
09:21:09.290 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 130.0 in stage 9.0 (TID 540, localhost, executor driver, partition 130, PROCESS_LOCAL, 4726 bytes)
09:21:09.290 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 131.0 in stage 9.0 (TID 541, localhost, executor driver, partition 131, PROCESS_LOCAL, 4726 bytes)
09:21:09.290 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 128.0 in stage 9.0 (TID 538) in 31 ms on localhost (executor driver) (128/200)
09:21:09.290 INFO  [Executor task launch worker for task 540] org.apache.spark.executor.Executor - Running task 130.0 in stage 9.0 (TID 540)
09:21:09.290 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 129.0 in stage 9.0 (TID 539) in 31 ms on localhost (executor driver) (129/200)
09:21:09.290 INFO  [Executor task launch worker for task 537] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=127),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/127]
09:21:09.290 INFO  [Executor task launch worker for task 540] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=130), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/130] for update
09:21:09.290 INFO  [Executor task launch worker for task 540] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=130), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/130] for update
09:21:09.290 INFO  [Executor task launch worker for task 537] org.apache.spark.executor.Executor - Finished task 127.0 in stage 9.0 (TID 537). 3322 bytes result sent to driver
09:21:09.290 INFO  [Executor task launch worker for task 540] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.290 INFO  [Executor task launch worker for task 540] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.290 INFO  [Executor task launch worker for task 541] org.apache.spark.executor.Executor - Running task 131.0 in stage 9.0 (TID 541)
09:21:09.290 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 132.0 in stage 9.0 (TID 542, localhost, executor driver, partition 132, PROCESS_LOCAL, 4726 bytes)
09:21:09.290 INFO  [Executor task launch worker for task 542] org.apache.spark.executor.Executor - Running task 132.0 in stage 9.0 (TID 542)
09:21:09.290 INFO  [Executor task launch worker for task 542] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=132), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/132] for update
09:21:09.290 INFO  [Executor task launch worker for task 542] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=132), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/132] for update
09:21:09.290 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 127.0 in stage 9.0 (TID 537) in 31 ms on localhost (executor driver) (130/200)
09:21:09.290 INFO  [Executor task launch worker for task 541] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=131), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/131] for update
09:21:09.290 INFO  [Executor task launch worker for task 540] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=130),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/130] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/130/3.delta
09:21:09.306 INFO  [Executor task launch worker for task 542] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.306 INFO  [Executor task launch worker for task 542] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.306 INFO  [Executor task launch worker for task 541] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=131), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/131] for update
09:21:09.306 INFO  [Executor task launch worker for task 541] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.306 INFO  [Executor task launch worker for task 541] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.306 INFO  [Executor task launch worker for task 541] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=131),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/131] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/131/3.delta
09:21:09.322 INFO  [Executor task launch worker for task 541] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=131),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/131]
09:21:09.322 INFO  [Executor task launch worker for task 541] org.apache.spark.executor.Executor - Finished task 131.0 in stage 9.0 (TID 541). 3365 bytes result sent to driver
09:21:09.322 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 133.0 in stage 9.0 (TID 543, localhost, executor driver, partition 133, PROCESS_LOCAL, 4726 bytes)
09:21:09.322 INFO  [Executor task launch worker for task 543] org.apache.spark.executor.Executor - Running task 133.0 in stage 9.0 (TID 543)
09:21:09.322 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 131.0 in stage 9.0 (TID 541) in 32 ms on localhost (executor driver) (131/200)
09:21:09.322 INFO  [Executor task launch worker for task 543] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=133), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/133] for update
09:21:09.322 INFO  [Executor task launch worker for task 543] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=133), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/133] for update
09:21:09.322 INFO  [Executor task launch worker for task 543] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.322 INFO  [Executor task launch worker for task 543] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.322 INFO  [Executor task launch worker for task 540] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=130),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/130]
09:21:09.322 INFO  [Executor task launch worker for task 540] org.apache.spark.executor.Executor - Finished task 130.0 in stage 9.0 (TID 540). 3322 bytes result sent to driver
09:21:09.322 INFO  [Executor task launch worker for task 542] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=132),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/132] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/132/3.delta
09:21:09.322 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 134.0 in stage 9.0 (TID 544, localhost, executor driver, partition 134, PROCESS_LOCAL, 4726 bytes)
09:21:09.337 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 130.0 in stage 9.0 (TID 540) in 47 ms on localhost (executor driver) (132/200)
09:21:09.337 INFO  [Executor task launch worker for task 544] org.apache.spark.executor.Executor - Running task 134.0 in stage 9.0 (TID 544)
09:21:09.337 INFO  [Executor task launch worker for task 543] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=133),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/133] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/133/3.delta
09:21:09.337 INFO  [Executor task launch worker for task 544] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=134), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/134] for update
09:21:09.337 INFO  [Executor task launch worker for task 544] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=134), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/134] for update
09:21:09.337 INFO  [Executor task launch worker for task 544] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.337 INFO  [Executor task launch worker for task 544] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.337 INFO  [Executor task launch worker for task 542] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=132),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/132]
09:21:09.337 INFO  [Executor task launch worker for task 542] org.apache.spark.executor.Executor - Finished task 132.0 in stage 9.0 (TID 542). 3322 bytes result sent to driver
09:21:09.337 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 135.0 in stage 9.0 (TID 545, localhost, executor driver, partition 135, PROCESS_LOCAL, 4726 bytes)
09:21:09.337 INFO  [Executor task launch worker for task 545] org.apache.spark.executor.Executor - Running task 135.0 in stage 9.0 (TID 545)
09:21:09.337 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 132.0 in stage 9.0 (TID 542) in 47 ms on localhost (executor driver) (133/200)
09:21:09.337 INFO  [Executor task launch worker for task 543] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=133),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/133]
09:21:09.337 INFO  [Executor task launch worker for task 543] org.apache.spark.executor.Executor - Finished task 133.0 in stage 9.0 (TID 543). 3365 bytes result sent to driver
09:21:09.337 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 136.0 in stage 9.0 (TID 546, localhost, executor driver, partition 136, PROCESS_LOCAL, 4726 bytes)
09:21:09.337 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 133.0 in stage 9.0 (TID 543) in 15 ms on localhost (executor driver) (134/200)
09:21:09.337 INFO  [Executor task launch worker for task 546] org.apache.spark.executor.Executor - Running task 136.0 in stage 9.0 (TID 546)
09:21:09.337 INFO  [Executor task launch worker for task 545] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=135), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/135] for update
09:21:09.337 INFO  [Executor task launch worker for task 544] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=134),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/134] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/134/3.delta
09:21:09.353 INFO  [Executor task launch worker for task 545] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=135), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/135] for update
09:21:09.353 INFO  [Executor task launch worker for task 545] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.353 INFO  [Executor task launch worker for task 545] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.353 INFO  [Executor task launch worker for task 546] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=136), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/136] for update
09:21:09.353 INFO  [Executor task launch worker for task 546] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=136), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/136] for update
09:21:09.353 INFO  [Executor task launch worker for task 546] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.353 INFO  [Executor task launch worker for task 546] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.353 INFO  [Executor task launch worker for task 544] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=134),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/134]
09:21:09.353 INFO  [Executor task launch worker for task 545] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=135),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/135] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/135/3.delta
09:21:09.353 INFO  [Executor task launch worker for task 544] org.apache.spark.executor.Executor - Finished task 134.0 in stage 9.0 (TID 544). 3322 bytes result sent to driver
09:21:09.353 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 137.0 in stage 9.0 (TID 547, localhost, executor driver, partition 137, PROCESS_LOCAL, 4726 bytes)
09:21:09.353 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 134.0 in stage 9.0 (TID 544) in 31 ms on localhost (executor driver) (135/200)
09:21:09.353 INFO  [Executor task launch worker for task 547] org.apache.spark.executor.Executor - Running task 137.0 in stage 9.0 (TID 547)
09:21:09.353 INFO  [Executor task launch worker for task 546] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=136),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/136] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/136/3.delta
09:21:09.353 INFO  [Executor task launch worker for task 545] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=135),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/135]
09:21:09.353 INFO  [Executor task launch worker for task 545] org.apache.spark.executor.Executor - Finished task 135.0 in stage 9.0 (TID 545). 3322 bytes result sent to driver
09:21:09.353 INFO  [Executor task launch worker for task 546] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=136),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/136]
09:21:09.353 INFO  [Executor task launch worker for task 546] org.apache.spark.executor.Executor - Finished task 136.0 in stage 9.0 (TID 546). 3322 bytes result sent to driver
09:21:09.353 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 138.0 in stage 9.0 (TID 548, localhost, executor driver, partition 138, PROCESS_LOCAL, 4726 bytes)
09:21:09.353 INFO  [Executor task launch worker for task 548] org.apache.spark.executor.Executor - Running task 138.0 in stage 9.0 (TID 548)
09:21:09.353 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 139.0 in stage 9.0 (TID 549, localhost, executor driver, partition 139, PROCESS_LOCAL, 4726 bytes)
09:21:09.368 INFO  [Executor task launch worker for task 548] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=138), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/138] for update
09:21:09.368 INFO  [Executor task launch worker for task 548] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=138), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/138] for update
09:21:09.368 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 135.0 in stage 9.0 (TID 545) in 31 ms on localhost (executor driver) (136/200)
09:21:09.368 INFO  [Executor task launch worker for task 547] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=137), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/137] for update
09:21:09.368 INFO  [Executor task launch worker for task 548] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.368 INFO  [Executor task launch worker for task 549] org.apache.spark.executor.Executor - Running task 139.0 in stage 9.0 (TID 549)
09:21:09.368 INFO  [Executor task launch worker for task 547] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=137), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/137] for update
09:21:09.368 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 136.0 in stage 9.0 (TID 546) in 31 ms on localhost (executor driver) (137/200)
09:21:09.368 INFO  [Executor task launch worker for task 548] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.368 INFO  [Executor task launch worker for task 547] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.368 INFO  [Executor task launch worker for task 547] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.368 INFO  [Executor task launch worker for task 549] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=139), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/139] for update
09:21:09.368 INFO  [Executor task launch worker for task 549] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=139), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/139] for update
09:21:09.368 INFO  [Executor task launch worker for task 549] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.368 INFO  [Executor task launch worker for task 549] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.368 INFO  [Executor task launch worker for task 547] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=137),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/137] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/137/3.delta
09:21:09.368 INFO  [Executor task launch worker for task 548] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=138),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/138] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/138/3.delta
09:21:09.368 INFO  [Executor task launch worker for task 549] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=139),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/139] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/139/3.delta
09:21:09.368 INFO  [Executor task launch worker for task 548] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=138),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/138]
09:21:09.368 INFO  [Executor task launch worker for task 547] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=137),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/137]
09:21:09.368 INFO  [Executor task launch worker for task 548] org.apache.spark.executor.Executor - Finished task 138.0 in stage 9.0 (TID 548). 3365 bytes result sent to driver
09:21:09.368 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 140.0 in stage 9.0 (TID 550, localhost, executor driver, partition 140, PROCESS_LOCAL, 4726 bytes)
09:21:09.368 INFO  [Executor task launch worker for task 547] org.apache.spark.executor.Executor - Finished task 137.0 in stage 9.0 (TID 547). 3322 bytes result sent to driver
09:21:09.368 INFO  [Executor task launch worker for task 550] org.apache.spark.executor.Executor - Running task 140.0 in stage 9.0 (TID 550)
09:21:09.368 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 141.0 in stage 9.0 (TID 551, localhost, executor driver, partition 141, PROCESS_LOCAL, 4726 bytes)
09:21:09.368 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 138.0 in stage 9.0 (TID 548) in 15 ms on localhost (executor driver) (138/200)
09:21:09.368 INFO  [Executor task launch worker for task 551] org.apache.spark.executor.Executor - Running task 141.0 in stage 9.0 (TID 551)
09:21:09.368 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 137.0 in stage 9.0 (TID 547) in 15 ms on localhost (executor driver) (139/200)
09:21:09.384 INFO  [Executor task launch worker for task 550] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=140), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/140] for update
09:21:09.384 INFO  [Executor task launch worker for task 550] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=140), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/140] for update
09:21:09.384 INFO  [Executor task launch worker for task 551] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=141), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/141] for update
09:21:09.384 INFO  [Executor task launch worker for task 550] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.384 INFO  [Executor task launch worker for task 551] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=141), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/141] for update
09:21:09.384 INFO  [Executor task launch worker for task 550] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.384 INFO  [Executor task launch worker for task 551] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.384 INFO  [Executor task launch worker for task 551] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.384 INFO  [Executor task launch worker for task 549] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=139),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/139]
09:21:09.384 INFO  [Executor task launch worker for task 549] org.apache.spark.executor.Executor - Finished task 139.0 in stage 9.0 (TID 549). 3365 bytes result sent to driver
09:21:09.384 INFO  [Executor task launch worker for task 551] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=141),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/141] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/141/3.delta
09:21:09.384 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 142.0 in stage 9.0 (TID 552, localhost, executor driver, partition 142, PROCESS_LOCAL, 4726 bytes)
09:21:09.384 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 139.0 in stage 9.0 (TID 549) in 31 ms on localhost (executor driver) (140/200)
09:21:09.384 INFO  [Executor task launch worker for task 552] org.apache.spark.executor.Executor - Running task 142.0 in stage 9.0 (TID 552)
09:21:09.384 INFO  [Executor task launch worker for task 552] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=142), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/142] for update
09:21:09.384 INFO  [Executor task launch worker for task 552] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=142), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/142] for update
09:21:09.384 INFO  [Executor task launch worker for task 552] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.384 INFO  [Executor task launch worker for task 552] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.384 INFO  [Executor task launch worker for task 551] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=141),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/141]
09:21:09.384 INFO  [Executor task launch worker for task 551] org.apache.spark.executor.Executor - Finished task 141.0 in stage 9.0 (TID 551). 3365 bytes result sent to driver
09:21:09.384 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 143.0 in stage 9.0 (TID 553, localhost, executor driver, partition 143, PROCESS_LOCAL, 4726 bytes)
09:21:09.384 INFO  [Executor task launch worker for task 553] org.apache.spark.executor.Executor - Running task 143.0 in stage 9.0 (TID 553)
09:21:09.384 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 141.0 in stage 9.0 (TID 551) in 16 ms on localhost (executor driver) (141/200)
09:21:09.384 INFO  [Executor task launch worker for task 553] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=143), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/143] for update
09:21:09.384 INFO  [Executor task launch worker for task 550] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=140),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/140] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/140/3.delta
09:21:09.400 INFO  [Executor task launch worker for task 553] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=143), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/143] for update
09:21:09.400 INFO  [Executor task launch worker for task 553] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.400 INFO  [Executor task launch worker for task 553] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.400 INFO  [Executor task launch worker for task 552] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=142),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/142] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/142/3.delta
09:21:09.400 INFO  [Executor task launch worker for task 550] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=140),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/140]
09:21:09.400 INFO  [Executor task launch worker for task 552] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=142),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/142]
09:21:09.400 INFO  [Executor task launch worker for task 550] org.apache.spark.executor.Executor - Finished task 140.0 in stage 9.0 (TID 550). 3408 bytes result sent to driver
09:21:09.400 INFO  [Executor task launch worker for task 552] org.apache.spark.executor.Executor - Finished task 142.0 in stage 9.0 (TID 552). 3365 bytes result sent to driver
09:21:09.400 INFO  [Executor task launch worker for task 553] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=143),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/143] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/143/3.delta
09:21:09.400 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 144.0 in stage 9.0 (TID 554, localhost, executor driver, partition 144, PROCESS_LOCAL, 4726 bytes)
09:21:09.400 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 145.0 in stage 9.0 (TID 555, localhost, executor driver, partition 145, PROCESS_LOCAL, 4726 bytes)
09:21:09.400 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 140.0 in stage 9.0 (TID 550) in 32 ms on localhost (executor driver) (142/200)
09:21:09.400 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 142.0 in stage 9.0 (TID 552) in 16 ms on localhost (executor driver) (143/200)
09:21:09.400 INFO  [Executor task launch worker for task 554] org.apache.spark.executor.Executor - Running task 144.0 in stage 9.0 (TID 554)
09:21:09.400 INFO  [Executor task launch worker for task 555] org.apache.spark.executor.Executor - Running task 145.0 in stage 9.0 (TID 555)
09:21:09.400 INFO  [Executor task launch worker for task 554] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=144), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/144] for update
09:21:09.400 INFO  [Executor task launch worker for task 554] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=144), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/144] for update
09:21:09.400 INFO  [Executor task launch worker for task 555] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=145), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/145] for update
09:21:09.400 INFO  [Executor task launch worker for task 554] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.400 INFO  [Executor task launch worker for task 554] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.400 INFO  [Executor task launch worker for task 555] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=145), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/145] for update
09:21:09.400 INFO  [Executor task launch worker for task 553] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=143),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/143]
09:21:09.415 INFO  [Executor task launch worker for task 555] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.415 INFO  [Executor task launch worker for task 555] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.415 INFO  [Executor task launch worker for task 553] org.apache.spark.executor.Executor - Finished task 143.0 in stage 9.0 (TID 553). 3322 bytes result sent to driver
09:21:09.415 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 146.0 in stage 9.0 (TID 556, localhost, executor driver, partition 146, PROCESS_LOCAL, 4726 bytes)
09:21:09.415 INFO  [Executor task launch worker for task 556] org.apache.spark.executor.Executor - Running task 146.0 in stage 9.0 (TID 556)
09:21:09.415 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 143.0 in stage 9.0 (TID 553) in 31 ms on localhost (executor driver) (144/200)
09:21:09.415 INFO  [Executor task launch worker for task 556] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=146), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/146] for update
09:21:09.415 INFO  [Executor task launch worker for task 556] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=146), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/146] for update
09:21:09.415 INFO  [Executor task launch worker for task 556] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.415 INFO  [Executor task launch worker for task 556] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.431 INFO  [Executor task launch worker for task 555] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=145),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/145] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/145/3.delta
09:21:09.431 INFO  [Executor task launch worker for task 554] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=144),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/144] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/144/3.delta
09:21:09.431 INFO  [Executor task launch worker for task 556] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=146),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/146] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/146/3.delta
09:21:09.431 INFO  [Executor task launch worker for task 554] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=144),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/144]
09:21:09.431 INFO  [Executor task launch worker for task 554] org.apache.spark.executor.Executor - Finished task 144.0 in stage 9.0 (TID 554). 3408 bytes result sent to driver
09:21:09.431 INFO  [Executor task launch worker for task 555] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=145),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/145]
09:21:09.431 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 147.0 in stage 9.0 (TID 557, localhost, executor driver, partition 147, PROCESS_LOCAL, 4726 bytes)
09:21:09.431 INFO  [Executor task launch worker for task 555] org.apache.spark.executor.Executor - Finished task 145.0 in stage 9.0 (TID 555). 3437 bytes result sent to driver
09:21:09.431 INFO  [Executor task launch worker for task 557] org.apache.spark.executor.Executor - Running task 147.0 in stage 9.0 (TID 557)
09:21:09.431 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 144.0 in stage 9.0 (TID 554) in 31 ms on localhost (executor driver) (145/200)
09:21:09.431 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 148.0 in stage 9.0 (TID 558, localhost, executor driver, partition 148, PROCESS_LOCAL, 4726 bytes)
09:21:09.431 INFO  [Executor task launch worker for task 558] org.apache.spark.executor.Executor - Running task 148.0 in stage 9.0 (TID 558)
09:21:09.431 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 145.0 in stage 9.0 (TID 555) in 31 ms on localhost (executor driver) (146/200)
09:21:09.431 INFO  [Executor task launch worker for task 556] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=146),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/146]
09:21:09.431 INFO  [Executor task launch worker for task 558] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=148), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/148] for update
09:21:09.431 INFO  [Executor task launch worker for task 556] org.apache.spark.executor.Executor - Finished task 146.0 in stage 9.0 (TID 556). 3408 bytes result sent to driver
09:21:09.431 INFO  [Executor task launch worker for task 557] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=147), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/147] for update
09:21:09.447 INFO  [Executor task launch worker for task 558] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=148), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/148] for update
09:21:09.447 INFO  [Executor task launch worker for task 557] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=147), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/147] for update
09:21:09.447 INFO  [Executor task launch worker for task 557] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.447 INFO  [Executor task launch worker for task 558] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.447 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 149.0 in stage 9.0 (TID 559, localhost, executor driver, partition 149, PROCESS_LOCAL, 4726 bytes)
09:21:09.447 INFO  [Executor task launch worker for task 557] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.447 INFO  [Executor task launch worker for task 558] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.447 INFO  [Executor task launch worker for task 559] org.apache.spark.executor.Executor - Running task 149.0 in stage 9.0 (TID 559)
09:21:09.447 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 146.0 in stage 9.0 (TID 556) in 32 ms on localhost (executor driver) (147/200)
09:21:09.447 INFO  [Executor task launch worker for task 559] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=149), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/149] for update
09:21:09.447 INFO  [Executor task launch worker for task 559] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=149), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/149] for update
09:21:09.447 INFO  [Executor task launch worker for task 559] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.447 INFO  [Executor task launch worker for task 559] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.447 INFO  [Executor task launch worker for task 557] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=147),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/147] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/147/3.delta
09:21:09.447 INFO  [Executor task launch worker for task 558] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=148),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/148] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/148/3.delta
09:21:09.447 INFO  [Executor task launch worker for task 559] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=149),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/149] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/149/3.delta
09:21:09.447 INFO  [Executor task launch worker for task 557] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=147),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/147]
09:21:09.447 INFO  [Executor task launch worker for task 558] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=148),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/148]
09:21:09.447 INFO  [Executor task launch worker for task 557] org.apache.spark.executor.Executor - Finished task 147.0 in stage 9.0 (TID 557). 3322 bytes result sent to driver
09:21:09.447 INFO  [Executor task launch worker for task 559] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=149),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/149]
09:21:09.462 INFO  [Executor task launch worker for task 558] org.apache.spark.executor.Executor - Finished task 148.0 in stage 9.0 (TID 558). 3322 bytes result sent to driver
09:21:09.462 INFO  [Executor task launch worker for task 559] org.apache.spark.executor.Executor - Finished task 149.0 in stage 9.0 (TID 559). 3322 bytes result sent to driver
09:21:09.462 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 150.0 in stage 9.0 (TID 560, localhost, executor driver, partition 150, PROCESS_LOCAL, 4726 bytes)
09:21:09.462 INFO  [Executor task launch worker for task 560] org.apache.spark.executor.Executor - Running task 150.0 in stage 9.0 (TID 560)
09:21:09.462 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 151.0 in stage 9.0 (TID 561, localhost, executor driver, partition 151, PROCESS_LOCAL, 4726 bytes)
09:21:09.462 INFO  [Executor task launch worker for task 561] org.apache.spark.executor.Executor - Running task 151.0 in stage 9.0 (TID 561)
09:21:09.462 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 152.0 in stage 9.0 (TID 562, localhost, executor driver, partition 152, PROCESS_LOCAL, 4726 bytes)
09:21:09.462 INFO  [Executor task launch worker for task 562] org.apache.spark.executor.Executor - Running task 152.0 in stage 9.0 (TID 562)
09:21:09.462 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 149.0 in stage 9.0 (TID 559) in 15 ms on localhost (executor driver) (148/200)
09:21:09.462 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 147.0 in stage 9.0 (TID 557) in 31 ms on localhost (executor driver) (149/200)
09:21:09.462 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 148.0 in stage 9.0 (TID 558) in 31 ms on localhost (executor driver) (150/200)
09:21:09.462 INFO  [Executor task launch worker for task 562] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=152), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/152] for update
09:21:09.462 INFO  [Executor task launch worker for task 561] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=151), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/151] for update
09:21:09.462 INFO  [Executor task launch worker for task 560] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=150), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/150] for update
09:21:09.462 INFO  [Executor task launch worker for task 562] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=152), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/152] for update
09:21:09.462 INFO  [Executor task launch worker for task 561] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=151), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/151] for update
09:21:09.462 INFO  [Executor task launch worker for task 560] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=150), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/150] for update
09:21:09.462 INFO  [Executor task launch worker for task 562] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.462 INFO  [Executor task launch worker for task 561] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.478 INFO  [Executor task launch worker for task 562] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 16 ms
09:21:09.478 INFO  [Executor task launch worker for task 561] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 16 ms
09:21:09.478 INFO  [Executor task launch worker for task 560] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.478 INFO  [Executor task launch worker for task 560] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.478 INFO  [Executor task launch worker for task 560] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=150),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/150] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/150/3.delta
09:21:09.478 INFO  [Executor task launch worker for task 562] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=152),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/152] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/152/3.delta
09:21:09.478 INFO  [Executor task launch worker for task 561] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=151),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/151] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/151/3.delta
09:21:09.493 INFO  [Executor task launch worker for task 560] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=150),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/150]
09:21:09.493 INFO  [Executor task launch worker for task 560] org.apache.spark.executor.Executor - Finished task 150.0 in stage 9.0 (TID 560). 3365 bytes result sent to driver
09:21:09.493 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 153.0 in stage 9.0 (TID 563, localhost, executor driver, partition 153, PROCESS_LOCAL, 4726 bytes)
09:21:09.493 INFO  [Executor task launch worker for task 563] org.apache.spark.executor.Executor - Running task 153.0 in stage 9.0 (TID 563)
09:21:09.493 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 150.0 in stage 9.0 (TID 560) in 31 ms on localhost (executor driver) (151/200)
09:21:09.493 INFO  [Executor task launch worker for task 562] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=152),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/152]
09:21:09.493 INFO  [Executor task launch worker for task 562] org.apache.spark.executor.Executor - Finished task 152.0 in stage 9.0 (TID 562). 3365 bytes result sent to driver
09:21:09.493 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 154.0 in stage 9.0 (TID 564, localhost, executor driver, partition 154, PROCESS_LOCAL, 4726 bytes)
09:21:09.493 INFO  [Executor task launch worker for task 564] org.apache.spark.executor.Executor - Running task 154.0 in stage 9.0 (TID 564)
09:21:09.493 INFO  [Executor task launch worker for task 563] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=153), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/153] for update
09:21:09.493 INFO  [Executor task launch worker for task 563] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=153), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/153] for update
09:21:09.493 INFO  [Executor task launch worker for task 561] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=151),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/151]
09:21:09.493 INFO  [Executor task launch worker for task 563] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.493 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 152.0 in stage 9.0 (TID 562) in 31 ms on localhost (executor driver) (152/200)
09:21:09.493 INFO  [Executor task launch worker for task 563] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.493 INFO  [Executor task launch worker for task 561] org.apache.spark.executor.Executor - Finished task 151.0 in stage 9.0 (TID 561). 3394 bytes result sent to driver
09:21:09.493 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 155.0 in stage 9.0 (TID 565, localhost, executor driver, partition 155, PROCESS_LOCAL, 4726 bytes)
09:21:09.493 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 151.0 in stage 9.0 (TID 561) in 31 ms on localhost (executor driver) (153/200)
09:21:09.493 INFO  [Executor task launch worker for task 564] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=154), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/154] for update
09:21:09.493 INFO  [Executor task launch worker for task 565] org.apache.spark.executor.Executor - Running task 155.0 in stage 9.0 (TID 565)
09:21:09.493 INFO  [Executor task launch worker for task 563] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=153),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/153] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/153/3.delta
09:21:09.509 INFO  [Executor task launch worker for task 564] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=154), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/154] for update
09:21:09.509 INFO  [Executor task launch worker for task 564] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.509 INFO  [Executor task launch worker for task 564] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.509 INFO  [Executor task launch worker for task 565] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=155), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/155] for update
09:21:09.509 INFO  [Executor task launch worker for task 565] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=155), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/155] for update
09:21:09.509 INFO  [Executor task launch worker for task 565] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.509 INFO  [Executor task launch worker for task 565] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.509 INFO  [Executor task launch worker for task 563] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=153),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/153]
09:21:09.509 INFO  [Executor task launch worker for task 563] org.apache.spark.executor.Executor - Finished task 153.0 in stage 9.0 (TID 563). 3322 bytes result sent to driver
09:21:09.509 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 156.0 in stage 9.0 (TID 566, localhost, executor driver, partition 156, PROCESS_LOCAL, 4726 bytes)
09:21:09.509 INFO  [Executor task launch worker for task 566] org.apache.spark.executor.Executor - Running task 156.0 in stage 9.0 (TID 566)
09:21:09.509 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 153.0 in stage 9.0 (TID 563) in 16 ms on localhost (executor driver) (154/200)
09:21:09.509 INFO  [Executor task launch worker for task 564] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=154),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/154] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/154/3.delta
09:21:09.509 INFO  [Executor task launch worker for task 566] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=156), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/156] for update
09:21:09.509 INFO  [Executor task launch worker for task 566] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=156), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/156] for update
09:21:09.509 INFO  [Executor task launch worker for task 566] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.509 INFO  [Executor task launch worker for task 566] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.509 INFO  [Executor task launch worker for task 565] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=155),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/155] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/155/3.delta
09:21:09.509 INFO  [Executor task launch worker for task 564] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=154),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/154]
09:21:09.509 INFO  [Executor task launch worker for task 566] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=156),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/156] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/156/3.delta
09:21:09.525 INFO  [Executor task launch worker for task 564] org.apache.spark.executor.Executor - Finished task 154.0 in stage 9.0 (TID 564). 3322 bytes result sent to driver
09:21:09.525 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 157.0 in stage 9.0 (TID 567, localhost, executor driver, partition 157, PROCESS_LOCAL, 4726 bytes)
09:21:09.525 INFO  [Executor task launch worker for task 567] org.apache.spark.executor.Executor - Running task 157.0 in stage 9.0 (TID 567)
09:21:09.525 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 154.0 in stage 9.0 (TID 564) in 32 ms on localhost (executor driver) (155/200)
09:21:09.525 INFO  [Executor task launch worker for task 567] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=157), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/157] for update
09:21:09.525 INFO  [Executor task launch worker for task 567] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=157), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/157] for update
09:21:09.525 INFO  [Executor task launch worker for task 567] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.525 INFO  [Executor task launch worker for task 567] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.525 INFO  [Executor task launch worker for task 565] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=155),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/155]
09:21:09.525 INFO  [Executor task launch worker for task 566] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=156),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/156]
09:21:09.525 INFO  [Executor task launch worker for task 565] org.apache.spark.executor.Executor - Finished task 155.0 in stage 9.0 (TID 565). 3365 bytes result sent to driver
09:21:09.525 INFO  [Executor task launch worker for task 566] org.apache.spark.executor.Executor - Finished task 156.0 in stage 9.0 (TID 566). 3351 bytes result sent to driver
09:21:09.525 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 158.0 in stage 9.0 (TID 568, localhost, executor driver, partition 158, PROCESS_LOCAL, 4726 bytes)
09:21:09.525 INFO  [Executor task launch worker for task 568] org.apache.spark.executor.Executor - Running task 158.0 in stage 9.0 (TID 568)
09:21:09.525 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 155.0 in stage 9.0 (TID 565) in 32 ms on localhost (executor driver) (156/200)
09:21:09.525 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 159.0 in stage 9.0 (TID 569, localhost, executor driver, partition 159, PROCESS_LOCAL, 4726 bytes)
09:21:09.525 INFO  [Executor task launch worker for task 569] org.apache.spark.executor.Executor - Running task 159.0 in stage 9.0 (TID 569)
09:21:09.525 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 156.0 in stage 9.0 (TID 566) in 16 ms on localhost (executor driver) (157/200)
09:21:09.525 INFO  [Executor task launch worker for task 569] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=159), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/159] for update
09:21:09.525 INFO  [Executor task launch worker for task 568] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=158), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/158] for update
09:21:09.525 INFO  [Executor task launch worker for task 567] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=157),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/157] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/157/3.delta
09:21:09.540 INFO  [Executor task launch worker for task 569] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=159), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/159] for update
09:21:09.540 INFO  [Executor task launch worker for task 568] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=158), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/158] for update
09:21:09.540 INFO  [Executor task launch worker for task 569] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.540 INFO  [Executor task launch worker for task 568] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.540 INFO  [Executor task launch worker for task 569] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.540 INFO  [Executor task launch worker for task 568] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.540 INFO  [Executor task launch worker for task 567] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=157),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/157]
09:21:09.540 INFO  [Executor task launch worker for task 567] org.apache.spark.executor.Executor - Finished task 157.0 in stage 9.0 (TID 567). 3322 bytes result sent to driver
09:21:09.540 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 160.0 in stage 9.0 (TID 570, localhost, executor driver, partition 160, PROCESS_LOCAL, 4726 bytes)
09:21:09.540 INFO  [Executor task launch worker for task 570] org.apache.spark.executor.Executor - Running task 160.0 in stage 9.0 (TID 570)
09:21:09.540 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 157.0 in stage 9.0 (TID 567) in 15 ms on localhost (executor driver) (158/200)
09:21:09.540 INFO  [Executor task launch worker for task 569] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=159),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/159] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/159/3.delta
09:21:09.540 INFO  [Executor task launch worker for task 568] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=158),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/158] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/158/3.delta
09:21:09.540 INFO  [Executor task launch worker for task 570] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=160), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/160] for update
09:21:09.540 INFO  [Executor task launch worker for task 570] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=160), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/160] for update
09:21:09.540 INFO  [Executor task launch worker for task 570] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.540 INFO  [Executor task launch worker for task 570] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.540 INFO  [Executor task launch worker for task 569] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=159),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/159]
09:21:09.540 INFO  [Executor task launch worker for task 568] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=158),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/158]
09:21:09.540 INFO  [Executor task launch worker for task 570] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=160),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/160] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/160/3.delta
09:21:09.556 INFO  [Executor task launch worker for task 569] org.apache.spark.executor.Executor - Finished task 159.0 in stage 9.0 (TID 569). 3322 bytes result sent to driver
09:21:09.556 INFO  [Executor task launch worker for task 568] org.apache.spark.executor.Executor - Finished task 158.0 in stage 9.0 (TID 568). 3322 bytes result sent to driver
09:21:09.556 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 161.0 in stage 9.0 (TID 571, localhost, executor driver, partition 161, PROCESS_LOCAL, 4726 bytes)
09:21:09.556 INFO  [Executor task launch worker for task 571] org.apache.spark.executor.Executor - Running task 161.0 in stage 9.0 (TID 571)
09:21:09.556 INFO  [dispatcher-event-loop-6] org.apache.spark.scheduler.TaskSetManager - Starting task 162.0 in stage 9.0 (TID 572, localhost, executor driver, partition 162, PROCESS_LOCAL, 4726 bytes)
09:21:09.556 INFO  [Executor task launch worker for task 572] org.apache.spark.executor.Executor - Running task 162.0 in stage 9.0 (TID 572)
09:21:09.556 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 159.0 in stage 9.0 (TID 569) in 31 ms on localhost (executor driver) (159/200)
09:21:09.556 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 158.0 in stage 9.0 (TID 568) in 31 ms on localhost (executor driver) (160/200)
09:21:09.556 INFO  [Executor task launch worker for task 571] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=161), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/161] for update
09:21:09.556 INFO  [Executor task launch worker for task 571] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=161), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/161] for update
09:21:09.556 INFO  [Executor task launch worker for task 571] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.556 INFO  [Executor task launch worker for task 571] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.556 INFO  [Executor task launch worker for task 572] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=162), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/162] for update
09:21:09.556 INFO  [Executor task launch worker for task 572] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=162), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/162] for update
09:21:09.556 INFO  [Executor task launch worker for task 572] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.556 INFO  [Executor task launch worker for task 572] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.556 INFO  [Executor task launch worker for task 570] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=160),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/160]
09:21:09.556 INFO  [Executor task launch worker for task 571] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=161),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/161] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/161/3.delta
09:21:09.556 INFO  [Executor task launch worker for task 572] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=162),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/162] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/162/3.delta
09:21:09.572 INFO  [Executor task launch worker for task 570] org.apache.spark.executor.Executor - Finished task 160.0 in stage 9.0 (TID 570). 3322 bytes result sent to driver
09:21:09.572 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 163.0 in stage 9.0 (TID 573, localhost, executor driver, partition 163, PROCESS_LOCAL, 4726 bytes)
09:21:09.572 INFO  [Executor task launch worker for task 573] org.apache.spark.executor.Executor - Running task 163.0 in stage 9.0 (TID 573)
09:21:09.572 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 160.0 in stage 9.0 (TID 570) in 32 ms on localhost (executor driver) (161/200)
09:21:09.572 INFO  [Executor task launch worker for task 573] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=163), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/163] for update
09:21:09.572 INFO  [Executor task launch worker for task 573] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=163), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/163] for update
09:21:09.572 INFO  [Executor task launch worker for task 573] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.572 INFO  [Executor task launch worker for task 573] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.572 INFO  [Executor task launch worker for task 571] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=161),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/161]
09:21:09.572 INFO  [Executor task launch worker for task 572] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=162),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/162]
09:21:09.572 INFO  [Executor task launch worker for task 571] org.apache.spark.executor.Executor - Finished task 161.0 in stage 9.0 (TID 571). 3322 bytes result sent to driver
09:21:09.572 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 164.0 in stage 9.0 (TID 574, localhost, executor driver, partition 164, PROCESS_LOCAL, 4726 bytes)
09:21:09.572 INFO  [Executor task launch worker for task 572] org.apache.spark.executor.Executor - Finished task 162.0 in stage 9.0 (TID 572). 3322 bytes result sent to driver
09:21:09.572 INFO  [Executor task launch worker for task 574] org.apache.spark.executor.Executor - Running task 164.0 in stage 9.0 (TID 574)
09:21:09.572 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 161.0 in stage 9.0 (TID 571) in 16 ms on localhost (executor driver) (162/200)
09:21:09.572 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 165.0 in stage 9.0 (TID 575, localhost, executor driver, partition 165, PROCESS_LOCAL, 4726 bytes)
09:21:09.572 INFO  [Executor task launch worker for task 575] org.apache.spark.executor.Executor - Running task 165.0 in stage 9.0 (TID 575)
09:21:09.572 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 162.0 in stage 9.0 (TID 572) in 16 ms on localhost (executor driver) (163/200)
09:21:09.572 INFO  [Executor task launch worker for task 574] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=164), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/164] for update
09:21:09.572 INFO  [Executor task launch worker for task 575] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=165), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/165] for update
09:21:09.587 INFO  [Executor task launch worker for task 574] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=164), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/164] for update
09:21:09.587 INFO  [Executor task launch worker for task 575] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=165), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/165] for update
09:21:09.587 INFO  [Executor task launch worker for task 574] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.587 INFO  [Executor task launch worker for task 575] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.587 INFO  [Executor task launch worker for task 574] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.587 INFO  [Executor task launch worker for task 575] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.587 INFO  [Executor task launch worker for task 573] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=163),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/163] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/163/3.delta
09:21:09.587 INFO  [Executor task launch worker for task 573] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=163),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/163]
09:21:09.587 INFO  [Executor task launch worker for task 574] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=164),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/164] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/164/3.delta
09:21:09.587 INFO  [Executor task launch worker for task 573] org.apache.spark.executor.Executor - Finished task 163.0 in stage 9.0 (TID 573). 3365 bytes result sent to driver
09:21:09.587 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 166.0 in stage 9.0 (TID 576, localhost, executor driver, partition 166, PROCESS_LOCAL, 4726 bytes)
09:21:09.587 INFO  [Executor task launch worker for task 576] org.apache.spark.executor.Executor - Running task 166.0 in stage 9.0 (TID 576)
09:21:09.587 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 163.0 in stage 9.0 (TID 573) in 15 ms on localhost (executor driver) (164/200)
09:21:09.587 INFO  [Executor task launch worker for task 575] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=165),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/165] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/165/3.delta
09:21:09.587 INFO  [Executor task launch worker for task 576] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=166), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/166] for update
09:21:09.587 INFO  [Executor task launch worker for task 575] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=165),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/165]
09:21:09.587 INFO  [Executor task launch worker for task 574] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=164),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/164]
09:21:09.603 INFO  [Executor task launch worker for task 576] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=166), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/166] for update
09:21:09.603 INFO  [Executor task launch worker for task 576] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.603 INFO  [Executor task launch worker for task 576] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.603 INFO  [Executor task launch worker for task 574] org.apache.spark.executor.Executor - Finished task 164.0 in stage 9.0 (TID 574). 3322 bytes result sent to driver
09:21:09.603 INFO  [Executor task launch worker for task 575] org.apache.spark.executor.Executor - Finished task 165.0 in stage 9.0 (TID 575). 3322 bytes result sent to driver
09:21:09.603 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 167.0 in stage 9.0 (TID 577, localhost, executor driver, partition 167, PROCESS_LOCAL, 4726 bytes)
09:21:09.603 INFO  [Executor task launch worker for task 577] org.apache.spark.executor.Executor - Running task 167.0 in stage 9.0 (TID 577)
09:21:09.603 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 168.0 in stage 9.0 (TID 578, localhost, executor driver, partition 168, PROCESS_LOCAL, 4726 bytes)
09:21:09.603 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 164.0 in stage 9.0 (TID 574) in 31 ms on localhost (executor driver) (165/200)
09:21:09.603 INFO  [Executor task launch worker for task 578] org.apache.spark.executor.Executor - Running task 168.0 in stage 9.0 (TID 578)
09:21:09.603 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 165.0 in stage 9.0 (TID 575) in 31 ms on localhost (executor driver) (166/200)
09:21:09.603 INFO  [Executor task launch worker for task 578] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=168), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/168] for update
09:21:09.603 INFO  [Executor task launch worker for task 578] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=168), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/168] for update
09:21:09.603 INFO  [Executor task launch worker for task 578] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.603 INFO  [Executor task launch worker for task 578] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.603 INFO  [Executor task launch worker for task 577] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=167), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/167] for update
09:21:09.603 INFO  [Executor task launch worker for task 577] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=167), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/167] for update
09:21:09.603 INFO  [Executor task launch worker for task 577] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.603 INFO  [Executor task launch worker for task 577] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.603 INFO  [Executor task launch worker for task 576] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=166),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/166] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/166/3.delta
09:21:09.603 INFO  [Executor task launch worker for task 578] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=168),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/168] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/168/3.delta
09:21:09.634 INFO  [Executor task launch worker for task 576] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=166),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/166]
09:21:09.634 INFO  [Executor task launch worker for task 576] org.apache.spark.executor.Executor - Finished task 166.0 in stage 9.0 (TID 576). 3365 bytes result sent to driver
09:21:09.634 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 169.0 in stage 9.0 (TID 579, localhost, executor driver, partition 169, PROCESS_LOCAL, 4726 bytes)
09:21:09.634 INFO  [Executor task launch worker for task 579] org.apache.spark.executor.Executor - Running task 169.0 in stage 9.0 (TID 579)
09:21:09.634 INFO  [Executor task launch worker for task 578] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=168),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/168]
09:21:09.634 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 166.0 in stage 9.0 (TID 576) in 47 ms on localhost (executor driver) (167/200)
09:21:09.634 INFO  [Executor task launch worker for task 578] org.apache.spark.executor.Executor - Finished task 168.0 in stage 9.0 (TID 578). 3365 bytes result sent to driver
09:21:09.634 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 170.0 in stage 9.0 (TID 580, localhost, executor driver, partition 170, PROCESS_LOCAL, 4726 bytes)
09:21:09.634 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 168.0 in stage 9.0 (TID 578) in 31 ms on localhost (executor driver) (168/200)
09:21:09.634 INFO  [Executor task launch worker for task 580] org.apache.spark.executor.Executor - Running task 170.0 in stage 9.0 (TID 580)
09:21:09.634 INFO  [Executor task launch worker for task 579] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=169), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/169] for update
09:21:09.634 INFO  [Executor task launch worker for task 579] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=169), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/169] for update
09:21:09.634 INFO  [Executor task launch worker for task 579] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.634 INFO  [Executor task launch worker for task 579] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.634 INFO  [Executor task launch worker for task 577] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=167),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/167] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/167/3.delta
09:21:09.634 INFO  [Executor task launch worker for task 580] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=170), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/170] for update
09:21:09.634 INFO  [Executor task launch worker for task 580] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=170), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/170] for update
09:21:09.634 INFO  [Executor task launch worker for task 580] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.634 INFO  [Executor task launch worker for task 580] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.650 INFO  [Executor task launch worker for task 579] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=169),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/169] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/169/3.delta
09:21:09.650 INFO  [Executor task launch worker for task 580] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=170),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/170] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/170/3.delta
09:21:09.650 INFO  [Executor task launch worker for task 577] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=167),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/167]
09:21:09.650 INFO  [Executor task launch worker for task 577] org.apache.spark.executor.Executor - Finished task 167.0 in stage 9.0 (TID 577). 3365 bytes result sent to driver
09:21:09.650 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 171.0 in stage 9.0 (TID 581, localhost, executor driver, partition 171, PROCESS_LOCAL, 4726 bytes)
09:21:09.650 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 167.0 in stage 9.0 (TID 577) in 47 ms on localhost (executor driver) (169/200)
09:21:09.650 INFO  [Executor task launch worker for task 581] org.apache.spark.executor.Executor - Running task 171.0 in stage 9.0 (TID 581)
09:21:09.650 INFO  [Executor task launch worker for task 579] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=169),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/169]
09:21:09.650 INFO  [Executor task launch worker for task 579] org.apache.spark.executor.Executor - Finished task 169.0 in stage 9.0 (TID 579). 3365 bytes result sent to driver
09:21:09.650 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 172.0 in stage 9.0 (TID 582, localhost, executor driver, partition 172, PROCESS_LOCAL, 4726 bytes)
09:21:09.650 INFO  [Executor task launch worker for task 582] org.apache.spark.executor.Executor - Running task 172.0 in stage 9.0 (TID 582)
09:21:09.650 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 169.0 in stage 9.0 (TID 579) in 16 ms on localhost (executor driver) (170/200)
09:21:09.650 INFO  [Executor task launch worker for task 581] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=171), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/171] for update
09:21:09.650 INFO  [Executor task launch worker for task 580] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=170),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/170]
09:21:09.650 INFO  [Executor task launch worker for task 581] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=171), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/171] for update
09:21:09.650 INFO  [Executor task launch worker for task 580] org.apache.spark.executor.Executor - Finished task 170.0 in stage 9.0 (TID 580). 3365 bytes result sent to driver
09:21:09.650 INFO  [Executor task launch worker for task 582] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=172), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/172] for update
09:21:09.665 INFO  [Executor task launch worker for task 581] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.665 INFO  [Executor task launch worker for task 581] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.665 INFO  [Executor task launch worker for task 582] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=172), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/172] for update
09:21:09.665 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 173.0 in stage 9.0 (TID 583, localhost, executor driver, partition 173, PROCESS_LOCAL, 4726 bytes)
09:21:09.665 INFO  [Executor task launch worker for task 582] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.665 INFO  [Executor task launch worker for task 582] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.665 INFO  [Executor task launch worker for task 583] org.apache.spark.executor.Executor - Running task 173.0 in stage 9.0 (TID 583)
09:21:09.665 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 170.0 in stage 9.0 (TID 580) in 31 ms on localhost (executor driver) (171/200)
09:21:09.665 INFO  [Executor task launch worker for task 583] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=173), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/173] for update
09:21:09.665 INFO  [Executor task launch worker for task 583] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=173), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/173] for update
09:21:09.665 INFO  [Executor task launch worker for task 583] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.665 INFO  [Executor task launch worker for task 583] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.665 INFO  [Executor task launch worker for task 581] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=171),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/171] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/171/3.delta
09:21:09.665 INFO  [Executor task launch worker for task 582] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=172),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/172] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/172/3.delta
09:21:09.665 INFO  [Executor task launch worker for task 583] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=173),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/173] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/173/3.delta
09:21:09.665 INFO  [Executor task launch worker for task 582] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=172),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/172]
09:21:09.681 INFO  [Executor task launch worker for task 582] org.apache.spark.executor.Executor - Finished task 172.0 in stage 9.0 (TID 582). 3322 bytes result sent to driver
09:21:09.681 INFO  [dispatcher-event-loop-5] org.apache.spark.scheduler.TaskSetManager - Starting task 174.0 in stage 9.0 (TID 584, localhost, executor driver, partition 174, PROCESS_LOCAL, 4726 bytes)
09:21:09.681 INFO  [Executor task launch worker for task 581] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=171),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/171]
09:21:09.681 INFO  [Executor task launch worker for task 581] org.apache.spark.executor.Executor - Finished task 171.0 in stage 9.0 (TID 581). 3365 bytes result sent to driver
09:21:09.681 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 172.0 in stage 9.0 (TID 582) in 31 ms on localhost (executor driver) (172/200)
09:21:09.681 INFO  [Executor task launch worker for task 584] org.apache.spark.executor.Executor - Running task 174.0 in stage 9.0 (TID 584)
09:21:09.681 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 175.0 in stage 9.0 (TID 585, localhost, executor driver, partition 175, PROCESS_LOCAL, 4726 bytes)
09:21:09.681 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 171.0 in stage 9.0 (TID 581) in 31 ms on localhost (executor driver) (173/200)
09:21:09.681 INFO  [Executor task launch worker for task 585] org.apache.spark.executor.Executor - Running task 175.0 in stage 9.0 (TID 585)
09:21:09.681 INFO  [Executor task launch worker for task 584] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=174), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/174] for update
09:21:09.681 INFO  [Executor task launch worker for task 584] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=174), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/174] for update
09:21:09.681 INFO  [Executor task launch worker for task 584] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.681 INFO  [Executor task launch worker for task 584] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.681 INFO  [Executor task launch worker for task 583] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=173),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/173]
09:21:09.681 INFO  [Executor task launch worker for task 583] org.apache.spark.executor.Executor - Finished task 173.0 in stage 9.0 (TID 583). 3365 bytes result sent to driver
09:21:09.681 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 176.0 in stage 9.0 (TID 586, localhost, executor driver, partition 176, PROCESS_LOCAL, 4726 bytes)
09:21:09.681 INFO  [Executor task launch worker for task 586] org.apache.spark.executor.Executor - Running task 176.0 in stage 9.0 (TID 586)
09:21:09.681 INFO  [Executor task launch worker for task 585] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=175), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/175] for update
09:21:09.681 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 173.0 in stage 9.0 (TID 583) in 16 ms on localhost (executor driver) (174/200)
09:21:09.681 INFO  [Executor task launch worker for task 586] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=176), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/176] for update
09:21:09.681 INFO  [Executor task launch worker for task 584] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=174),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/174] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/174/3.delta
09:21:09.697 INFO  [Executor task launch worker for task 585] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=175), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/175] for update
09:21:09.697 INFO  [Executor task launch worker for task 586] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=176), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/176] for update
09:21:09.697 INFO  [Executor task launch worker for task 585] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.697 INFO  [Executor task launch worker for task 586] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.697 INFO  [Executor task launch worker for task 585] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.697 INFO  [Executor task launch worker for task 586] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.697 INFO  [Executor task launch worker for task 584] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=174),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/174]
09:21:09.697 INFO  [Executor task launch worker for task 584] org.apache.spark.executor.Executor - Finished task 174.0 in stage 9.0 (TID 584). 3322 bytes result sent to driver
09:21:09.697 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 177.0 in stage 9.0 (TID 587, localhost, executor driver, partition 177, PROCESS_LOCAL, 4726 bytes)
09:21:09.697 INFO  [Executor task launch worker for task 587] org.apache.spark.executor.Executor - Running task 177.0 in stage 9.0 (TID 587)
09:21:09.697 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 174.0 in stage 9.0 (TID 584) in 16 ms on localhost (executor driver) (175/200)
09:21:09.697 INFO  [Executor task launch worker for task 585] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=175),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/175] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/175/3.delta
09:21:09.697 INFO  [Executor task launch worker for task 586] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=176),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/176] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/176/3.delta
09:21:09.704 INFO  [Executor task launch worker for task 587] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=177), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/177] for update
09:21:09.704 INFO  [Executor task launch worker for task 587] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=177), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/177] for update
09:21:09.704 INFO  [Executor task launch worker for task 587] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.704 INFO  [Executor task launch worker for task 587] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.706 INFO  [Executor task launch worker for task 585] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=175),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/175]
09:21:09.706 INFO  [Executor task launch worker for task 586] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=176),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/176]
09:21:09.706 INFO  [Executor task launch worker for task 586] org.apache.spark.executor.Executor - Finished task 176.0 in stage 9.0 (TID 586). 3322 bytes result sent to driver
09:21:09.706 INFO  [Executor task launch worker for task 585] org.apache.spark.executor.Executor - Finished task 175.0 in stage 9.0 (TID 585). 3322 bytes result sent to driver
09:21:09.707 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 178.0 in stage 9.0 (TID 588, localhost, executor driver, partition 178, PROCESS_LOCAL, 4726 bytes)
09:21:09.707 INFO  [Executor task launch worker for task 588] org.apache.spark.executor.Executor - Running task 178.0 in stage 9.0 (TID 588)
09:21:09.707 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 179.0 in stage 9.0 (TID 589, localhost, executor driver, partition 179, PROCESS_LOCAL, 4726 bytes)
09:21:09.708 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 176.0 in stage 9.0 (TID 586) in 26 ms on localhost (executor driver) (176/200)
09:21:09.708 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 175.0 in stage 9.0 (TID 585) in 27 ms on localhost (executor driver) (177/200)
09:21:09.708 INFO  [Executor task launch worker for task 589] org.apache.spark.executor.Executor - Running task 179.0 in stage 9.0 (TID 589)
09:21:09.709 INFO  [Executor task launch worker for task 588] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=178), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/178] for update
09:21:09.709 INFO  [Executor task launch worker for task 588] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=178), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/178] for update
09:21:09.709 INFO  [Executor task launch worker for task 588] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.709 INFO  [Executor task launch worker for task 588] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.710 INFO  [Executor task launch worker for task 589] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=179), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/179] for update
09:21:09.710 INFO  [Executor task launch worker for task 589] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=179), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/179] for update
09:21:09.710 INFO  [Executor task launch worker for task 589] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.710 INFO  [Executor task launch worker for task 589] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.713 INFO  [Executor task launch worker for task 587] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=177),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/177] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/177/3.delta
09:21:09.716 INFO  [Executor task launch worker for task 588] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=178),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/178] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/178/3.delta
09:21:09.717 INFO  [Executor task launch worker for task 587] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=177),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/177]
09:21:09.717 INFO  [Executor task launch worker for task 587] org.apache.spark.executor.Executor - Finished task 177.0 in stage 9.0 (TID 587). 3365 bytes result sent to driver
09:21:09.717 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 180.0 in stage 9.0 (TID 590, localhost, executor driver, partition 180, PROCESS_LOCAL, 4726 bytes)
09:21:09.718 INFO  [Executor task launch worker for task 590] org.apache.spark.executor.Executor - Running task 180.0 in stage 9.0 (TID 590)
09:21:09.718 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 177.0 in stage 9.0 (TID 587) in 21 ms on localhost (executor driver) (178/200)
09:21:09.719 INFO  [Executor task launch worker for task 588] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=178),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/178]
09:21:09.720 INFO  [Executor task launch worker for task 588] org.apache.spark.executor.Executor - Finished task 178.0 in stage 9.0 (TID 588). 3365 bytes result sent to driver
09:21:09.720 INFO  [Executor task launch worker for task 590] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=180), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/180] for update
09:21:09.720 INFO  [Executor task launch worker for task 590] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=180), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/180] for update
09:21:09.720 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 181.0 in stage 9.0 (TID 591, localhost, executor driver, partition 181, PROCESS_LOCAL, 4726 bytes)
09:21:09.720 INFO  [Executor task launch worker for task 590] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.720 INFO  [Executor task launch worker for task 590] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.720 INFO  [Executor task launch worker for task 591] org.apache.spark.executor.Executor - Running task 181.0 in stage 9.0 (TID 591)
09:21:09.720 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 178.0 in stage 9.0 (TID 588) in 14 ms on localhost (executor driver) (179/200)
09:21:09.721 INFO  [Executor task launch worker for task 589] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=179),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/179] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/179/3.delta
09:21:09.722 INFO  [Executor task launch worker for task 591] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=181), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/181] for update
09:21:09.722 INFO  [Executor task launch worker for task 591] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=181), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/181] for update
09:21:09.722 INFO  [Executor task launch worker for task 591] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.722 INFO  [Executor task launch worker for task 591] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.724 INFO  [Executor task launch worker for task 589] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=179),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/179]
09:21:09.725 INFO  [Executor task launch worker for task 589] org.apache.spark.executor.Executor - Finished task 179.0 in stage 9.0 (TID 589). 3408 bytes result sent to driver
09:21:09.725 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 182.0 in stage 9.0 (TID 592, localhost, executor driver, partition 182, PROCESS_LOCAL, 4726 bytes)
09:21:09.725 INFO  [Executor task launch worker for task 592] org.apache.spark.executor.Executor - Running task 182.0 in stage 9.0 (TID 592)
09:21:09.725 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 179.0 in stage 9.0 (TID 589) in 18 ms on localhost (executor driver) (180/200)
09:21:09.726 INFO  [Executor task launch worker for task 590] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=180),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/180] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/180/3.delta
09:21:09.727 INFO  [Executor task launch worker for task 592] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=182), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/182] for update
09:21:09.727 INFO  [Executor task launch worker for task 591] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=181),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/181] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/181/3.delta
09:21:09.727 INFO  [Executor task launch worker for task 592] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=182), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/182] for update
09:21:09.728 INFO  [Executor task launch worker for task 592] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.728 INFO  [Executor task launch worker for task 592] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
09:21:09.730 INFO  [Executor task launch worker for task 590] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=180),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/180]
09:21:09.731 INFO  [Executor task launch worker for task 590] org.apache.spark.executor.Executor - Finished task 180.0 in stage 9.0 (TID 590). 3408 bytes result sent to driver
09:21:09.731 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 183.0 in stage 9.0 (TID 593, localhost, executor driver, partition 183, PROCESS_LOCAL, 4726 bytes)
09:21:09.731 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 180.0 in stage 9.0 (TID 590) in 14 ms on localhost (executor driver) (181/200)
09:21:09.731 INFO  [Executor task launch worker for task 593] org.apache.spark.executor.Executor - Running task 183.0 in stage 9.0 (TID 593)
09:21:09.731 INFO  [Executor task launch worker for task 593] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=183), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/183] for update
09:21:09.731 INFO  [Executor task launch worker for task 593] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=183), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/183] for update
09:21:09.731 INFO  [Executor task launch worker for task 592] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=182),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/182] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/182/3.delta
09:21:09.731 INFO  [Executor task launch worker for task 593] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.731 INFO  [Executor task launch worker for task 593] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.731 INFO  [Executor task launch worker for task 591] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=181),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/181]
09:21:09.731 INFO  [Executor task launch worker for task 591] org.apache.spark.executor.Executor - Finished task 181.0 in stage 9.0 (TID 591). 3408 bytes result sent to driver
09:21:09.731 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 184.0 in stage 9.0 (TID 594, localhost, executor driver, partition 184, PROCESS_LOCAL, 4726 bytes)
09:21:09.731 INFO  [Executor task launch worker for task 594] org.apache.spark.executor.Executor - Running task 184.0 in stage 9.0 (TID 594)
09:21:09.731 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 181.0 in stage 9.0 (TID 591) in 11 ms on localhost (executor driver) (182/200)
09:21:09.731 INFO  [Executor task launch worker for task 592] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=182),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/182]
09:21:09.731 INFO  [Executor task launch worker for task 594] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=184), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/184] for update
09:21:09.731 INFO  [Executor task launch worker for task 593] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=183),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/183] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/183/3.delta
09:21:09.747 INFO  [Executor task launch worker for task 594] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=184), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/184] for update
09:21:09.747 INFO  [Executor task launch worker for task 594] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.747 INFO  [Executor task launch worker for task 594] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.747 INFO  [Executor task launch worker for task 592] org.apache.spark.executor.Executor - Finished task 182.0 in stage 9.0 (TID 592). 3365 bytes result sent to driver
09:21:09.747 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 185.0 in stage 9.0 (TID 595, localhost, executor driver, partition 185, PROCESS_LOCAL, 4726 bytes)
09:21:09.747 INFO  [Executor task launch worker for task 595] org.apache.spark.executor.Executor - Running task 185.0 in stage 9.0 (TID 595)
09:21:09.747 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 182.0 in stage 9.0 (TID 592) in 22 ms on localhost (executor driver) (183/200)
09:21:09.747 INFO  [Executor task launch worker for task 595] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=185), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/185] for update
09:21:09.747 INFO  [Executor task launch worker for task 595] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=185), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/185] for update
09:21:09.747 INFO  [Executor task launch worker for task 595] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.747 INFO  [Executor task launch worker for task 595] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.747 INFO  [Executor task launch worker for task 593] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=183),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/183]
09:21:09.747 INFO  [Executor task launch worker for task 593] org.apache.spark.executor.Executor - Finished task 183.0 in stage 9.0 (TID 593). 3322 bytes result sent to driver
09:21:09.747 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 186.0 in stage 9.0 (TID 596, localhost, executor driver, partition 186, PROCESS_LOCAL, 4726 bytes)
09:21:09.747 INFO  [Executor task launch worker for task 596] org.apache.spark.executor.Executor - Running task 186.0 in stage 9.0 (TID 596)
09:21:09.747 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 183.0 in stage 9.0 (TID 593) in 16 ms on localhost (executor driver) (184/200)
09:21:09.747 INFO  [Executor task launch worker for task 594] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=184),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/184] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/184/3.delta
09:21:09.747 INFO  [Executor task launch worker for task 596] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=186), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/186] for update
09:21:09.747 INFO  [Executor task launch worker for task 595] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=185),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/185] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/185/3.delta
09:21:09.762 INFO  [Executor task launch worker for task 596] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=186), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/186] for update
09:21:09.762 INFO  [Executor task launch worker for task 596] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.762 INFO  [Executor task launch worker for task 596] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.762 INFO  [Executor task launch worker for task 595] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=185),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/185]
09:21:09.762 INFO  [Executor task launch worker for task 594] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=184),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/184]
09:21:09.762 INFO  [Executor task launch worker for task 594] org.apache.spark.executor.Executor - Finished task 184.0 in stage 9.0 (TID 594). 3322 bytes result sent to driver
09:21:09.762 INFO  [Executor task launch worker for task 595] org.apache.spark.executor.Executor - Finished task 185.0 in stage 9.0 (TID 595). 3322 bytes result sent to driver
09:21:09.762 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 187.0 in stage 9.0 (TID 597, localhost, executor driver, partition 187, PROCESS_LOCAL, 4726 bytes)
09:21:09.762 INFO  [Executor task launch worker for task 597] org.apache.spark.executor.Executor - Running task 187.0 in stage 9.0 (TID 597)
09:21:09.762 INFO  [dispatcher-event-loop-2] org.apache.spark.scheduler.TaskSetManager - Starting task 188.0 in stage 9.0 (TID 598, localhost, executor driver, partition 188, PROCESS_LOCAL, 4726 bytes)
09:21:09.762 INFO  [Executor task launch worker for task 598] org.apache.spark.executor.Executor - Running task 188.0 in stage 9.0 (TID 598)
09:21:09.762 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 185.0 in stage 9.0 (TID 595) in 15 ms on localhost (executor driver) (185/200)
09:21:09.762 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 184.0 in stage 9.0 (TID 594) in 31 ms on localhost (executor driver) (186/200)
09:21:09.762 INFO  [Executor task launch worker for task 596] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=186),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/186] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/186/3.delta
09:21:09.762 INFO  [Executor task launch worker for task 597] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=187), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/187] for update
09:21:09.762 INFO  [Executor task launch worker for task 597] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=187), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/187] for update
09:21:09.762 INFO  [Executor task launch worker for task 598] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=188), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/188] for update
09:21:09.762 INFO  [Executor task launch worker for task 596] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=186),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/186]
09:21:09.778 INFO  [Executor task launch worker for task 597] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.778 INFO  [Executor task launch worker for task 598] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=188), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/188] for update
09:21:09.778 INFO  [Executor task launch worker for task 597] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.778 INFO  [Executor task launch worker for task 598] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.778 INFO  [Executor task launch worker for task 598] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.778 INFO  [Executor task launch worker for task 596] org.apache.spark.executor.Executor - Finished task 186.0 in stage 9.0 (TID 596). 3322 bytes result sent to driver
09:21:09.778 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 189.0 in stage 9.0 (TID 599, localhost, executor driver, partition 189, PROCESS_LOCAL, 4726 bytes)
09:21:09.778 INFO  [Executor task launch worker for task 599] org.apache.spark.executor.Executor - Running task 189.0 in stage 9.0 (TID 599)
09:21:09.778 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 186.0 in stage 9.0 (TID 596) in 31 ms on localhost (executor driver) (187/200)
09:21:09.778 INFO  [Executor task launch worker for task 599] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=189), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/189] for update
09:21:09.778 INFO  [Executor task launch worker for task 599] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=189), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/189] for update
09:21:09.778 INFO  [Executor task launch worker for task 599] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.778 INFO  [Executor task launch worker for task 599] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.778 INFO  [Executor task launch worker for task 598] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=188),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/188] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/188/3.delta
09:21:09.778 INFO  [Executor task launch worker for task 597] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=187),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/187] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/187/3.delta
09:21:09.778 INFO  [Executor task launch worker for task 599] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=189),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/189] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/189/3.delta
09:21:09.778 INFO  [Executor task launch worker for task 598] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=188),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/188]
09:21:09.778 INFO  [Executor task launch worker for task 597] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=187),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/187]
09:21:09.794 INFO  [Executor task launch worker for task 598] org.apache.spark.executor.Executor - Finished task 188.0 in stage 9.0 (TID 598). 3322 bytes result sent to driver
09:21:09.794 INFO  [Executor task launch worker for task 597] org.apache.spark.executor.Executor - Finished task 187.0 in stage 9.0 (TID 597). 3322 bytes result sent to driver
09:21:09.794 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 190.0 in stage 9.0 (TID 600, localhost, executor driver, partition 190, PROCESS_LOCAL, 4726 bytes)
09:21:09.794 INFO  [Executor task launch worker for task 600] org.apache.spark.executor.Executor - Running task 190.0 in stage 9.0 (TID 600)
09:21:09.794 INFO  [dispatcher-event-loop-4] org.apache.spark.scheduler.TaskSetManager - Starting task 191.0 in stage 9.0 (TID 601, localhost, executor driver, partition 191, PROCESS_LOCAL, 4726 bytes)
09:21:09.794 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 188.0 in stage 9.0 (TID 598) in 32 ms on localhost (executor driver) (188/200)
09:21:09.794 INFO  [Executor task launch worker for task 601] org.apache.spark.executor.Executor - Running task 191.0 in stage 9.0 (TID 601)
09:21:09.794 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 187.0 in stage 9.0 (TID 597) in 32 ms on localhost (executor driver) (189/200)
09:21:09.794 INFO  [Executor task launch worker for task 601] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=191), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/191] for update
09:21:09.794 INFO  [Executor task launch worker for task 601] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=191), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/191] for update
09:21:09.794 INFO  [Executor task launch worker for task 601] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.794 INFO  [Executor task launch worker for task 601] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.794 INFO  [Executor task launch worker for task 600] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=190), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/190] for update
09:21:09.794 INFO  [Executor task launch worker for task 600] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=190), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/190] for update
09:21:09.794 INFO  [Executor task launch worker for task 600] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.794 INFO  [Executor task launch worker for task 600] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.794 INFO  [Executor task launch worker for task 599] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=189),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/189]
09:21:09.809 INFO  [Executor task launch worker for task 599] org.apache.spark.executor.Executor - Finished task 189.0 in stage 9.0 (TID 599). 3322 bytes result sent to driver
09:21:09.809 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 192.0 in stage 9.0 (TID 602, localhost, executor driver, partition 192, PROCESS_LOCAL, 4726 bytes)
09:21:09.809 INFO  [Executor task launch worker for task 602] org.apache.spark.executor.Executor - Running task 192.0 in stage 9.0 (TID 602)
09:21:09.809 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 189.0 in stage 9.0 (TID 599) in 31 ms on localhost (executor driver) (190/200)
09:21:09.809 INFO  [Executor task launch worker for task 601] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=191),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/191] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/191/3.delta
09:21:09.809 INFO  [Executor task launch worker for task 600] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=190),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/190] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/190/3.delta
09:21:09.809 INFO  [Executor task launch worker for task 602] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=192), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/192] for update
09:21:09.809 INFO  [Executor task launch worker for task 602] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=192), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/192] for update
09:21:09.809 INFO  [Executor task launch worker for task 602] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.809 INFO  [Executor task launch worker for task 602] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.809 INFO  [Executor task launch worker for task 601] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=191),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/191]
09:21:09.809 INFO  [Executor task launch worker for task 601] org.apache.spark.executor.Executor - Finished task 191.0 in stage 9.0 (TID 601). 3365 bytes result sent to driver
09:21:09.809 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 193.0 in stage 9.0 (TID 603, localhost, executor driver, partition 193, PROCESS_LOCAL, 4726 bytes)
09:21:09.809 INFO  [Executor task launch worker for task 603] org.apache.spark.executor.Executor - Running task 193.0 in stage 9.0 (TID 603)
09:21:09.809 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 191.0 in stage 9.0 (TID 601) in 15 ms on localhost (executor driver) (191/200)
09:21:09.809 INFO  [Executor task launch worker for task 600] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=190),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/190]
09:21:09.809 INFO  [Executor task launch worker for task 602] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=192),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/192] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/192/3.delta
09:21:09.809 INFO  [Executor task launch worker for task 603] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=193), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/193] for update
09:21:09.825 INFO  [Executor task launch worker for task 603] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=193), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/193] for update
09:21:09.825 INFO  [Executor task launch worker for task 600] org.apache.spark.executor.Executor - Finished task 190.0 in stage 9.0 (TID 600). 3365 bytes result sent to driver
09:21:09.825 INFO  [Executor task launch worker for task 603] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.825 INFO  [Executor task launch worker for task 603] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.825 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 194.0 in stage 9.0 (TID 604, localhost, executor driver, partition 194, PROCESS_LOCAL, 4726 bytes)
09:21:09.825 INFO  [Executor task launch worker for task 604] org.apache.spark.executor.Executor - Running task 194.0 in stage 9.0 (TID 604)
09:21:09.825 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 190.0 in stage 9.0 (TID 600) in 31 ms on localhost (executor driver) (192/200)
09:21:09.825 INFO  [Executor task launch worker for task 604] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=194), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/194] for update
09:21:09.825 INFO  [Executor task launch worker for task 604] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=194), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/194] for update
09:21:09.825 INFO  [Executor task launch worker for task 604] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.825 INFO  [Executor task launch worker for task 604] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.825 INFO  [Executor task launch worker for task 602] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=192),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/192]
09:21:09.825 INFO  [Executor task launch worker for task 602] org.apache.spark.executor.Executor - Finished task 192.0 in stage 9.0 (TID 602). 3322 bytes result sent to driver
09:21:09.825 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 195.0 in stage 9.0 (TID 605, localhost, executor driver, partition 195, PROCESS_LOCAL, 4726 bytes)
09:21:09.825 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 192.0 in stage 9.0 (TID 602) in 16 ms on localhost (executor driver) (193/200)
09:21:09.825 INFO  [Executor task launch worker for task 605] org.apache.spark.executor.Executor - Running task 195.0 in stage 9.0 (TID 605)
09:21:09.825 INFO  [Executor task launch worker for task 603] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=193),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/193] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/193/3.delta
09:21:09.825 INFO  [Executor task launch worker for task 604] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=194),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/194] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/194/3.delta
09:21:09.825 INFO  [Executor task launch worker for task 605] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=195), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/195] for update
09:21:09.841 INFO  [Executor task launch worker for task 605] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=195), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/195] for update
09:21:09.841 INFO  [Executor task launch worker for task 605] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.841 INFO  [Executor task launch worker for task 605] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.841 INFO  [Executor task launch worker for task 603] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=193),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/193]
09:21:09.841 INFO  [Executor task launch worker for task 604] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=194),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/194]
09:21:09.841 INFO  [Executor task launch worker for task 604] org.apache.spark.executor.Executor - Finished task 194.0 in stage 9.0 (TID 604). 3322 bytes result sent to driver
09:21:09.841 INFO  [Executor task launch worker for task 603] org.apache.spark.executor.Executor - Finished task 193.0 in stage 9.0 (TID 603). 3322 bytes result sent to driver
09:21:09.841 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 196.0 in stage 9.0 (TID 606, localhost, executor driver, partition 196, PROCESS_LOCAL, 4726 bytes)
09:21:09.841 INFO  [Executor task launch worker for task 606] org.apache.spark.executor.Executor - Running task 196.0 in stage 9.0 (TID 606)
09:21:09.841 INFO  [dispatcher-event-loop-1] org.apache.spark.scheduler.TaskSetManager - Starting task 197.0 in stage 9.0 (TID 607, localhost, executor driver, partition 197, PROCESS_LOCAL, 4726 bytes)
09:21:09.841 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 194.0 in stage 9.0 (TID 604) in 16 ms on localhost (executor driver) (194/200)
09:21:09.841 INFO  [Executor task launch worker for task 607] org.apache.spark.executor.Executor - Running task 197.0 in stage 9.0 (TID 607)
09:21:09.841 INFO  [Executor task launch worker for task 605] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=195),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/195] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/195/3.delta
09:21:09.841 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 193.0 in stage 9.0 (TID 603) in 32 ms on localhost (executor driver) (195/200)
09:21:09.841 INFO  [Executor task launch worker for task 606] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=196), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/196] for update
09:21:09.841 INFO  [Executor task launch worker for task 606] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=196), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/196] for update
09:21:09.841 INFO  [Executor task launch worker for task 607] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=197), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/197] for update
09:21:09.841 INFO  [Executor task launch worker for task 605] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=195),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/195]
09:21:09.856 INFO  [Executor task launch worker for task 606] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.856 INFO  [Executor task launch worker for task 607] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=197), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/197] for update
09:21:09.856 INFO  [Executor task launch worker for task 606] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.856 INFO  [Executor task launch worker for task 607] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.856 INFO  [Executor task launch worker for task 607] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.856 INFO  [Executor task launch worker for task 605] org.apache.spark.executor.Executor - Finished task 195.0 in stage 9.0 (TID 605). 3322 bytes result sent to driver
09:21:09.856 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 198.0 in stage 9.0 (TID 608, localhost, executor driver, partition 198, PROCESS_LOCAL, 4726 bytes)
09:21:09.856 INFO  [Executor task launch worker for task 608] org.apache.spark.executor.Executor - Running task 198.0 in stage 9.0 (TID 608)
09:21:09.856 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 195.0 in stage 9.0 (TID 605) in 31 ms on localhost (executor driver) (196/200)
09:21:09.856 INFO  [Executor task launch worker for task 608] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=198), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/198] for update
09:21:09.856 INFO  [Executor task launch worker for task 608] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=198), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/198] for update
09:21:09.856 INFO  [Executor task launch worker for task 608] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.856 INFO  [Executor task launch worker for task 608] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.856 INFO  [Executor task launch worker for task 606] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=196),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/196] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/196/3.delta
09:21:09.856 INFO  [Executor task launch worker for task 607] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=197),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/197] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/197/3.delta
09:21:09.872 INFO  [Executor task launch worker for task 608] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=198),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/198] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/198/3.delta
09:21:09.872 INFO  [Executor task launch worker for task 606] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=196),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/196]
09:21:09.872 INFO  [Executor task launch worker for task 607] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=197),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/197]
09:21:09.872 INFO  [Executor task launch worker for task 607] org.apache.spark.executor.Executor - Finished task 197.0 in stage 9.0 (TID 607). 3322 bytes result sent to driver
09:21:09.872 INFO  [Executor task launch worker for task 606] org.apache.spark.executor.Executor - Finished task 196.0 in stage 9.0 (TID 606). 3322 bytes result sent to driver
09:21:09.872 INFO  [dispatcher-event-loop-0] org.apache.spark.scheduler.TaskSetManager - Starting task 199.0 in stage 9.0 (TID 609, localhost, executor driver, partition 199, PROCESS_LOCAL, 4726 bytes)
09:21:09.872 INFO  [Executor task launch worker for task 609] org.apache.spark.executor.Executor - Running task 199.0 in stage 9.0 (TID 609)
09:21:09.872 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 197.0 in stage 9.0 (TID 607) in 31 ms on localhost (executor driver) (197/200)
09:21:09.872 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 196.0 in stage 9.0 (TID 606) in 31 ms on localhost (executor driver) (198/200)
09:21:09.872 INFO  [Executor task launch worker for task 608] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=198),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/198]
09:21:09.872 INFO  [Executor task launch worker for task 608] org.apache.spark.executor.Executor - Finished task 198.0 in stage 9.0 (TID 608). 3322 bytes result sent to driver
09:21:09.872 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 198.0 in stage 9.0 (TID 608) in 16 ms on localhost (executor driver) (199/200)
09:21:09.872 INFO  [Executor task launch worker for task 609] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=199), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/199] for update
09:21:09.872 INFO  [Executor task launch worker for task 609] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Retrieved version 2 of HDFSStateStoreProvider[id = (op=0, part=199), dir = C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/199] for update
09:21:09.872 INFO  [Executor task launch worker for task 609] org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 0 non-empty blocks out of 1 blocks
09:21:09.872 INFO  [Executor task launch worker for task 609] org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
09:21:09.887 INFO  [Executor task launch worker for task 609] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Committed version 3 for HDFSStateStore[id=(op=0,part=199),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/199] to file C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/199/3.delta
09:21:09.887 INFO  [Executor task launch worker for task 609] org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider - Aborted version 3 for HDFSStateStore[id=(op=0,part=199),dir=C:/Users/user/AppData/Local/Temp/temporary-a343d96b-199b-42bf-9c9b-f371b9e7f430/state/0/199]
09:21:09.887 INFO  [Executor task launch worker for task 609] org.apache.spark.executor.Executor - Finished task 199.0 in stage 9.0 (TID 609). 3322 bytes result sent to driver
09:21:09.887 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSetManager - Finished task 199.0 in stage 9.0 (TID 609) in 15 ms on localhost (executor driver) (200/200)
09:21:09.887 INFO  [task-result-getter-0] org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 9.0, whose tasks have all completed, from pool 
09:21:09.887 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - ResultStage 9 (start at demo.scala:28) finished in 1.674 s
09:21:09.887 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.scheduler.DAGScheduler - Job 6 finished: start at demo.scala:28, took 1.731869 s
09:21:09.903 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.SparkContext - Starting job: start at demo.scala:28
09:21:09.903 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Got job 7 (start at demo.scala:28) with 1 output partitions
09:21:09.903 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 10 (start at demo.scala:28)
09:21:09.903 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
09:21:09.903 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
09:21:09.903 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 10 (MapPartitionsRDD[50] at start at demo.scala:28), which has no missing parents
09:21:09.903 INFO  [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore - Block broadcast_16 stored as values in memory (estimated size 8.4 KB, free 1953.3 MB)
09:21:09.903 INFO  [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore - Block broadcast_16_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1953.3 MB)
09:21:09.903 INFO  [dispatcher-event-loop-1] org.apache.spark.storage.BlockManagerInfo - Added broadcast_16_piece0 in memory on 172.16.2.246:51465 (size: 4.6 KB, free: 1954.4 MB)
09:21:09.903 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext - Created broadcast 16 from broadcast at DAGScheduler.scala:1004
09:21:09.903 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[50] at start at demo.scala:28) (first 15 tasks are for partitions Vector(0))
09:21:09.903 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 10.0 with 1 tasks
09:21:09.903 INFO  [dispatcher-event-loop-7] org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 10.0 (TID 610, localhost, executor driver, partition 0, PROCESS_LOCAL, 5957 bytes)
09:21:09.903 INFO  [Executor task launch worker for task 610] org.apache.spark.executor.Executor - Running task 0.0 in stage 10.0 (TID 610)
09:21:09.919 INFO  [Executor task launch worker for task 610] org.apache.spark.executor.Executor - Finished task 0.0 in stage 10.0 (TID 610). 951 bytes result sent to driver
09:21:09.919 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 10.0 (TID 610) in 16 ms on localhost (executor driver) (1/1)
09:21:09.919 INFO  [task-result-getter-2] org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 10.0, whose tasks have all completed, from pool 
09:21:09.919 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - ResultStage 10 (start at demo.scala:28) finished in 0.016 s
09:21:09.919 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.scheduler.DAGScheduler - Job 7 finished: start at demo.scala:28, took 0.006556 s
09:21:09.919 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.SparkContext - Starting job: start at demo.scala:28
09:21:09.919 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Got job 8 (start at demo.scala:28) with 2 output partitions
09:21:09.919 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 11 (start at demo.scala:28)
09:21:09.919 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
09:21:09.919 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
09:21:09.919 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 11 (MapPartitionsRDD[50] at start at demo.scala:28), which has no missing parents
09:21:09.919 INFO  [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore - Block broadcast_17 stored as values in memory (estimated size 8.4 KB, free 1953.3 MB)
09:21:09.919 INFO  [dag-scheduler-event-loop] org.apache.spark.storage.memory.MemoryStore - Block broadcast_17_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1953.3 MB)
09:21:09.919 INFO  [dispatcher-event-loop-5] org.apache.spark.storage.BlockManagerInfo - Added broadcast_17_piece0 in memory on 172.16.2.246:51465 (size: 4.6 KB, free: 1954.4 MB)
09:21:09.919 INFO  [dag-scheduler-event-loop] org.apache.spark.SparkContext - Created broadcast 17 from broadcast at DAGScheduler.scala:1004
09:21:09.919 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from ResultStage 11 (MapPartitionsRDD[50] at start at demo.scala:28) (first 15 tasks are for partitions Vector(1, 2))
09:21:09.919 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 11.0 with 2 tasks
09:21:09.919 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 11.0 (TID 611, localhost, executor driver, partition 1, PROCESS_LOCAL, 5958 bytes)
09:21:09.919 INFO  [dispatcher-event-loop-3] org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 11.0 (TID 612, localhost, executor driver, partition 2, PROCESS_LOCAL, 5990 bytes)
09:21:09.919 INFO  [Executor task launch worker for task 611] org.apache.spark.executor.Executor - Running task 0.0 in stage 11.0 (TID 611)
09:21:09.919 INFO  [Executor task launch worker for task 612] org.apache.spark.executor.Executor - Running task 1.0 in stage 11.0 (TID 612)
09:21:09.919 INFO  [Executor task launch worker for task 611] org.apache.spark.executor.Executor - Finished task 0.0 in stage 11.0 (TID 611). 867 bytes result sent to driver
09:21:09.934 INFO  [task-result-getter-1] org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 11.0 (TID 611) in 15 ms on localhost (executor driver) (1/2)
09:21:09.934 INFO  [Executor task launch worker for task 612] org.apache.spark.executor.Executor - Finished task 1.0 in stage 11.0 (TID 612). 925 bytes result sent to driver
09:21:09.934 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 11.0 (TID 612) in 15 ms on localhost (executor driver) (2/2)
09:21:09.934 INFO  [task-result-getter-3] org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 11.0, whose tasks have all completed, from pool 
09:21:09.934 INFO  [dag-scheduler-event-loop] org.apache.spark.scheduler.DAGScheduler - ResultStage 11 (start at demo.scala:28) finished in 0.015 s
09:21:09.934 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.scheduler.DAGScheduler - Job 8 finished: start at demo.scala:28, took 0.015845 s
09:21:09.934 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.sql.execution.streaming.StreamExecution - Streaming query made progress: {
  "id" : "20adb406-fa0e-4b6d-891d-3b838da918df",
  "runId" : "042f103f-d70f-40a8-8188-bbfcfa159ed0",
  "name" : null,
  "timestamp" : "2020-10-12T01:21:07.916Z",
  "numInputRows" : 1,
  "inputRowsPerSecond" : 66.66666666666667,
  "processedRowsPerSecond" : 0.4955401387512389,
  "durationMs" : {
    "addBatch" : 1861,
    "getBatch" : 31,
    "getOffset" : 0,
    "queryPlanning" : 16,
    "triggerExecution" : 2018,
    "walCommit" : 110
  },
  "stateOperators" : [ {
    "numRowsTotal" : 7,
    "numRowsUpdated" : 2
  } ],
  "sources" : [ {
    "description" : "TextSocketSource[host: 10.112.0.8, port: 1122]",
    "startOffset" : 2,
    "endOffset" : 3,
    "numInputRows" : 1,
    "inputRowsPerSecond" : 66.66666666666667,
    "processedRowsPerSecond" : 0.4955401387512389
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSink@ee7e03"
  }
}
09:21:10.044 INFO  [stream execution thread for [id = 20adb406-fa0e-4b6d-891d-3b838da918df, runId = 042f103f-d70f-40a8-8188-bbfcfa159ed0]] org.apache.spark.sql.execution.streaming.StreamExecution - Streaming query made progress: {
  "id" : "20adb406-fa0e-4b6d-891d-3b838da918df",
  "runId" : "042f103f-d70f-40a8-8188-bbfcfa159ed0",
  "name" : null,
  "timestamp" : "2020-10-12T01:21:10.044Z",
  "numInputRows" : 0,
  "inputRowsPerSecond" : 0.0,
  "durationMs" : {
    "getOffset" : 0,
    "triggerExecution" : 0
  },
  "stateOperators" : [ {
    "numRowsTotal" : 7,
    "numRowsUpdated" : 0
  } ],
  "sources" : [ {
    "description" : "TextSocketSource[host: 10.112.0.8, port: 1122]",
    "startOffset" : 3,
    "endOffset" : 3,
    "numInputRows" : 0,
    "inputRowsPerSecond" : 0.0
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSink@ee7e03"
  }
}
09:21:46.044 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
09:21:49.262 ERROR [stream execution thread for [id = 30d160bf-be1a-49c3-9103-3c05180d95be, runId = 03218109-6e08-49ce-867d-622509383cc8]] org.apache.spark.sql.execution.streaming.StreamExecution - Query [id = 30d160bf-be1a-49c3-9103-3c05180d95be, runId = 03218109-6e08-49ce-867d-622509383cc8] terminated with error
java.net.ConnectException: Connection refused: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at java.net.Socket.connect(Socket.java:538)
	at java.net.Socket.<init>(Socket.java:434)
	at java.net.Socket.<init>(Socket.java:211)
	at org.apache.spark.sql.execution.streaming.TextSocketSource.initialize(socket.scala:73)
	at org.apache.spark.sql.execution.streaming.TextSocketSource.<init>(socket.scala:70)
	at org.apache.spark.sql.execution.streaming.TextSocketSourceProvider.createSource(socket.scala:215)
	at org.apache.spark.sql.execution.datasources.DataSource.createSource(DataSource.scala:244)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anonfun$2$$anonfun$applyOrElse$1.apply(StreamExecution.scala:158)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anonfun$2$$anonfun$applyOrElse$1.apply(StreamExecution.scala:155)
	at scala.collection.mutable.HashMap.getOrElseUpdate(HashMap.scala:79)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anonfun$2.applyOrElse(StreamExecution.scala:155)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anonfun$2.applyOrElse(StreamExecution.scala:153)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$2.apply(TreeNode.scala:267)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$2.apply(TreeNode.scala:267)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:266)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformDown$1.apply(TreeNode.scala:272)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformDown$1.apply(TreeNode.scala:272)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:306)
	at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)
	at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:304)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:272)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformDown$1.apply(TreeNode.scala:272)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformDown$1.apply(TreeNode.scala:272)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:306)
	at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)
	at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:304)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:272)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformDown$1.apply(TreeNode.scala:272)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformDown$1.apply(TreeNode.scala:272)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:306)
	at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)
	at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:304)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:272)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformDown$1.apply(TreeNode.scala:272)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformDown$1.apply(TreeNode.scala:272)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:306)
	at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)
	at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:304)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:272)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transform(TreeNode.scala:256)
	at org.apache.spark.sql.execution.streaming.StreamExecution.logicalPlan$lzycompute(StreamExecution.scala:153)
	at org.apache.spark.sql.execution.streaming.StreamExecution.logicalPlan(StreamExecution.scala:147)
	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runBatches(StreamExecution.scala:276)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:206)
09:22:23.620 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
09:28:25.276 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
09:28:35.495 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
09:29:09.448 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
09:52:39.292 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
09:53:06.417 WARN  [TextSocketSource(10.112.0.8, 1122)] org.apache.spark.sql.execution.streaming.TextSocketSource - Stream closed by 10.112.0.8:1122
10:00:43.405 WARN  [main] org.apache.spark.util.Utils - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
10:00:44.433 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
10:01:11.337 WARN  [main] org.apache.spark.util.Utils - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
10:01:12.369 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
10:01:34.730 WARN  [TextSocketSource(10.112.0.8, 1122)] org.apache.spark.sql.execution.streaming.TextSocketSource - Stream closed by 10.112.0.8:1122
10:12:11.527 WARN  [main] org.apache.spark.util.Utils - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
10:12:12.659 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
10:12:21.960 WARN  [main] org.apache.spark.util.Utils - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
10:12:23.095 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
10:13:47.208 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
10:13:50.609 ERROR [stream execution thread for [id = cce0b9c5-6bee-4970-acbf-4cfc482ca04d, runId = aaa342a2-bb72-4c96-9db2-10a722b57c6b]] org.apache.spark.sql.execution.streaming.StreamExecution - Query [id = cce0b9c5-6bee-4970-acbf-4cfc482ca04d, runId = aaa342a2-bb72-4c96-9db2-10a722b57c6b] terminated with error
java.net.ConnectException: Connection refused: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at java.net.Socket.connect(Socket.java:538)
	at java.net.Socket.<init>(Socket.java:434)
	at java.net.Socket.<init>(Socket.java:211)
	at org.apache.spark.sql.execution.streaming.TextSocketSource.initialize(socket.scala:73)
	at org.apache.spark.sql.execution.streaming.TextSocketSource.<init>(socket.scala:70)
	at org.apache.spark.sql.execution.streaming.TextSocketSourceProvider.createSource(socket.scala:215)
	at org.apache.spark.sql.execution.datasources.DataSource.createSource(DataSource.scala:244)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anonfun$2$$anonfun$applyOrElse$1.apply(StreamExecution.scala:158)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anonfun$2$$anonfun$applyOrElse$1.apply(StreamExecution.scala:155)
	at scala.collection.mutable.HashMap.getOrElseUpdate(HashMap.scala:79)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anonfun$2.applyOrElse(StreamExecution.scala:155)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anonfun$2.applyOrElse(StreamExecution.scala:153)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$2.apply(TreeNode.scala:267)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$2.apply(TreeNode.scala:267)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:266)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformDown$1.apply(TreeNode.scala:272)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformDown$1.apply(TreeNode.scala:272)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:306)
	at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)
	at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:304)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:272)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transform(TreeNode.scala:256)
	at org.apache.spark.sql.execution.streaming.StreamExecution.logicalPlan$lzycompute(StreamExecution.scala:153)
	at org.apache.spark.sql.execution.streaming.StreamExecution.logicalPlan(StreamExecution.scala:147)
	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runBatches(StreamExecution.scala:276)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:206)
10:14:03.899 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
10:14:48.692 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
10:14:52.276 ERROR [stream execution thread for [id = e4913c3c-5faf-4b4f-98ac-fbc9bc1066ce, runId = 5d7cdc1f-931e-48af-9ae2-9723007b95b6]] org.apache.spark.sql.execution.streaming.StreamExecution - Query [id = e4913c3c-5faf-4b4f-98ac-fbc9bc1066ce, runId = 5d7cdc1f-931e-48af-9ae2-9723007b95b6] terminated with error
java.net.ConnectException: Connection refused: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at java.net.Socket.connect(Socket.java:538)
	at java.net.Socket.<init>(Socket.java:434)
	at java.net.Socket.<init>(Socket.java:211)
	at org.apache.spark.sql.execution.streaming.TextSocketSource.initialize(socket.scala:73)
	at org.apache.spark.sql.execution.streaming.TextSocketSource.<init>(socket.scala:70)
	at org.apache.spark.sql.execution.streaming.TextSocketSourceProvider.createSource(socket.scala:215)
	at org.apache.spark.sql.execution.datasources.DataSource.createSource(DataSource.scala:244)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anonfun$2$$anonfun$applyOrElse$1.apply(StreamExecution.scala:158)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anonfun$2$$anonfun$applyOrElse$1.apply(StreamExecution.scala:155)
	at scala.collection.mutable.HashMap.getOrElseUpdate(HashMap.scala:79)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anonfun$2.applyOrElse(StreamExecution.scala:155)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anonfun$2.applyOrElse(StreamExecution.scala:153)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$2.apply(TreeNode.scala:267)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$2.apply(TreeNode.scala:267)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:266)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformDown$1.apply(TreeNode.scala:272)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformDown$1.apply(TreeNode.scala:272)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:306)
	at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)
	at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:304)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:272)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transform(TreeNode.scala:256)
	at org.apache.spark.sql.execution.streaming.StreamExecution.logicalPlan$lzycompute(StreamExecution.scala:153)
	at org.apache.spark.sql.execution.streaming.StreamExecution.logicalPlan(StreamExecution.scala:147)
	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runBatches(StreamExecution.scala:276)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:206)
10:15:00.549 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
16:03:03.465 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
16:03:33.418 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
16:05:14.782 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
16:05:56.327 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
16:07:30.041 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
16:07:51.357 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
16:12:15.573 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
16:13:32.557 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
16:30:36.324 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
16:30:54.995 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
16:37:27.323 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
16:37:46.374 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
16:38:13.256 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
16:38:31.981 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
16:38:47.972 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
16:39:05.216 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
16:39:17.621 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
16:39:44.986 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
16:40:05.638 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
16:42:31.856 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
16:43:03.461 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
16:43:24.333 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
16:49:03.568 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
16:50:37.836 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
16:51:02.468 ERROR [stream execution thread for [id = 1f1fabb4-46b9-4caf-b63f-bdf43e59557f, runId = 754eab74-66f0-4672-afa8-7819d5a17984]] org.apache.spark.sql.execution.streaming.StreamExecution - Query [id = 1f1fabb4-46b9-4caf-b63f-bdf43e59557f, runId = 754eab74-66f0-4672-afa8-7819d5a17984] terminated with error
java.lang.RuntimeException: Offsets committed out of order: 7 followed by 0
	at scala.sys.package$.error(package.scala:27)
	at org.apache.spark.sql.execution.streaming.TextSocketSource.commit(socket.scala:151)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anonfun$org$apache$spark$sql$execution$streaming$StreamExecution$$constructNextBatch$2$$anonfun$apply$mcV$sp$4.apply(StreamExecution.scala:578)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anonfun$org$apache$spark$sql$execution$streaming$StreamExecution$$constructNextBatch$2$$anonfun$apply$mcV$sp$4.apply(StreamExecution.scala:577)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at org.apache.spark.sql.execution.streaming.StreamProgress.foreach(StreamProgress.scala:25)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anonfun$org$apache$spark$sql$execution$streaming$StreamExecution$$constructNextBatch$2.apply$mcV$sp(StreamExecution.scala:577)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anonfun$org$apache$spark$sql$execution$streaming$StreamExecution$$constructNextBatch$2.apply(StreamExecution.scala:560)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anonfun$org$apache$spark$sql$execution$streaming$StreamExecution$$constructNextBatch$2.apply(StreamExecution.scala:560)
	at org.apache.spark.sql.execution.streaming.ProgressReporter$class.reportTimeTaken(ProgressReporter.scala:279)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:58)
	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$constructNextBatch(StreamExecution.scala:560)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anonfun$org$apache$spark$sql$execution$streaming$StreamExecution$$runBatches$1$$anonfun$apply$mcZ$sp$1.apply$mcV$sp(StreamExecution.scala:301)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anonfun$org$apache$spark$sql$execution$streaming$StreamExecution$$runBatches$1$$anonfun$apply$mcZ$sp$1.apply(StreamExecution.scala:294)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anonfun$org$apache$spark$sql$execution$streaming$StreamExecution$$runBatches$1$$anonfun$apply$mcZ$sp$1.apply(StreamExecution.scala:294)
	at org.apache.spark.sql.execution.streaming.ProgressReporter$class.reportTimeTaken(ProgressReporter.scala:279)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:58)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anonfun$org$apache$spark$sql$execution$streaming$StreamExecution$$runBatches$1.apply$mcZ$sp(StreamExecution.scala:294)
	at org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:56)
	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runBatches(StreamExecution.scala:290)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:206)
16:51:35.480 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
16:53:04.500 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
16:54:07.618 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
16:54:33.777 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
16:55:09.280 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
16:55:33.162 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
16:55:51.584 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
16:58:51.439 WARN  [main] org.apache.spark.util.Utils - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
16:58:52.553 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
17:02:19.268 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
17:03:03.701 WARN  [main] org.apache.spark.sql.execution.streaming.TextSocketSourceProvider - The socket source should not be used for production applications! It does not support recovery.
